{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model from .pt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformer_pre.model.layers.0.self_attn.linears.0.weight': tensor([[ 0.1929, -0.1434,  0.1674,  ..., -0.2686, -0.0792, -0.2879],\n",
       "         [-0.5098, -0.0883,  0.1339,  ...,  0.2154,  0.0339, -0.2529],\n",
       "         [ 0.0295, -0.1906, -0.0567,  ..., -0.1459, -0.1303,  0.1134],\n",
       "         ...,\n",
       "         [-0.3129, -0.0735, -0.1781,  ...,  0.1442, -0.2938,  0.3018],\n",
       "         [ 0.1674, -0.0591,  0.1731,  ...,  0.2861, -0.0229,  0.0705],\n",
       "         [ 0.4894,  0.2884,  0.3042,  ...,  0.1915,  0.1011, -0.1972]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.self_attn.linears.0.bias': tensor([ 0.1978, -0.0811,  0.4387,  0.2889, -0.2096, -0.3072,  0.0796, -0.3571,\n",
       "         -0.3882,  0.1370,  0.4042, -0.7931, -0.1303, -0.7332, -0.7641, -0.1119,\n",
       "          0.3365,  0.3808, -0.4955, -0.4895, -0.2097, -0.3209, -0.3213, -0.0183,\n",
       "         -0.1759,  0.3475, -0.2716,  0.0756,  0.3113,  0.5932, -0.0885,  0.0647,\n",
       "         -0.3849, -0.2654,  0.1210, -0.5482, -0.5969,  0.2672,  0.5791, -0.2713,\n",
       "          0.3348,  0.3451, -0.5052,  0.1682,  0.1163, -0.7698, -0.4078,  0.7576,\n",
       "         -0.2664, -0.6873], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.self_attn.linears.1.weight': tensor([[-0.3986,  0.1108,  0.1962,  ..., -0.1693, -0.0610,  0.2078],\n",
       "         [ 0.0639,  0.0214,  0.0261,  ...,  0.0083,  0.1847,  0.1300],\n",
       "         [-0.4816,  0.0809, -0.0087,  ..., -0.0276,  0.0680,  0.0754],\n",
       "         ...,\n",
       "         [-0.2291,  0.1108, -0.0615,  ...,  0.0693,  0.0388, -0.0248],\n",
       "         [ 0.2736, -0.0837,  0.0788,  ...,  0.0578, -0.0036, -0.0672],\n",
       "         [ 0.0226,  0.0391,  0.0426,  ...,  0.0096, -0.1733,  0.1278]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.self_attn.linears.1.bias': tensor([-0.0789, -0.1411, -0.0460, -0.0866,  0.0874, -0.0903,  0.0955, -0.1204,\n",
       "         -0.0193, -0.1312,  0.1102, -0.1048,  0.0410, -0.1079,  0.0975, -0.0970,\n",
       "          0.1302,  0.0401, -0.0026,  0.1350,  0.0527, -0.0560,  0.1290, -0.1341,\n",
       "          0.1307,  0.1356,  0.1026, -0.0706, -0.0911,  0.0842,  0.0821,  0.1341,\n",
       "         -0.1218, -0.0806, -0.1367,  0.1334,  0.0300,  0.1203, -0.0412, -0.1075,\n",
       "          0.1184,  0.0117, -0.0881,  0.0003,  0.1279, -0.0429, -0.0396,  0.0975,\n",
       "         -0.0364,  0.0842], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.self_attn.linears.2.weight': tensor([[ 0.0728, -0.1384, -0.0202,  ..., -0.1181, -0.1345,  0.1474],\n",
       "         [-0.2576, -0.0586, -0.0445,  ...,  0.0765,  0.2134, -0.1019],\n",
       "         [-0.0172,  0.0125,  0.0258,  ...,  0.0500, -0.0269,  0.1252],\n",
       "         ...,\n",
       "         [ 0.1999,  0.0642, -0.0648,  ..., -0.0710, -0.0553,  0.1848],\n",
       "         [-0.1406, -0.1016,  0.0987,  ...,  0.0222,  0.2413, -0.0713],\n",
       "         [-0.2877,  0.0932,  0.0276,  ..., -0.0273,  0.1202, -0.0741]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.self_attn.linears.2.bias': tensor([-0.0979, -0.0872, -0.0708,  0.0353,  0.0236, -0.0313,  0.1972, -0.2446,\n",
       "          0.0689, -0.1765,  0.1427, -0.0594,  0.1578, -0.2912,  0.2391, -0.4130,\n",
       "          0.1511,  0.2062,  0.0645,  0.1795,  0.2861, -0.0231,  0.0785, -0.4090,\n",
       "          0.2121,  0.0435,  0.2891, -0.4341, -0.0057,  0.1671, -0.0338,  0.1762,\n",
       "         -0.0340, -0.1262, -0.2874,  0.1431,  0.2004,  0.0460,  0.1261, -0.4915,\n",
       "          0.0472,  0.0877, -0.0336, -0.0772,  0.1129, -0.0694, -0.2462,  0.1499,\n",
       "          0.0318,  0.0343], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.self_attn.linears.3.weight': tensor([[ 0.0428, -0.3914, -0.0186,  ...,  0.1363, -0.4614, -0.3384],\n",
       "         [-0.0031,  0.0968,  0.0248,  ..., -0.0293, -0.0574,  0.0189],\n",
       "         [ 0.0101,  0.4184, -0.0408,  ..., -0.0789,  0.4655,  0.1689],\n",
       "         ...,\n",
       "         [ 0.1066,  0.6499, -0.1475,  ..., -0.2108,  0.4315,  0.1234],\n",
       "         [ 0.0118,  0.2387, -0.0213,  ..., -0.0600,  0.3158,  0.0483],\n",
       "         [-0.1301, -0.0637,  0.2058,  ...,  0.0538,  0.1837, -0.0238]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.self_attn.linears.3.bias': tensor([-3.2616e-02, -3.7118e-02,  6.1701e-05,  8.6055e-03, -2.1221e-02,\n",
       "          1.3452e-02,  6.4088e-02, -1.8787e-02,  5.4259e-02, -3.6818e-02,\n",
       "          9.7637e-02, -5.7644e-02,  3.5240e-02, -1.0884e-02, -5.4742e-02,\n",
       "         -4.8388e-02, -3.4968e-03,  2.1060e-02,  5.0789e-02,  1.5344e-02,\n",
       "          3.7943e-02, -1.5705e-02,  2.9873e-02, -2.7092e-03, -7.2577e-02,\n",
       "          1.6388e-01, -3.7982e-03, -4.0517e-02, -1.4735e-02, -3.0095e-03,\n",
       "         -2.7702e-02,  6.2101e-03, -2.2756e-02,  3.1798e-02,  9.9100e-03,\n",
       "          2.6366e-02, -4.1130e-02, -4.5006e-03,  2.8224e-03, -1.4627e-02,\n",
       "         -1.2453e-03,  2.2996e-02,  9.4283e-03,  1.8452e-02,  8.8370e-03,\n",
       "          1.9393e-02, -1.5882e-02, -4.3917e-02,  1.8511e-02, -1.0119e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.feed_forward.bn.weight': tensor([0.9426, 0.6083, 1.1580, 1.0716, 0.6796, 0.8794, 1.8289, 0.9769, 1.0464,\n",
       "         0.5438, 0.9646, 1.0272, 1.0716, 1.2510, 0.5674, 1.2118, 0.9372, 0.6815,\n",
       "         1.2830, 0.8912, 1.1343, 0.7117, 1.2338, 0.6935, 0.5360, 0.9408, 1.0923,\n",
       "         0.9271, 0.7866, 0.6273, 0.9900, 1.1186, 1.0877, 1.2229, 1.5218, 0.8754,\n",
       "         0.8121, 1.4762, 1.1391, 1.5425, 1.0249, 1.4257, 1.2475, 0.8746, 1.4063,\n",
       "         1.1855, 1.2018, 1.0729, 1.3026, 0.7146], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.feed_forward.bn.bias': tensor([-0.0988, -0.5955, -0.2007, -0.1573, -0.2672, -0.0808,  0.0093, -0.1908,\n",
       "         -0.1232, -0.3033, -0.1617, -0.2800, -0.2446, -0.1558, -0.4658, -0.2700,\n",
       "         -0.2421, -0.3178, -0.7716, -0.1647, -0.3674, -0.5015, -0.0464, -0.1833,\n",
       "         -0.5950, -0.2233, -0.3146, -0.1803, -0.2721, -0.2322, -0.0739, -0.8149,\n",
       "         -0.2398, -0.8293, -0.3843, -0.2805, -0.2194, -0.0505, -0.0132, -0.1815,\n",
       "         -0.1326, -0.5732,  0.2683, -0.4166, -0.3804, -0.3536, -0.1333, -0.1473,\n",
       "         -0.7848, -0.3834], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.feed_forward.bn.running_mean': tensor([ 0.1335, -0.0960,  0.0859,  0.1117, -0.0254,  0.1216,  0.0709,  0.1346,\n",
       "          0.0445,  0.1042,  0.0340,  0.0801,  0.0617, -0.0464, -0.0374, -0.1310,\n",
       "          0.3535,  0.0052, -0.0228,  0.0429,  0.0054,  0.1071,  0.0145,  0.0835,\n",
       "          0.1476,  0.1224, -0.1227,  0.2279,  0.0637,  0.0023,  0.1069,  0.0752,\n",
       "         -0.0176, -0.0417, -0.1063,  0.1282,  0.1429, -0.0550,  0.0407, -0.0329,\n",
       "          0.0483, -0.1039,  0.0423,  0.0026,  0.0104, -0.0233, -0.0715,  0.0530,\n",
       "          0.0316,  0.2727], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.feed_forward.bn.running_var': tensor([0.0558, 0.0450, 0.0272, 0.0702, 0.0350, 0.0785, 0.0407, 0.0529, 0.0323,\n",
       "         0.0346, 0.0613, 0.0537, 0.0418, 0.0136, 0.0744, 0.0185, 0.0671, 0.0546,\n",
       "         0.0134, 0.0334, 0.0073, 0.0219, 0.0217, 0.0269, 0.0403, 0.0317, 0.0978,\n",
       "         0.0735, 0.0437, 0.0508, 0.0214, 0.0254, 0.0173, 0.0144, 0.0293, 0.0850,\n",
       "         0.0384, 0.0309, 0.0427, 0.0418, 0.0109, 0.0289, 0.0510, 0.0344, 0.0136,\n",
       "         0.0452, 0.0391, 0.0309, 0.0042, 0.0980], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.feed_forward.bn.num_batches_tracked': tensor(213030),\n",
       " 'transformer_pre.model.layers.0.feed_forward.encoder_0.weight_ih_l0': tensor([[-0.3878,  0.0493, -0.1239,  ..., -0.0175, -0.1073,  0.0093],\n",
       "         [ 0.2174, -0.1033, -0.1739,  ..., -0.0880, -0.2287,  0.0774],\n",
       "         [ 0.0057,  0.1191, -0.1507,  ...,  0.0052, -0.1089,  0.0361],\n",
       "         ...,\n",
       "         [-0.1716,  0.3056,  0.0156,  ...,  0.0184, -0.0021, -0.2322],\n",
       "         [-0.0559,  0.1948,  0.1776,  ...,  0.1214, -0.1626, -0.1502],\n",
       "         [ 0.0718, -0.0992, -0.1154,  ...,  0.0722, -0.5134, -0.0269]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.feed_forward.encoder_0.weight_hh_l0': tensor([[-0.0532,  0.0971, -0.0912,  ..., -0.0294, -0.2710, -0.0623],\n",
       "         [-0.0687,  0.0937, -0.2631,  ..., -0.0107,  0.1357,  0.0492],\n",
       "         [ 0.0168, -0.0407, -0.3470,  ..., -0.0449, -0.1317,  0.3252],\n",
       "         ...,\n",
       "         [-0.3438,  0.2125,  0.0566,  ..., -0.4121,  0.5051,  0.0799],\n",
       "         [-0.0332, -0.0527, -0.2633,  ...,  0.0654,  0.0977,  0.0154],\n",
       "         [-0.1006, -0.2317, -0.1809,  ..., -0.1170, -0.4511,  0.0194]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.feed_forward.encoder_0.bias_ih_l0': tensor([-0.0732,  0.0436, -0.1981, -0.3213,  0.0598, -0.4032, -0.1352,  0.0136,\n",
       "          0.0079, -0.1588,  0.0073, -0.1364,  0.0254, -0.1179,  0.3509,  0.0535,\n",
       "          0.1302,  0.0653, -0.0393, -0.0559,  0.1266, -0.3687, -0.4025,  0.0028,\n",
       "         -0.0608, -0.3747, -0.0103, -0.0444,  0.1557, -0.0816, -0.0295, -0.1701,\n",
       "         -0.1101,  0.0643, -0.3845, -0.2638, -0.1711,  0.2476,  0.0768, -0.1864,\n",
       "         -0.1912, -0.3618, -0.0420, -0.2906, -0.2413, -0.0434, -0.2682, -0.1737,\n",
       "         -0.4012, -0.2912,  0.1586, -0.0242,  0.0859, -0.0723, -0.1672, -0.1204,\n",
       "         -0.2155, -0.1481, -0.0371, -0.0114, -0.1262, -0.2638,  0.1291, -0.2396,\n",
       "         -0.0474,  0.0411, -0.0704, -0.1213, -0.1381, -0.0268, -0.2778,  0.0283,\n",
       "          0.0966,  0.1040,  0.1786, -0.1409,  0.0842, -0.1556, -0.0097,  0.1695,\n",
       "         -0.2738, -0.2878,  0.0206,  0.0863, -0.1829, -0.2583,  0.0353,  0.0812,\n",
       "          0.0451, -0.0548, -0.2203, -0.1106, -0.0885, -0.2289, -0.0471, -0.2778,\n",
       "         -0.0554, -0.2163, -0.1209, -0.1161,  0.1487, -0.0357,  0.1854, -0.0010,\n",
       "         -0.0818, -0.0585,  0.0983,  0.0779,  0.0521,  0.1163,  0.2025,  0.1373,\n",
       "          0.1183, -0.0251,  0.0585, -0.0210,  0.2341, -0.0576, -0.2122,  0.1250,\n",
       "          0.1202,  0.0545, -0.0878,  0.0263,  0.0935,  0.1587, -0.2582,  0.2432,\n",
       "         -0.1260, -0.0619,  0.0348,  0.1769,  0.0747, -0.1541,  0.1297, -0.1983,\n",
       "         -0.0405, -0.0789, -0.0450, -0.0396,  0.0937,  0.0072,  0.2287,  0.0842,\n",
       "          0.0714, -0.0376,  0.1628,  0.0704,  0.0959,  0.0294,  0.2449,  0.0047,\n",
       "         -0.0535, -0.2374, -0.1026, -0.2582,  0.1549,  0.0747, -0.1166,  0.0160,\n",
       "         -0.2179, -0.1216, -0.1537, -0.0319,  0.0610,  0.3331,  0.2731,  0.2495,\n",
       "          0.2237,  0.1572,  0.1244, -0.3551,  0.0610,  0.2795, -0.0534, -0.1147,\n",
       "          0.1067,  0.1833, -0.1262, -0.1180,  0.0254, -0.3144, -0.3202,  0.3221,\n",
       "         -0.7392, -0.1652, -0.0130,  0.1174,  0.3090, -0.2036,  0.1843, -0.2532,\n",
       "          0.1279,  0.1573, -0.5776,  0.0888, -0.1139, -0.1344, -0.1882, -0.3317],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.feed_forward.encoder_0.bias_hh_l0': tensor([ 8.2333e-02,  5.6771e-02, -7.3498e-02, -4.2581e-01, -8.4536e-02,\n",
       "         -2.8023e-01, -1.3863e-01, -1.0703e-01,  5.1436e-02, -2.3653e-01,\n",
       "         -1.0457e-01, -2.1619e-01,  9.2150e-02, -2.9666e-01,  3.6578e-01,\n",
       "          2.6923e-01,  1.1931e-01,  1.0942e-01, -8.6057e-02,  6.8557e-02,\n",
       "          1.4116e-01, -3.8742e-01, -2.4542e-01, -3.4353e-02, -1.6509e-01,\n",
       "         -4.6170e-01,  2.2003e-01, -1.1428e-02, -6.0614e-02, -5.1986e-03,\n",
       "         -4.9071e-02, -1.9771e-01,  1.5075e-02,  2.0854e-01, -2.5906e-01,\n",
       "         -7.6267e-02, -1.4144e-01,  1.7703e-01, -8.7891e-02, -2.7172e-01,\n",
       "         -2.4941e-01, -5.1946e-01, -8.2560e-02, -2.1317e-01, -1.1254e-01,\n",
       "          4.8321e-02, -1.6397e-01,  4.2026e-02, -4.9606e-01, -2.4191e-01,\n",
       "          3.4019e-02,  2.4312e-02,  1.0694e-01, -2.3697e-01, -8.7893e-02,\n",
       "          2.1358e-02, -2.6893e-01,  4.0721e-02, -1.8686e-01,  5.0218e-02,\n",
       "         -8.2997e-02, -9.9190e-02,  9.1219e-02, -3.0230e-01, -1.2388e-01,\n",
       "         -9.4862e-02, -1.7464e-01, -1.1704e-01, -1.3820e-01,  8.7228e-02,\n",
       "         -1.8442e-01, -7.7137e-02, -8.2963e-02, -1.1136e-01,  1.3300e-01,\n",
       "         -2.9568e-01, -7.3803e-02,  4.0622e-02, -1.7510e-01,  1.3749e-01,\n",
       "         -1.9066e-01, -1.0086e-01, -2.3615e-01, -7.0864e-02, -3.4198e-01,\n",
       "         -3.3064e-01, -1.7282e-01,  2.0194e-01, -1.1215e-01, -1.5256e-01,\n",
       "         -2.1189e-01, -7.7881e-02, -1.2713e-01, -7.4111e-02,  1.0616e-02,\n",
       "         -7.5204e-02, -6.2945e-02, -2.6545e-01, -2.2496e-01, -1.8779e-01,\n",
       "         -1.1416e-01,  1.2198e-02,  6.3928e-02, -2.9979e-02, -1.4261e-01,\n",
       "         -3.0685e-02,  1.5963e-01,  1.0434e-01, -1.2993e-01, -1.9356e-02,\n",
       "          1.9087e-01,  1.7550e-01,  1.3831e-01,  1.4239e-01,  5.0554e-02,\n",
       "         -1.8106e-01,  3.3301e-01, -3.0989e-03,  5.4744e-02,  1.4039e-01,\n",
       "         -8.3452e-02,  6.2450e-02,  3.3323e-02,  1.4328e-01, -9.2287e-02,\n",
       "          7.5564e-04, -1.4207e-01,  2.2358e-01, -1.4707e-01,  1.3498e-01,\n",
       "          7.3319e-02,  8.4724e-02,  1.6232e-01, -4.2122e-01,  1.2931e-01,\n",
       "         -1.1366e-01, -4.9443e-02, -8.2378e-02, -4.3282e-02, -9.6052e-02,\n",
       "          1.2139e-01,  1.3612e-01,  1.7481e-01, -5.1987e-03,  1.2026e-01,\n",
       "          5.9578e-02, -9.5815e-02, -6.3211e-02, -2.6357e-02,  4.7980e-02,\n",
       "          2.5679e-01, -1.0917e-01,  1.6987e-02, -1.5283e-01, -2.0649e-01,\n",
       "         -4.1143e-01,  1.4568e-01, -5.3419e-02,  6.5587e-02,  1.7407e-01,\n",
       "         -1.6615e-01, -3.1151e-01, -2.5733e-01, -1.1084e-01,  1.5378e-01,\n",
       "          2.4541e-01,  2.4342e-01,  1.5809e-01,  1.4283e-02,  3.0660e-02,\n",
       "         -1.1447e-04, -3.4309e-01, -1.2875e-01,  8.3375e-02, -1.3352e-01,\n",
       "         -1.9408e-01,  1.5149e-01,  1.7917e-02, -6.7636e-02,  1.3187e-01,\n",
       "         -2.6862e-02, -3.1828e-01, -3.5240e-01,  1.1182e-01, -7.2985e-01,\n",
       "         -7.3302e-03,  6.3593e-02,  9.4058e-02,  2.5549e-01, -1.9939e-03,\n",
       "          3.0758e-01, -3.5141e-01,  5.6505e-02, -1.1578e-03, -5.5237e-01,\n",
       "         -2.9613e-02, -5.1341e-04, -1.6876e-01, -5.5667e-02, -3.2333e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.feed_forward.encoder_1.weight_ih_l0': tensor([[-0.1260, -0.1229, -0.1833,  ...,  0.0352, -0.0996, -0.0537],\n",
       "         [-0.1826, -0.0216,  0.1610,  ..., -0.3434,  0.1873,  0.1007],\n",
       "         [ 0.1159, -0.1532,  0.2005,  ...,  0.1663, -0.1379, -0.0108],\n",
       "         ...,\n",
       "         [-0.3285,  0.3068,  0.0698,  ..., -0.2147, -0.2967,  0.3195],\n",
       "         [ 0.0649, -0.0591,  0.0322,  ...,  0.0167,  0.0280, -0.0287],\n",
       "         [ 0.0604, -0.2340, -0.1850,  ...,  0.0734,  0.2489, -0.3174]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.feed_forward.encoder_1.weight_hh_l0': tensor([[-0.2428,  0.2500, -0.0119,  ..., -0.0085,  0.1109, -0.2234],\n",
       "         [-0.0256,  0.2264, -0.0734,  ..., -0.3793, -0.0520, -0.2973],\n",
       "         [-0.1170,  0.1185, -0.3074,  ...,  0.0557, -0.4792, -0.3711],\n",
       "         ...,\n",
       "         [ 0.0724, -0.4241, -0.2711,  ...,  0.0169, -0.1382, -0.0394],\n",
       "         [-0.0722, -0.0794, -0.1074,  ...,  0.3119,  0.0226,  0.0361],\n",
       "         [-0.1560, -0.0682,  0.3498,  ...,  0.1302, -0.2980, -0.1528]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.feed_forward.encoder_1.bias_ih_l0': tensor([ 1.7270e-01,  1.9966e-01, -1.6011e-01,  5.9815e-02, -2.1223e-03,\n",
       "          4.7117e-05, -5.7756e-02, -1.9750e-01, -8.1334e-02,  6.2950e-02,\n",
       "          1.7247e-01, -2.0820e-02, -1.7543e-01, -2.2872e-01, -2.3883e-01,\n",
       "         -5.3931e-01, -1.6635e-01,  6.0722e-02, -4.1291e-01, -9.2744e-02,\n",
       "          1.5199e-01, -2.1200e-01,  7.8026e-02, -6.4978e-02, -4.7066e-02,\n",
       "         -3.2199e-01,  8.7012e-02, -3.4657e-02, -3.0645e-01,  4.7000e-02,\n",
       "          1.9796e-02, -3.1620e-01,  1.0778e-01, -3.5545e-01,  2.3567e-01,\n",
       "          1.1886e-02, -2.2180e-01, -2.0836e-01, -8.6020e-02, -5.8348e-02,\n",
       "         -1.6893e-01,  2.5581e-01,  1.5299e-01,  5.1853e-02, -3.9708e-01,\n",
       "         -7.3420e-02, -1.3822e-01, -2.1586e-01, -2.3805e-01, -1.1144e-01,\n",
       "         -2.9025e-02, -2.7028e-02, -1.3622e-01, -7.1037e-02, -2.2451e-01,\n",
       "         -5.8590e-02,  4.7557e-02, -2.7110e-01,  1.1259e-01,  2.0935e-01,\n",
       "         -1.5849e-01,  1.6563e-01, -1.4446e-01, -8.5796e-02, -1.0506e-01,\n",
       "         -2.5684e-01, -6.0241e-02, -2.2702e-01, -3.0997e-01, -1.4609e-01,\n",
       "          1.9063e-01, -9.0230e-02, -1.2833e-01,  3.5367e-02,  2.7886e-01,\n",
       "         -8.3968e-02,  1.3344e-01, -1.3740e-01, -2.8564e-01, -1.1960e-01,\n",
       "          1.0089e-01, -1.4508e-02, -1.6891e-01, -5.5308e-02,  8.3501e-03,\n",
       "          2.5996e-02,  1.0133e-02, -1.6249e-01,  7.0925e-02, -1.7047e-01,\n",
       "         -1.8023e-01, -5.1430e-02, -1.7008e-01, -2.9537e-01, -3.2224e-02,\n",
       "          4.6751e-02,  7.3926e-02, -3.7869e-02, -5.7753e-02, -6.7910e-02,\n",
       "         -2.2570e-02, -2.2405e-01, -5.2499e-02, -1.4767e-01,  5.0042e-02,\n",
       "         -4.7989e-03, -7.3394e-02, -6.4451e-03,  8.3603e-02,  9.8315e-02,\n",
       "         -1.7554e-01, -1.5817e-01, -5.8010e-02, -1.3702e-02,  4.0484e-02,\n",
       "          2.0693e-01,  6.8326e-03,  2.3498e-02,  2.6833e-01, -1.3633e-01,\n",
       "          1.5012e-01,  9.0286e-02, -8.7517e-02,  1.5406e-01,  1.3489e-01,\n",
       "          9.6914e-02,  2.4955e-01,  3.1193e-02, -1.5258e-01,  1.4172e-02,\n",
       "          5.0142e-02,  2.5292e-02, -2.2471e-01, -2.5924e-02, -2.0943e-01,\n",
       "          1.7295e-01, -6.9735e-02,  4.2214e-02,  1.3105e-01,  7.8655e-02,\n",
       "          1.0401e-01, -2.2727e-01, -8.8490e-02,  1.6658e-02, -6.8208e-02,\n",
       "         -1.6208e-01, -7.5396e-02,  1.2447e-01,  1.2772e-01, -6.7616e-02,\n",
       "          7.5676e-02,  1.7724e-01, -1.8731e-01, -6.7999e-03,  1.4189e-01,\n",
       "          2.3380e-02, -6.6041e-02, -9.6418e-02,  1.2365e-01,  6.0163e-02,\n",
       "          3.6296e-03,  2.9682e-01, -8.6375e-02,  2.6868e-01, -6.8888e-02,\n",
       "         -1.9929e-01, -1.4604e-01,  8.2160e-02, -7.5622e-01,  7.6452e-04,\n",
       "         -4.0166e-01,  1.1818e-01,  3.9480e-02,  2.2451e-01, -1.6082e-01,\n",
       "         -1.8717e-01, -2.3217e-01, -2.0097e-01, -1.1128e-01,  1.5972e-01,\n",
       "          1.7236e-01, -1.6872e-02, -9.8109e-03, -2.3445e-01,  2.0277e-01,\n",
       "         -1.5135e-01, -1.0176e-01, -3.7108e-01,  2.3046e-01,  2.6433e-01,\n",
       "          1.4124e-01,  1.7889e-01,  2.0224e-01, -1.7481e-01, -2.3865e-01,\n",
       "          3.0311e-01,  2.9058e-01, -1.7168e-01, -3.1997e-01, -1.5339e-03],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.feed_forward.encoder_1.bias_hh_l0': tensor([-0.0618,  0.0138, -0.2631, -0.1114,  0.0517,  0.0175, -0.0290, -0.2754,\n",
       "          0.0315,  0.1770, -0.0490, -0.0842, -0.1611, -0.1614, -0.1452, -0.5124,\n",
       "         -0.2132, -0.1562, -0.3364, -0.0237, -0.0250, -0.3475,  0.0788, -0.0523,\n",
       "         -0.1364, -0.2083, -0.0355,  0.0291, -0.1481,  0.1142,  0.0838, -0.5230,\n",
       "         -0.0072, -0.1587,  0.2177, -0.0263, -0.1729, -0.2970,  0.0506, -0.1195,\n",
       "         -0.3325,  0.2338,  0.3711, -0.0745, -0.2934,  0.0180, -0.0639, -0.2299,\n",
       "         -0.4001, -0.0811, -0.0011,  0.0852, -0.1545, -0.2419, -0.2030, -0.0046,\n",
       "          0.0217, -0.1493, -0.0472,  0.0061, -0.1741,  0.2485, -0.0536, -0.1452,\n",
       "         -0.0511, -0.2113, -0.1616, -0.1621, -0.3840, -0.0201,  0.0540,  0.0091,\n",
       "         -0.2424, -0.0253,  0.1980,  0.0021, -0.0183, -0.1237, -0.2789, -0.0185,\n",
       "         -0.0148, -0.1781, -0.0146, -0.2015,  0.0834, -0.0419, -0.0625, -0.2227,\n",
       "         -0.0406, -0.1554, -0.2437, -0.0414, -0.2282, -0.1465, -0.1313,  0.1414,\n",
       "          0.0788, -0.1441, -0.0072,  0.0429,  0.2149, -0.1109,  0.1127, -0.2151,\n",
       "          0.0518,  0.1272,  0.1047, -0.1436,  0.0261,  0.1173, -0.0930, -0.1095,\n",
       "         -0.0790,  0.1130,  0.0341,  0.1202,  0.0169,  0.0655,  0.3197,  0.0551,\n",
       "          0.1968, -0.0803,  0.0575,  0.2065,  0.0531,  0.1761,  0.2723, -0.0047,\n",
       "         -0.2234, -0.0435, -0.0143, -0.0181, -0.0367, -0.0474, -0.1493,  0.1491,\n",
       "          0.0730,  0.2146,  0.0376,  0.0031,  0.0502, -0.2528,  0.0935,  0.0459,\n",
       "         -0.2071, -0.1937,  0.0103,  0.1575,  0.1095,  0.0948,  0.2093,  0.0816,\n",
       "         -0.1128,  0.1588, -0.0724,  0.1178, -0.1334, -0.0217,  0.0437, -0.0112,\n",
       "         -0.1806,  0.3104, -0.0292,  0.3135, -0.1404, -0.1329, -0.0896, -0.1550,\n",
       "         -0.8315,  0.0092, -0.3710,  0.0679,  0.2249,  0.0742, -0.0898, -0.1986,\n",
       "         -0.2856, -0.0201, -0.1310, -0.0279,  0.2804, -0.0197, -0.1209, -0.2907,\n",
       "          0.2209, -0.1597, -0.2315, -0.3935,  0.3889,  0.3182,  0.1143,  0.2971,\n",
       "          0.2198, -0.2802, -0.0175,  0.1981,  0.2135, -0.1630, -0.1595,  0.1274],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.feed_forward.encoder_2.weight_ih_l0': tensor([[-1.5254e-02, -1.3676e-01, -6.4132e-03,  ..., -1.3083e-01,\n",
       "           6.5948e-02,  2.4824e-04],\n",
       "         [ 1.5839e-01,  1.8632e-01, -2.6851e-01,  ...,  3.7753e-02,\n",
       "          -1.6832e-01,  2.4232e-01],\n",
       "         [-1.5704e-02,  9.9355e-02, -1.3545e-01,  ...,  3.5717e-03,\n",
       "           1.4518e-02,  2.8753e-01],\n",
       "         ...,\n",
       "         [-9.5986e-02, -1.5448e-01,  1.5104e-02,  ...,  9.6316e-02,\n",
       "          -8.2965e-02, -8.4302e-02],\n",
       "         [-2.2396e-02, -1.0914e+00, -1.1173e+00,  ...,  2.1525e-01,\n",
       "          -3.4441e-02, -6.6197e-02],\n",
       "         [ 2.6920e-01,  6.1323e-04,  8.4009e-02,  ..., -1.1104e-01,\n",
       "           1.5945e-01, -3.2700e-02]], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.feed_forward.encoder_2.weight_hh_l0': tensor([[ 0.1436, -0.0644,  0.1729,  ..., -0.0605,  0.1233,  0.2388],\n",
       "         [-0.2014, -0.1260,  0.0321,  ..., -0.0109, -0.0827, -0.1809],\n",
       "         [ 0.0242, -0.0512, -0.4908,  ..., -0.0755,  0.1698, -0.1096],\n",
       "         ...,\n",
       "         [-0.0541, -0.0013,  0.1473,  ...,  0.3563,  0.4260,  0.2293],\n",
       "         [ 0.0927,  0.1204,  0.1571,  ..., -0.0966,  0.2906,  0.5161],\n",
       "         [-0.0095,  0.0544,  0.2029,  ...,  0.1235, -0.3016, -0.1750]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.feed_forward.encoder_2.bias_ih_l0': tensor([ 1.8536e-01, -2.0661e-01, -1.4784e-01, -5.5297e-02, -2.4387e-02,\n",
       "          2.1209e-01,  2.1776e-02,  5.9875e-02, -6.4156e-03, -8.3809e-02,\n",
       "          7.2420e-02,  4.5318e-02, -2.1390e-01, -3.8719e-01, -9.4958e-02,\n",
       "         -3.7520e-01,  1.2808e-01, -2.0426e-01,  1.9760e-03,  6.7249e-02,\n",
       "         -6.0858e-02, -2.2606e-01, -1.0376e-01, -3.6461e-02, -2.7748e-01,\n",
       "         -9.5933e-03,  2.0145e-01,  1.8332e-02, -2.4191e-01, -3.3859e-01,\n",
       "          6.2165e-02, -6.6087e-04, -1.3045e-01, -3.7047e-01,  2.3814e-02,\n",
       "          4.0345e-01,  2.4190e-02,  5.1309e-02, -1.2832e-01, -1.9753e-01,\n",
       "         -8.0977e-01, -6.7391e-01, -3.1454e-02, -4.0662e-02, -1.3782e-01,\n",
       "         -5.3539e-01, -1.5784e-01,  1.4225e-01, -7.6482e-01,  1.7883e-01,\n",
       "          2.1764e-01, -8.7790e-02, -4.4656e-02, -2.7795e-01, -5.4740e-05,\n",
       "         -1.6150e-02, -7.1127e-02,  4.7495e-02, -1.0046e-01,  5.2148e-04,\n",
       "         -1.1134e-02, -2.8473e-03, -3.0160e-01, -8.7803e-02, -2.9362e-01,\n",
       "         -3.2985e-02,  5.9970e-02, -8.8296e-02, -4.6427e-01, -1.7967e-01,\n",
       "          4.0392e-02, -9.1169e-02, -2.1441e-01, -2.5650e-02, -1.4309e-01,\n",
       "         -9.2889e-02,  3.7792e-02,  1.1114e-01, -2.9453e-01, -2.5522e-01,\n",
       "         -1.8791e-02,  2.8022e-02, -1.1310e-02, -4.5047e-01, -1.7468e-01,\n",
       "          1.1620e-02, -1.3789e-01, -7.3088e-02,  1.2826e-01, -1.6945e-01,\n",
       "          1.6892e-02, -1.6751e-01, -3.1433e-01, -1.0138e-01, -1.2107e-02,\n",
       "         -6.3179e-02, -6.7119e-02,  1.9196e-03, -2.6595e-01, -1.3698e-01,\n",
       "          2.3422e-01, -9.0955e-03,  1.3182e-01, -4.5222e-03,  1.8637e-01,\n",
       "          1.7624e-01,  2.3424e-01,  4.9760e-02,  1.2223e-01, -1.8956e-01,\n",
       "          2.8103e-03,  7.4919e-02, -6.5227e-02,  1.1873e-01, -1.4674e-01,\n",
       "          6.2746e-02,  5.3981e-02, -1.3257e-01,  6.9287e-02,  6.5100e-02,\n",
       "         -1.6644e-01, -2.4107e-02,  8.8352e-02, -1.0268e-01,  5.2440e-02,\n",
       "          8.9774e-03, -6.1914e-02,  1.9711e-02,  1.5036e-01, -7.0806e-03,\n",
       "          1.1349e-01,  8.8305e-02, -7.8221e-02,  1.5862e-01,  9.8139e-02,\n",
       "          3.5098e-02,  4.3792e-02, -8.8232e-02,  7.9978e-02, -7.2741e-02,\n",
       "         -1.2593e-01, -2.5014e-01,  4.9183e-02,  1.6939e-01, -4.4486e-02,\n",
       "          4.1227e-02, -1.9065e-02, -4.6639e-02,  1.8180e-01,  6.6236e-02,\n",
       "          1.2652e-02, -2.0584e-01, -1.1301e-02, -3.5860e-01, -1.2442e-02,\n",
       "          9.8768e-02,  1.5651e-01, -1.0056e-01,  2.6555e-02, -2.0986e-01,\n",
       "          1.5625e-01, -1.6319e-01, -3.9070e-02, -2.2402e-01,  4.5617e-02,\n",
       "         -9.5849e-03,  1.5888e-01, -2.1632e-01,  2.8769e-03,  1.4401e-01,\n",
       "         -2.1248e-01, -3.2185e-02,  1.4249e-01,  6.4611e-02, -7.1393e-02,\n",
       "         -3.5573e-02,  2.1751e-01,  2.9205e-01, -6.3796e-02, -3.0412e-02,\n",
       "          1.1453e-01,  2.8001e-02, -2.1296e-01, -4.4458e-01,  8.5329e-02,\n",
       "          3.7366e-01,  9.3712e-02,  1.1167e-01, -1.4526e-02, -3.5403e-01,\n",
       "         -3.8655e-01, -5.0084e-01,  2.0104e-02, -3.2885e-01, -1.6705e-01,\n",
       "         -8.2768e-02,  8.5114e-02,  3.0545e-01, -8.6368e-01,  2.7426e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.feed_forward.encoder_2.bias_hh_l0': tensor([ 0.0713,  0.0289, -0.1658, -0.0310,  0.0114,  0.1874,  0.1253, -0.1356,\n",
       "          0.0245, -0.2743, -0.0049, -0.0750, -0.1940, -0.3441, -0.1563, -0.2910,\n",
       "          0.1123, -0.2702, -0.1524,  0.1259, -0.0563, -0.2619, -0.2197, -0.0975,\n",
       "         -0.1680, -0.0985,  0.2650, -0.0652, -0.1688, -0.1435, -0.0024, -0.1100,\n",
       "         -0.1230, -0.6297, -0.0269,  0.4213, -0.0060, -0.1336, -0.1309, -0.1407,\n",
       "         -0.6967, -0.6979, -0.0912,  0.1462, -0.3611, -0.5463,  0.0047,  0.1039,\n",
       "         -0.8525,  0.0380, -0.0020, -0.3131, -0.2572, -0.1388, -0.0676, -0.1007,\n",
       "         -0.0967,  0.0548, -0.1063, -0.0340, -0.0077,  0.0189, -0.2629, -0.3017,\n",
       "         -0.0825, -0.1383,  0.0504, -0.0069, -0.3428, -0.1783, -0.0225, -0.3127,\n",
       "         -0.1562, -0.1623, -0.1309, -0.1983, -0.0557, -0.0641, -0.1149, -0.1182,\n",
       "          0.0586, -0.1361,  0.0846, -0.4403, -0.0448, -0.0982,  0.0365, -0.1459,\n",
       "          0.2143, -0.3459, -0.1372, -0.2567, -0.1419, -0.1666, -0.1598,  0.0073,\n",
       "         -0.1324,  0.0552, -0.2946, -0.0978,  0.2031,  0.0018, -0.0789,  0.0832,\n",
       "          0.0126, -0.0905,  0.4422,  0.2305,  0.2279,  0.0750, -0.0167,  0.0928,\n",
       "          0.0932,  0.0353,  0.0677,  0.1259,  0.2062, -0.0565, -0.0816,  0.2468,\n",
       "         -0.0624,  0.0430,  0.0556,  0.1255,  0.0972,  0.1615, -0.0883,  0.0926,\n",
       "         -0.0381, -0.0707,  0.0764, -0.0800,  0.1545,  0.2096, -0.0682,  0.2363,\n",
       "          0.1044, -0.0206,  0.0977,  0.0072, -0.1401, -0.1253,  0.2128,  0.0035,\n",
       "         -0.0472,  0.0407, -0.0247, -0.1185,  0.0128, -0.0294,  0.0712, -0.1692,\n",
       "         -0.0536, -0.2382, -0.0380,  0.2227,  0.2918,  0.0486, -0.0997, -0.1650,\n",
       "          0.0687, -0.1217, -0.0380, -0.3036,  0.0144,  0.1214,  0.3200, -0.0826,\n",
       "          0.0038,  0.1363, -0.3461, -0.0953,  0.1608,  0.1395,  0.0272,  0.1182,\n",
       "          0.1652,  0.0498,  0.0375,  0.0753, -0.0386, -0.0574, -0.1641, -0.4245,\n",
       "         -0.0982,  0.2402,  0.1386,  0.2174,  0.0449, -0.2648, -0.2956, -0.6207,\n",
       "          0.0888, -0.1334, -0.0715, -0.1540, -0.1128,  0.3363, -0.6417,  0.0382],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.sublayer.0.norm.a_2': tensor([1.4794, 0.4691, 0.5419, 0.8682, 0.8849, 1.4791, 0.5034, 0.3827, 0.8735,\n",
       "         0.8781, 1.4857, 0.7525, 0.0272, 0.9732, 0.8452, 1.5386, 0.1345, 0.8120,\n",
       "         1.0144, 0.8197, 1.5047, 0.1398, 0.6854, 0.9283, 0.8210, 1.4760, 0.5174,\n",
       "         0.7848, 0.9929, 0.8279, 1.5169, 0.6397, 0.6629, 0.9631, 0.8446, 1.3847,\n",
       "         0.8204, 0.1624, 0.9528, 0.8241, 1.4452, 0.5895, 0.7423, 0.9493, 0.8169,\n",
       "         1.4800, 0.6817, 0.6380, 0.9889, 0.8338], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.sublayer.0.norm.b_2': tensor([ 0.0266, -0.1127, -0.2250,  0.0671, -0.1122,  0.1126, -0.0867, -0.2327,\n",
       "          0.1984, -0.1598, -0.0475, -0.1491, -0.0068,  0.2798, -0.0041,  0.1458,\n",
       "         -0.2354,  0.0042,  0.2459, -0.0941, -0.0226, -0.1105, -0.0844,  0.2703,\n",
       "         -0.0684,  0.0872, -0.1832, -0.1494,  0.2436, -0.1114,  0.0600, -0.0532,\n",
       "         -0.1180,  0.2520, -0.0637, -0.0372, -0.2187, -0.3450,  0.1046, -0.1257,\n",
       "          0.1396, -0.1107, -0.2885,  0.1270, -0.1052,  0.1619, -0.2095, -0.1793,\n",
       "          0.1513, -0.0289], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.sublayer.1.norm.a_2': tensor([1.1740, 1.1869, 1.0134, 1.2725, 1.4816, 0.8882, 1.1816, 1.2430, 1.4006,\n",
       "         1.2702, 0.7329, 1.4527, 1.3241, 1.4007, 1.1425, 0.4271, 1.0196, 1.2138,\n",
       "         1.2921, 1.0359, 0.5862, 1.4371, 1.3765, 1.0573, 1.0002, 0.4400, 1.2832,\n",
       "         1.2267, 1.3492, 1.0578, 0.7473, 1.3001, 1.2883, 1.2667, 0.9376, 1.0290,\n",
       "         1.1126, 1.2653, 1.2139, 0.8960, 0.7281, 1.0514, 1.1925, 0.9669, 1.0856,\n",
       "         1.0840, 1.1082, 0.8933, 1.2765, 1.0034], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.0.sublayer.1.norm.b_2': tensor([ 0.1286,  0.3247, -0.0541,  0.1955, -0.1298,  0.0843, -0.0770, -0.0856,\n",
       "          0.2451, -0.2744,  0.2537, -0.1376, -0.0793,  0.1726, -0.2254,  0.2236,\n",
       "         -0.1089, -0.0424,  0.2664, -0.4324,  0.2878,  0.0498,  0.0927,  0.1445,\n",
       "         -0.2615, -0.0510, -0.0297, -0.1514,  0.0978, -0.2786,  0.1022,  0.1171,\n",
       "         -0.1034,  0.0140, -0.1799,  0.1822, -0.0735,  0.0677,  0.2125, -0.3238,\n",
       "          0.2196, -0.0888,  0.0296,  0.1604, -0.1147,  0.0903, -0.0425,  0.0242,\n",
       "          0.2259, -0.1238], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.self_attn.linears.0.weight': tensor([[ 0.1953, -0.0289,  0.0509,  ..., -0.1535,  0.1587, -0.0590],\n",
       "         [ 0.0669,  0.2518,  0.0501,  ...,  0.0561,  0.1613,  0.0249],\n",
       "         [-0.0809, -0.1363, -0.1532,  ...,  0.0022, -0.0149,  0.1919],\n",
       "         ...,\n",
       "         [ 0.1536,  0.1097,  0.0732,  ...,  0.1774,  0.0196,  0.1136],\n",
       "         [ 0.1180, -0.0043,  0.0913,  ...,  0.0175,  0.2392, -0.0299],\n",
       "         [-0.1792,  0.0539,  0.0115,  ...,  0.0535, -0.0336,  0.2210]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.self_attn.linears.0.bias': tensor([-0.2590, -0.4160,  0.0582, -0.0972, -0.0961, -0.1960,  0.0748, -0.2164,\n",
       "         -0.0068, -0.0192,  0.1242, -0.3701,  0.0462, -0.2594, -0.0518, -0.1274,\n",
       "         -0.0836,  0.2748,  0.0472, -0.1779, -0.2777, -0.3152,  0.0374, -0.2409,\n",
       "          0.2053,  0.1181,  0.3273,  0.1736, -0.3665,  0.4548,  0.0319, -0.0102,\n",
       "         -0.4541, -0.2218, -0.3431, -0.1020, -0.1387,  0.3811,  0.1368,  0.1184,\n",
       "         -0.0094, -0.1714, -0.1072, -0.0680,  0.2798, -0.2913, -0.0081,  0.2257,\n",
       "         -0.2041, -0.0140], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.self_attn.linears.1.weight': tensor([[-0.1777, -0.0898, -0.1106,  ..., -0.1439,  0.0306, -0.0617],\n",
       "         [-0.0099, -0.0336,  0.1303,  ...,  0.2604,  0.0780, -0.0994],\n",
       "         [-0.1118, -0.0377, -0.0075,  ...,  0.0675, -0.0408,  0.0385],\n",
       "         ...,\n",
       "         [-0.0494,  0.1246, -0.1357,  ...,  0.0221,  0.0992,  0.1379],\n",
       "         [ 0.1069,  0.0471,  0.0673,  ...,  0.2456, -0.0111,  0.0284],\n",
       "         [ 0.1113, -0.1672, -0.0837,  ...,  0.2264, -0.2526,  0.0938]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.self_attn.linears.1.bias': tensor([-0.0789, -0.1411, -0.0460, -0.0866,  0.0874, -0.0903,  0.0955, -0.1204,\n",
       "         -0.0193, -0.1312,  0.1102, -0.1048,  0.0410, -0.1079,  0.0975, -0.0970,\n",
       "          0.1302,  0.0401, -0.0026,  0.1350,  0.0527, -0.0560,  0.1290, -0.1341,\n",
       "          0.1307,  0.1356,  0.1026, -0.0706, -0.0911,  0.0842,  0.0821,  0.1341,\n",
       "         -0.1218, -0.0806, -0.1367,  0.1334,  0.0300,  0.1203, -0.0412, -0.1075,\n",
       "          0.1184,  0.0117, -0.0881,  0.0003,  0.1279, -0.0429, -0.0396,  0.0975,\n",
       "         -0.0364,  0.0842], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.self_attn.linears.2.weight': tensor([[ 0.0567, -0.1889,  0.0409,  ..., -0.2694, -0.1107, -0.0589],\n",
       "         [-0.1133, -0.2398, -0.0421,  ...,  0.0263,  0.1829, -0.2441],\n",
       "         [ 0.0658, -0.0555,  0.1102,  ..., -0.0690,  0.0953,  0.2711],\n",
       "         ...,\n",
       "         [-0.0537, -0.1322,  0.0787,  ...,  0.0295, -0.1436,  0.3663],\n",
       "         [-0.1503,  0.0368,  0.1192,  ...,  0.2816,  0.1474,  0.0324],\n",
       "         [-0.0662, -0.0760, -0.0199,  ..., -0.0322,  0.3416, -0.0064]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.self_attn.linears.2.bias': tensor([-0.0675, -0.0442, -0.1230,  0.0227,  0.1238, -0.0631,  0.0233, -0.0713,\n",
       "          0.0590,  0.0403,  0.1112, -0.2009,  0.1413, -0.1458,  0.0849, -0.1362,\n",
       "          0.1345,  0.1247, -0.0688,  0.1094,  0.1993,  0.0644,  0.2317, -0.2729,\n",
       "          0.1925,  0.0072,  0.0844, -0.2061, -0.0009,  0.0971, -0.0905,  0.1952,\n",
       "         -0.0326, -0.0044, -0.1243,  0.1135, -0.0061,  0.0199, -0.0644, -0.1826,\n",
       "         -0.0174,  0.2373, -0.1543,  0.0455,  0.1546, -0.0767, -0.0640,  0.0817,\n",
       "          0.0637,  0.1871], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.self_attn.linears.3.weight': tensor([[ 0.0503, -0.0841,  0.0613,  ..., -0.1251, -0.2609,  0.0231],\n",
       "         [-0.1422,  0.0300,  0.1392,  ..., -0.1159,  0.2478, -0.0300],\n",
       "         [-0.1967, -0.1854, -0.1166,  ...,  0.0094,  0.0331,  0.1266],\n",
       "         ...,\n",
       "         [-0.0854,  0.1002, -0.1592,  ..., -0.0689,  0.1482,  0.0723],\n",
       "         [ 0.0812,  0.3161, -0.1601,  ..., -0.1614,  0.1174,  0.1494],\n",
       "         [-0.0913, -0.0983,  0.3132,  ...,  0.1094, -0.1206, -0.1509]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.self_attn.linears.3.bias': tensor([-0.1633, -0.3102,  0.0651, -0.2120,  0.1187, -0.0787,  0.0857, -0.2241,\n",
       "         -0.0674, -0.0862,  0.1168, -0.2039, -0.0685, -0.3086,  0.0599, -0.0418,\n",
       "          0.1234, -0.1474, -0.0068,  0.0514,  0.1438,  0.0116,  0.1757, -0.1200,\n",
       "          0.0005,  0.4686, -0.0424, -0.0250, -0.0352,  0.2184,  0.1328, -0.0039,\n",
       "         -0.1423, -0.1616,  0.0032,  0.0250, -0.0164,  0.0376,  0.0051, -0.0459,\n",
       "         -0.0590, -0.2864,  0.0126,  0.2401,  0.1326, -0.0962, -0.0029,  0.2022,\n",
       "          0.0590,  0.1193], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.feed_forward.bn.weight': tensor([0.8923, 0.6060, 1.3513, 0.8648, 1.2918, 0.9361, 1.1697, 0.9692, 0.6889,\n",
       "         1.1601, 1.0796, 1.0096, 0.7585, 0.8040, 0.9283, 0.9485, 0.9462, 0.7372,\n",
       "         1.0488, 1.1505, 0.8872, 1.0308, 0.7736, 0.9013, 1.2752, 1.1686, 1.0660,\n",
       "         0.9872, 1.0503, 1.2465, 1.2277, 0.7373, 0.7441, 1.0618, 0.9176, 1.0305,\n",
       "         0.9208, 1.1062, 1.0271, 1.0618, 1.0296, 0.9734, 1.0288, 0.8638, 1.2258,\n",
       "         0.7994, 0.9262, 1.0434, 1.4606, 1.4329], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.feed_forward.bn.bias': tensor([-0.1383, -0.4941,  0.2561, -0.1840, -0.0481, -0.1446,  0.0069, -0.1970,\n",
       "         -0.3537, -0.0375, -0.0069, -0.1939, -0.3686, -0.2168, -0.2003, -0.1159,\n",
       "         -0.0483, -0.2048, -0.1909, -0.0859, -0.1365, -0.0982, -0.4208, -0.2383,\n",
       "          0.1071, -0.0443,  0.1961, -0.2716, -0.2042,  0.1196,  0.0755, -0.3528,\n",
       "         -0.2439, -0.0313,  0.0930, -0.1928, -0.1554, -0.0350, -0.0832,  0.0031,\n",
       "          0.0168, -0.2100, -0.0325, -0.1938,  0.0026, -0.1645, -0.0972, -0.0849,\n",
       "          0.1707,  0.1547], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.feed_forward.bn.running_mean': tensor([ 0.1688,  0.1990,  0.1357,  0.0480,  0.1414, -0.1148,  0.2543,  0.1091,\n",
       "          0.1788,  0.1611,  0.0596,  0.1108,  0.0529,  0.1381,  0.0092,  0.0891,\n",
       "          0.0793, -0.0348,  0.0953,  0.1798, -0.0596,  0.0109, -0.0319,  0.1281,\n",
       "          0.0020,  0.0335,  0.0423,  0.0871,  0.0279,  0.2080,  0.1741,  0.0398,\n",
       "          0.0343,  0.1266, -0.0288,  0.2050, -0.0309,  0.0498, -0.0659,  0.0551,\n",
       "          0.1413, -0.1343,  0.0891,  0.1690,  0.0885,  0.0078, -0.0084,  0.0285,\n",
       "          0.0678,  0.1738], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.feed_forward.bn.running_var': tensor([0.1373, 0.1012, 0.0754, 0.0486, 0.0616, 0.0975, 0.0854, 0.0305, 0.0903,\n",
       "         0.0610, 0.0333, 0.0190, 0.0804, 0.0411, 0.0440, 0.0570, 0.0518, 0.1721,\n",
       "         0.0598, 0.0943, 0.0897, 0.0290, 0.0611, 0.0949, 0.0485, 0.0345, 0.0310,\n",
       "         0.0405, 0.0263, 0.0909, 0.0667, 0.0965, 0.0998, 0.0400, 0.0798, 0.0851,\n",
       "         0.1007, 0.0276, 0.0374, 0.0799, 0.0482, 0.0498, 0.0356, 0.0519, 0.0303,\n",
       "         0.0749, 0.0577, 0.0460, 0.0193, 0.0549], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.feed_forward.bn.num_batches_tracked': tensor(213030),\n",
       " 'transformer_pre.model.layers.1.feed_forward.encoder_0.weight_ih_l0': tensor([[ 0.2212, -0.1191, -0.0174,  ..., -0.2032, -0.0260,  0.2034],\n",
       "         [ 0.2966, -0.0511, -0.2750,  ..., -0.0648,  0.1172, -0.1796],\n",
       "         [ 0.2932,  0.1248, -0.2071,  ...,  0.1646,  0.0493, -0.1711],\n",
       "         ...,\n",
       "         [ 0.1064,  0.3160,  0.1771,  ...,  0.0027, -0.1753, -0.3103],\n",
       "         [ 0.0607,  0.1930, -0.0087,  ...,  0.1441, -0.1925, -0.2931],\n",
       "         [-0.0528, -0.1244, -0.1454,  ..., -0.1400, -0.2836, -0.5243]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.feed_forward.encoder_0.weight_hh_l0': tensor([[-0.1523, -0.0998,  0.0609,  ..., -0.1475, -0.1579,  0.0196],\n",
       "         [-0.1196, -0.1303,  0.0678,  ...,  0.1300,  0.0172, -0.2387],\n",
       "         [-0.1400, -0.2018, -0.0899,  ...,  0.0728,  0.0275, -0.0027],\n",
       "         ...,\n",
       "         [ 0.1503,  0.0899,  0.1467,  ..., -0.0006,  0.1598, -0.1257],\n",
       "         [ 0.2650, -0.0364, -0.2688,  ...,  0.1971,  0.3755, -0.0944],\n",
       "         [-0.0295,  0.0583, -0.1951,  ...,  0.1206, -0.0953, -0.2402]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.feed_forward.encoder_0.bias_ih_l0': tensor([-0.0031, -0.1469, -0.0378, -0.0760, -0.0790, -0.0985, -0.2326, -0.1939,\n",
       "          0.1348, -0.1973,  0.0301, -0.0374, -0.1419,  0.1224, -0.0699, -0.3757,\n",
       "         -0.4123, -0.3953,  0.1076, -0.1468,  0.1609, -0.3139, -0.1043, -0.0145,\n",
       "         -0.1606, -0.1932, -0.2525, -0.2294, -0.0382, -0.0885, -0.1553, -0.1032,\n",
       "          0.0320, -0.1012,  0.0227, -0.2756, -0.1949, -0.1163, -0.1522,  0.1930,\n",
       "         -0.0316, -0.1826, -0.3974, -0.3152, -0.0810, -0.2189, -0.2068, -0.3105,\n",
       "         -0.2621, -0.3332,  0.0292, -0.3400, -0.0884, -0.1039, -0.2772, -0.1470,\n",
       "         -0.2028, -0.2096,  0.1015, -0.2765, -0.1864, -0.0922, -0.0465, -0.0289,\n",
       "         -0.1004, -0.3162, -0.4277, -0.1198, -0.2047, -0.2754, -0.2320, -0.2382,\n",
       "          0.3597, -0.0844, -0.3134, -0.1439,  0.1184, -0.1550, -0.0892,  0.0252,\n",
       "         -0.4444, -0.3172,  0.0552, -0.0421,  0.0192, -0.2035, -0.0495, -0.2238,\n",
       "         -0.0939, -0.2224, -0.3500, -0.1414, -0.2344, -0.2381, -0.0674, -0.0492,\n",
       "         -0.0411, -0.2592, -0.2939, -0.4316,  0.1857, -0.0432,  0.1869, -0.1718,\n",
       "         -0.0809, -0.2873,  0.1282, -0.0216,  0.1917,  0.0994,  0.1904,  0.2960,\n",
       "         -0.0208,  0.1744,  0.0672,  0.0455, -0.0158, -0.1845, -0.1482, -0.0312,\n",
       "          0.1704,  0.0357, -0.2553, -0.0812, -0.1864,  0.1743, -0.1867, -0.0113,\n",
       "         -0.1232,  0.1158, -0.1026,  0.1505, -0.0613,  0.2422,  0.1274, -0.1054,\n",
       "         -0.0835, -0.0609, -0.2148,  0.0145,  0.1329, -0.1247,  0.1781,  0.0627,\n",
       "         -0.0109,  0.0640,  0.2163,  0.1429,  0.3392,  0.0371, -0.0415, -0.0582,\n",
       "         -0.0235, -0.1099, -0.2612,  0.0529, -0.0229, -0.1222, -0.1901, -0.1096,\n",
       "         -0.2852,  0.0789, -0.3231, -0.1561, -0.1466, -0.1607, -0.2310, -0.0212,\n",
       "          0.0008, -0.1738,  0.2442, -0.2009,  0.1335,  0.1655, -0.1826, -0.2832,\n",
       "         -0.2705, -0.0507, -0.2496, -0.3031, -0.2579, -0.0097, -0.3586,  0.0803,\n",
       "         -0.0489, -0.0427, -0.0770,  0.0049, -0.2237, -0.0327, -0.1881, -0.3618,\n",
       "         -0.0342, -0.0840, -0.2694, -0.0874, -0.1466, -0.0487, -0.5389, -0.3874],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.feed_forward.encoder_0.bias_hh_l0': tensor([ 1.5241e-01, -1.3368e-01,  8.6753e-02, -1.8053e-01, -2.2335e-01,\n",
       "          2.4501e-02, -2.3609e-01, -3.1448e-01,  1.7831e-01, -2.7506e-01,\n",
       "         -8.1806e-02, -1.1723e-01, -7.5104e-02, -5.6408e-02, -5.4949e-02,\n",
       "         -1.5997e-01, -4.2318e-01, -3.5121e-01,  6.0820e-02, -2.2279e-02,\n",
       "          1.7549e-01, -3.3256e-01,  5.2734e-02, -5.1653e-02, -2.6490e-01,\n",
       "         -2.8028e-01, -2.2079e-02, -1.9640e-01, -2.5445e-01, -1.2109e-02,\n",
       "         -1.7484e-01, -1.3079e-01,  1.5722e-01,  4.3039e-02,  1.4811e-01,\n",
       "         -8.7992e-02, -1.6522e-01, -1.8685e-01, -3.1695e-01,  1.0768e-01,\n",
       "         -8.9756e-02, -3.4028e-01, -4.3794e-01, -2.3777e-01,  4.7696e-02,\n",
       "         -1.2717e-01, -1.0252e-01, -9.4825e-02, -3.5692e-01, -2.8394e-01,\n",
       "         -9.5402e-02, -2.9152e-01, -6.7360e-02, -2.6848e-01, -1.9788e-01,\n",
       "         -5.2444e-03, -2.5625e-01, -2.0827e-02, -4.8255e-02, -2.1495e-01,\n",
       "         -1.4321e-01,  7.2378e-02, -8.4387e-02, -9.1533e-02, -1.7686e-01,\n",
       "         -4.5217e-01, -5.3200e-01, -1.1552e-01, -2.0472e-01, -1.6138e-01,\n",
       "         -1.3861e-01, -3.4368e-01,  1.8010e-01, -2.9983e-01, -3.5896e-01,\n",
       "         -2.9869e-01, -3.9643e-02,  4.1249e-02, -2.5459e-01, -6.8472e-03,\n",
       "         -3.6128e-01, -1.3029e-01, -2.0157e-01, -1.9924e-01, -1.3988e-01,\n",
       "         -2.7580e-01, -2.5757e-01, -1.0299e-01, -2.5114e-01, -3.2018e-01,\n",
       "         -3.4155e-01, -1.0871e-01, -2.7310e-01, -8.3347e-02, -9.7189e-03,\n",
       "          1.5333e-01, -4.8673e-02, -3.0838e-01, -3.9798e-01, -5.0321e-01,\n",
       "         -7.7197e-02,  4.6699e-03,  6.5387e-02, -2.0083e-01, -1.4176e-01,\n",
       "         -2.5939e-01,  1.8954e-01,  4.8569e-03,  9.6720e-03, -3.6195e-02,\n",
       "          1.7869e-01,  3.3417e-01, -8.1653e-04,  3.4186e-01,  5.9255e-02,\n",
       "         -1.1457e-01,  8.3173e-02, -1.3001e-01,  1.1867e-01, -1.5853e-02,\n",
       "         -3.3297e-02,  4.3599e-02, -1.3417e-01,  3.5817e-02, -3.7218e-01,\n",
       "          1.6385e-02, -7.0538e-02, -3.0918e-02, -1.4425e-01,  3.1273e-01,\n",
       "         -6.4080e-02,  5.8280e-02,  2.6362e-02, -2.4996e-02,  1.2705e-01,\n",
       "         -2.0801e-02, -9.2458e-02, -6.4326e-02, -2.1307e-01, -4.1960e-02,\n",
       "          1.6067e-01,  4.2487e-03,  1.2423e-01, -2.6689e-02,  3.7960e-02,\n",
       "          1.6119e-01, -4.2340e-02,  9.3576e-03,  2.1689e-01,  5.5730e-02,\n",
       "         -2.9613e-02, -1.7212e-01,  4.6966e-02, -2.5343e-02, -3.6511e-01,\n",
       "         -1.0029e-01, -3.2076e-02, -2.5037e-01, -7.9989e-03,  4.8489e-02,\n",
       "         -2.3340e-01, -1.1105e-01, -4.2666e-01, -2.3507e-01, -5.3806e-02,\n",
       "         -2.4837e-01, -2.6065e-01, -1.1260e-01, -2.0853e-01, -3.0031e-01,\n",
       "          1.1967e-01, -1.8891e-01, -5.6226e-02, -3.0602e-02, -2.6271e-01,\n",
       "         -3.6249e-01, -2.2570e-01, -2.1607e-01, -1.9104e-01, -5.3276e-02,\n",
       "         -3.1021e-01, -1.3644e-02, -3.9085e-01, -1.2993e-01, -3.9620e-02,\n",
       "          1.1516e-01, -3.6354e-04, -1.8410e-02, -2.7726e-01,  1.6887e-01,\n",
       "         -6.4901e-02, -4.5996e-01, -1.0555e-01, -2.4249e-01, -2.4417e-01,\n",
       "         -2.0581e-01, -3.3186e-02, -8.2971e-02, -4.0641e-01, -3.7894e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.feed_forward.encoder_1.weight_ih_l0': tensor([[-0.2814, -0.0443, -0.2834,  ...,  0.0928,  0.0604, -0.1997],\n",
       "         [ 0.1022,  0.0298,  0.0462,  ..., -0.3344, -0.0042, -0.1779],\n",
       "         [ 0.3784, -0.0326, -0.0396,  ...,  0.1399, -0.0276, -0.1921],\n",
       "         ...,\n",
       "         [-0.2744,  0.4513,  0.0750,  ...,  0.0410, -0.0341, -0.0753],\n",
       "         [-0.0187, -0.0057,  0.2545,  ...,  0.1397,  0.0797, -0.3578],\n",
       "         [-0.1009, -0.0144, -0.3012,  ..., -0.0936, -0.0877, -0.3027]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.feed_forward.encoder_1.weight_hh_l0': tensor([[-0.0415, -0.2985, -0.2657,  ..., -0.3166,  0.0269, -0.0222],\n",
       "         [ 0.0076, -0.0906,  0.1501,  ..., -0.0856, -0.0582, -0.0917],\n",
       "         [ 0.0442, -0.0234, -0.2899,  ...,  0.2044, -0.0435, -0.3196],\n",
       "         ...,\n",
       "         [ 0.0608, -0.0440, -0.1119,  ...,  0.2276, -0.0503, -0.0607],\n",
       "         [ 0.1546,  0.1409, -0.0469,  ..., -0.2000,  0.3036, -0.1398],\n",
       "         [-0.0956, -0.0473, -0.0355,  ..., -0.0641, -0.0923, -0.2916]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.feed_forward.encoder_1.bias_ih_l0': tensor([ 5.1556e-02, -1.1769e-01, -2.1514e-01, -8.1784e-02, -1.4399e-01,\n",
       "         -3.4948e-02,  7.3571e-02, -4.3952e-01, -1.4540e-01, -2.6311e-02,\n",
       "          1.7068e-02, -3.9446e-01, -3.4271e-01, -2.0956e-01, -1.6704e-01,\n",
       "         -2.6178e-01, -9.8510e-02,  1.7438e-01, -2.0052e-01, -2.6700e-01,\n",
       "          7.7324e-02, -4.0844e-04, -4.3964e-01, -7.9359e-02, -1.4252e-01,\n",
       "         -1.1260e-01,  2.9520e-02, -3.4000e-01, -4.0138e-01, -1.9575e-01,\n",
       "          1.3506e-01,  5.4733e-03, -4.9125e-02, -3.3612e-01, -1.1742e-01,\n",
       "         -1.1852e-01,  2.0131e-01,  2.9646e-02, -2.9343e-01, -1.9550e-01,\n",
       "         -4.9297e-02,  9.2848e-02, -2.2598e-01,  2.0482e-01, -1.6498e-01,\n",
       "         -5.5999e-02, -6.9785e-02, -3.4286e-01, -1.6706e-01, -3.1216e-01,\n",
       "         -1.2172e-01, -1.5126e-01, -1.9703e-01, -1.8250e-01, -2.7359e-01,\n",
       "          1.6948e-01,  1.3293e-01, -4.0629e-01, -1.9979e-01,  2.7030e-02,\n",
       "         -2.8527e-01, -9.6070e-02, -3.5519e-01, -2.3276e-01, -8.9021e-02,\n",
       "         -4.2616e-02, -2.3700e-01, -2.2324e-02, -9.4156e-02, -5.9560e-02,\n",
       "         -5.7814e-02, -1.6781e-01, -2.1870e-01, -8.2711e-02, -3.4556e-02,\n",
       "         -1.6781e-01,  1.2706e-01, -2.5835e-01, -3.3920e-01, -3.4382e-01,\n",
       "         -3.1749e-01,  2.6089e-01, -1.6878e-01, -2.2021e-01,  2.3310e-01,\n",
       "         -1.0757e-01, -3.5044e-02, -2.1615e-01, -1.3576e-01, -3.2859e-01,\n",
       "         -1.7528e-01, -2.3970e-01, -1.2153e-01,  2.9873e-02, -2.1498e-02,\n",
       "         -5.5596e-02, -2.7533e-01, -1.6076e-01, -3.3783e-01, -1.9255e-01,\n",
       "         -1.3048e-01, -1.0051e-01, -1.8849e-02,  4.7258e-02,  6.3649e-02,\n",
       "         -1.1347e-01,  7.8581e-02, -1.9046e-02,  8.3388e-03,  2.0603e-01,\n",
       "         -1.3733e-01, -1.4179e-01, -1.1646e-01, -5.8918e-02,  8.8727e-02,\n",
       "          1.5692e-03, -8.1354e-02, -5.3374e-02,  1.4179e-01, -1.4494e-01,\n",
       "         -7.2348e-03,  1.1260e-01, -1.7283e-01,  9.6844e-02,  1.3547e-01,\n",
       "          6.2087e-02,  1.0485e-01, -2.5714e-02, -9.5809e-02,  3.9456e-02,\n",
       "          6.0800e-02,  1.0871e-01, -7.0100e-02, -7.4366e-03, -5.6101e-02,\n",
       "          2.6313e-01, -1.4804e-01, -6.3229e-02,  4.7813e-02,  5.8324e-02,\n",
       "          2.3363e-01, -1.0819e-01, -1.5444e-01,  1.5581e-01,  1.3196e-01,\n",
       "         -6.6459e-02,  1.0828e-01,  2.3956e-02,  9.4347e-02, -3.1299e-02,\n",
       "         -1.9907e-01, -5.2825e-02, -2.2652e-01, -1.6568e-01, -1.4899e-02,\n",
       "          4.2740e-03,  5.9903e-02, -5.2266e-01, -1.0064e-02, -3.1950e-02,\n",
       "          3.4724e-02, -6.5587e-02, -4.2365e-01, -1.0850e-01, -6.6091e-02,\n",
       "         -3.0458e-01, -1.8122e-01,  1.5277e-01, -2.2471e-01, -1.2220e-01,\n",
       "         -2.3916e-01, -1.5923e-01, -3.0722e-01,  5.3914e-02, -1.7627e-01,\n",
       "         -2.1409e-01, -5.2018e-02, -6.0521e-01, -2.9786e-01, -1.4067e-01,\n",
       "         -4.2508e-03,  5.3193e-02, -2.5094e-01, -2.3789e-02, -2.4467e-02,\n",
       "         -2.4986e-01,  1.7012e-01, -1.0184e-01, -5.3111e-01, -8.5762e-02,\n",
       "         -8.4466e-02,  1.6321e-01, -1.2823e-01,  3.8597e-02, -3.2779e-01,\n",
       "         -9.4613e-02, -6.3955e-02, -8.4179e-02, -2.1611e-01, -3.5935e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.feed_forward.encoder_1.bias_hh_l0': tensor([-1.8293e-01, -3.0358e-01, -3.1810e-01, -2.5302e-01, -9.0123e-02,\n",
       "         -1.7517e-02,  1.0228e-01, -5.1742e-01, -3.2565e-02,  8.7728e-02,\n",
       "         -2.0438e-01, -4.5782e-01, -3.2840e-01, -1.4224e-01, -7.3386e-02,\n",
       "         -2.3488e-01, -1.4537e-01, -4.2575e-02, -1.2399e-01, -1.9793e-01,\n",
       "         -9.9631e-02, -1.3595e-01, -4.3886e-01, -6.6673e-02, -2.3184e-01,\n",
       "          1.1179e-03, -9.2959e-02, -2.7624e-01, -2.4305e-01, -1.2859e-01,\n",
       "          1.9909e-01, -2.0132e-01, -1.6406e-01, -1.3937e-01, -1.3537e-01,\n",
       "         -1.5673e-01,  2.5024e-01, -5.9005e-02, -1.5681e-01, -2.5661e-01,\n",
       "         -2.1290e-01,  7.0800e-02, -7.8388e-03,  7.8430e-02, -6.1346e-02,\n",
       "          3.5391e-02,  4.5724e-03, -3.5694e-01, -3.2908e-01, -2.8179e-01,\n",
       "         -9.3834e-02, -3.9045e-02, -2.1533e-01, -3.5333e-01, -2.5206e-01,\n",
       "          2.2349e-01,  1.0712e-01, -2.8448e-01, -3.5960e-01, -1.7619e-01,\n",
       "         -3.0084e-01, -1.3211e-02, -2.6432e-01, -2.9217e-01, -3.5029e-02,\n",
       "          2.8775e-03, -3.3832e-01,  4.2615e-02, -1.6823e-01,  6.6402e-02,\n",
       "         -1.9444e-01, -6.8519e-02, -3.3272e-01, -1.4336e-01, -1.1542e-01,\n",
       "         -8.1711e-02, -2.4685e-02, -2.4462e-01, -3.3245e-01, -2.4274e-01,\n",
       "         -4.3318e-01,  9.7249e-02, -1.4506e-02, -3.6636e-01,  3.0810e-01,\n",
       "         -1.7548e-01, -1.0764e-01, -2.7638e-01, -2.4732e-01, -3.1355e-01,\n",
       "         -2.3875e-01, -2.2968e-01, -1.7968e-01,  1.7870e-01, -1.2057e-01,\n",
       "          3.9100e-02, -2.7049e-01, -2.6704e-01, -2.8724e-01, -8.1759e-02,\n",
       "          1.0694e-01,  1.2618e-02,  1.4637e-01, -2.0195e-02,  6.5450e-02,\n",
       "          1.8485e-02,  2.5672e-01, -1.5624e-01, -4.9142e-02,  2.2501e-01,\n",
       "         -5.4766e-02, -9.3147e-02, -1.3749e-01,  6.7795e-02,  8.2330e-02,\n",
       "         -8.5157e-02, -7.1316e-02, -1.1409e-02,  1.9311e-01,  4.6484e-02,\n",
       "          3.9406e-02, -5.8000e-02, -2.7859e-02,  1.4926e-01,  5.3660e-02,\n",
       "          1.4126e-01,  1.2756e-01, -6.1601e-02, -1.6658e-01, -1.8235e-02,\n",
       "         -3.6722e-03,  6.5353e-02,  1.1787e-01, -2.8960e-02,  4.0309e-03,\n",
       "          2.3926e-01, -5.2841e-03,  1.0916e-01, -4.5606e-02, -1.7259e-02,\n",
       "          1.7986e-01, -1.3368e-01,  2.7571e-02,  1.8502e-01, -6.9416e-03,\n",
       "         -9.8068e-02,  1.9402e-01,  5.6969e-02,  7.6131e-02,  1.3112e-01,\n",
       "         -6.5432e-02, -1.4844e-01, -1.5200e-01, -4.3250e-05, -2.2919e-01,\n",
       "          9.8689e-02, -7.4695e-03, -4.4794e-01, -9.0060e-02, -1.0329e-01,\n",
       "         -1.4946e-01, -5.1997e-02, -3.6643e-01, -6.3640e-02, -1.3762e-01,\n",
       "         -2.3820e-01, -1.2482e-01, -8.4395e-02, -3.0000e-01, -1.1377e-01,\n",
       "         -2.0851e-01, -2.0951e-01, -1.2177e-01, -9.6347e-02, -1.0525e-01,\n",
       "         -2.2549e-01, -1.0545e-01, -4.2430e-01, -3.1757e-01, -3.2832e-01,\n",
       "          1.0375e-01,  5.0384e-02, -3.6204e-01, -8.0004e-02, -6.3372e-03,\n",
       "         -2.5822e-01,  4.0354e-02, -1.2421e-01, -3.7263e-01, -3.1867e-02,\n",
       "         -1.1137e-01,  2.8141e-01, -1.1066e-01, -6.6742e-02, -1.0662e-01,\n",
       "         -1.9961e-01, -1.4108e-01, -7.5458e-02, -5.5664e-02, -2.3043e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.feed_forward.encoder_2.weight_ih_l0': tensor([[ 0.2652, -0.1937, -0.0449,  ..., -0.1846,  0.0054, -0.0677],\n",
       "         [-0.0373,  0.0621, -0.1504,  ...,  0.0367,  0.2801,  0.0866],\n",
       "         [ 0.1968, -0.0027, -0.1323,  ...,  0.0360,  0.2154,  0.0809],\n",
       "         ...,\n",
       "         [ 0.2128,  0.0848, -0.0112,  ...,  0.0010, -0.0493, -0.1279],\n",
       "         [ 0.0456, -0.0814,  0.5429,  ...,  0.1649,  0.1162, -0.0434],\n",
       "         [ 0.0609, -0.0823,  0.0337,  ..., -0.0284, -0.2348, -0.1323]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.feed_forward.encoder_2.weight_hh_l0': tensor([[ 0.0916,  0.0679,  0.1612,  ..., -0.2903,  0.0132,  0.0352],\n",
       "         [-0.2105,  0.1996, -0.3875,  ..., -0.0833,  0.2500,  0.0795],\n",
       "         [-0.0387, -0.0389, -0.0635,  ..., -0.0508, -0.0920,  0.0712],\n",
       "         ...,\n",
       "         [-0.1863, -0.0804, -0.0608,  ...,  0.2614,  0.1194, -0.1164],\n",
       "         [ 0.3079, -0.5101,  0.1800,  ..., -0.2252, -0.1009,  0.0190],\n",
       "         [ 0.0878, -0.1215, -0.1151,  ...,  0.1975, -0.0599, -0.1453]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.feed_forward.encoder_2.bias_ih_l0': tensor([ 0.2265, -0.1068,  0.0075, -0.0431, -0.0963, -0.2177, -0.2677,  0.0059,\n",
       "         -0.1309, -0.0525, -0.1248, -0.1780, -0.0094, -0.5280, -0.1309,  0.2285,\n",
       "         -0.0242, -0.0190, -0.1274, -0.1807, -0.1895, -0.1757, -0.1003, -0.1175,\n",
       "         -0.6057, -0.0995, -0.2641, -0.1361, -0.2289, -0.1368,  0.0079,  0.1649,\n",
       "          0.0317,  0.0454,  0.0220, -0.1385,  0.0665,  0.1704, -0.2688,  0.0054,\n",
       "         -0.1122, -0.3049, -0.1113, -0.3714,  0.0568,  0.1420,  0.0530, -0.0010,\n",
       "         -0.1732, -0.0206,  0.3048,  0.3423,  0.0850, -0.2913, -0.1741, -0.1205,\n",
       "         -0.3979, -0.0214, -0.2129, -0.0635, -0.3539,  0.0607, -0.4287, -0.1636,\n",
       "         -0.5176, -0.3011,  0.1245,  0.0385, -0.3783, -0.2142, -0.3228, -0.0721,\n",
       "         -0.1908, -0.0593, -0.2530, -0.1933,  0.3036,  0.1529, -0.1722, -0.3311,\n",
       "         -0.0751, -0.0236,  0.0873, -0.0031, -0.0886, -0.2099, -0.2562,  0.0124,\n",
       "         -0.2246, -0.0660,  0.0774, -0.0389, -0.2745, -0.0708,  0.1001, -0.3881,\n",
       "          0.0218,  0.0288, -0.1046, -0.1609,  0.2524,  0.1646,  0.0343,  0.0681,\n",
       "          0.0847,  0.1022, -0.1690, -0.0496,  0.0009, -0.1302,  0.0088,  0.1032,\n",
       "          0.0403,  0.0331, -0.0639,  0.1494,  0.0539, -0.0584,  0.1019, -0.0049,\n",
       "         -0.2282, -0.0148, -0.0600, -0.1622, -0.0403, -0.1004,  0.0188,  0.0930,\n",
       "          0.0299,  0.2127,  0.0239,  0.0224, -0.1266,  0.0603, -0.0970, -0.1179,\n",
       "         -0.0246,  0.1555, -0.1449, -0.0425, -0.0290, -0.1371, -0.0637,  0.0129,\n",
       "          0.0778,  0.1017, -0.2475, -0.1462,  0.2101, -0.0187,  0.0965,  0.1564,\n",
       "          0.1343, -0.3373, -0.0184, -0.2165, -0.2219, -0.2961, -0.0565, -0.2571,\n",
       "          0.0182, -0.3828,  0.1367, -0.1559, -0.1337,  0.0737, -0.2570, -0.0120,\n",
       "         -0.0020, -0.1020, -0.1262,  0.0060, -0.2068, -0.1261, -0.2461, -0.2689,\n",
       "         -0.2376,  0.0387, -0.1489,  0.0786,  0.1210, -0.0875, -0.0841, -0.2641,\n",
       "         -0.2612, -0.2121,  0.0385, -0.0647, -0.1232, -0.2440, -0.1511, -0.2453,\n",
       "         -0.1250, -0.4080, -0.4062,  0.1618,  0.1775, -0.3388, -0.1056, -0.0456],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.feed_forward.encoder_2.bias_hh_l0': tensor([ 0.1125,  0.1287, -0.0104, -0.0188, -0.0605, -0.2425, -0.1642, -0.1896,\n",
       "         -0.1000, -0.2430, -0.2021, -0.2983,  0.0105, -0.4848, -0.1922,  0.3127,\n",
       "         -0.0399, -0.0849, -0.2818, -0.1220, -0.1850, -0.2115, -0.2163, -0.1785,\n",
       "         -0.4962, -0.1884, -0.2006, -0.2196, -0.1558,  0.0582, -0.0567,  0.0556,\n",
       "          0.0392, -0.2139, -0.0287, -0.1207,  0.0363, -0.0145, -0.2714,  0.0622,\n",
       "          0.0008, -0.3288, -0.1710, -0.1846, -0.1665,  0.1311,  0.2155, -0.0393,\n",
       "         -0.2608, -0.1615,  0.0852,  0.1170, -0.1276, -0.1521, -0.2416, -0.2051,\n",
       "         -0.4235, -0.0141, -0.2187, -0.0980, -0.3505,  0.0825, -0.3900, -0.3775,\n",
       "         -0.3065, -0.4065,  0.1149,  0.1199, -0.2569, -0.2128, -0.3857, -0.2937,\n",
       "         -0.1326, -0.1960, -0.2408, -0.2987,  0.2102, -0.0223,  0.0075, -0.1940,\n",
       "          0.0023, -0.1878,  0.1832,  0.0070,  0.0412, -0.3197, -0.0818, -0.0604,\n",
       "         -0.1386, -0.2424, -0.0767, -0.1281, -0.1021, -0.1360, -0.0476, -0.3176,\n",
       "         -0.0434,  0.0821, -0.1332, -0.1217,  0.2214,  0.1755, -0.1765,  0.1559,\n",
       "         -0.0890, -0.1646,  0.0389,  0.1311,  0.1065,  0.1343, -0.0107,  0.1210,\n",
       "          0.1987, -0.0503,  0.1505,  0.2126,  0.2061,  0.0177, -0.0490,  0.1768,\n",
       "         -0.1241,  0.0523, -0.0928,  0.0660,  0.0044,  0.0521, -0.0076,  0.1659,\n",
       "         -0.1586,  0.1491, -0.0132, -0.1460,  0.1062,  0.1113, -0.2633,  0.0834,\n",
       "          0.0361,  0.2231, -0.1272,  0.0375, -0.0431, -0.0123,  0.1000, -0.1530,\n",
       "          0.0750,  0.1012, -0.2532, -0.2181,  0.0411, -0.1143,  0.1551,  0.1930,\n",
       "          0.0921, -0.2168, -0.0440, -0.0926, -0.0866, -0.1469, -0.1827, -0.2122,\n",
       "         -0.0693, -0.3413,  0.1378, -0.2355, -0.1649,  0.2047, -0.0958,  0.1217,\n",
       "         -0.0011, -0.1097, -0.2597, -0.0571, -0.1884, -0.0512, -0.1475, -0.1151,\n",
       "         -0.2899, -0.2036, -0.0476,  0.1844, -0.0321, -0.1730, -0.0352, -0.2440,\n",
       "         -0.4447, -0.3455,  0.0834,  0.0411, -0.0638, -0.1548, -0.0602, -0.3652,\n",
       "         -0.0563, -0.2126, -0.3106,  0.0906, -0.0204, -0.3080,  0.1164, -0.2817],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.sublayer.0.norm.a_2': tensor([0.8209, 1.0594, 0.8927, 0.6029, 0.9091, 0.9286, 0.8041, 0.9061, 0.7523,\n",
       "         1.2473, 0.6830, 0.8665, 0.5889, 0.7257, 1.1669, 0.8478, 0.8182, 1.0924,\n",
       "         1.0216, 0.8542, 0.9723, 0.8826, 0.6730, 0.8897, 1.1829, 0.7584, 1.0248,\n",
       "         0.8519, 1.1217, 1.1140, 0.8150, 1.0783, 1.0102, 1.0552, 0.7005, 1.0955,\n",
       "         0.7950, 1.0123, 0.8122, 0.7929, 1.1812, 1.0445, 0.6477, 0.7880, 0.8585,\n",
       "         1.0291, 0.6667, 0.8412, 0.9810, 0.9957], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.sublayer.0.norm.b_2': tensor([-0.0048,  0.1111, -0.2016,  0.1368, -0.0881,  0.0497,  0.0279, -0.0029,\n",
       "          0.1478, -0.1106,  0.0046, -0.0797,  0.0227,  0.1375, -0.0637,  0.1738,\n",
       "         -0.1831,  0.0976,  0.2323, -0.4072,  0.0619, -0.0224, -0.0943,  0.2743,\n",
       "         -0.0049, -0.1677, -0.0237, -0.1542,  0.0363, -0.0711, -0.0940,  0.1376,\n",
       "         -0.0611,  0.2308, -0.1395,  0.0893, -0.1269, -0.0196,  0.1047, -0.0596,\n",
       "          0.1051,  0.0645, -0.1591,  0.2001, -0.0824,  0.1527, -0.2024, -0.0310,\n",
       "          0.1580, -0.2004], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.sublayer.1.norm.a_2': tensor([0.9897, 0.8599, 1.3241, 1.2804, 1.0750, 1.2145, 1.2320, 0.4925, 0.4716,\n",
       "         1.1950, 0.9036, 1.0037, 0.4981, 0.5103, 1.1062, 0.9303, 0.6469, 0.7863,\n",
       "         0.9878, 0.8655, 1.1004, 0.5556, 0.6732, 0.5773, 0.7499, 1.1368, 0.7532,\n",
       "         1.0930, 1.1249, 0.9709, 0.5755, 0.9246, 1.0197, 1.1201, 0.9954, 1.0658,\n",
       "         0.6333, 1.4268, 1.0216, 0.9003, 1.2261, 0.9381, 0.8095, 0.8277, 1.2097,\n",
       "         1.1489, 0.5626, 0.9018, 1.0432, 1.2081], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.1.sublayer.1.norm.b_2': tensor([ 0.1328,  0.0031,  0.0502,  0.0281,  0.1732,  0.1017, -0.2804,  0.0817,\n",
       "          0.1326,  0.1329,  0.1031,  0.0502, -0.0180,  0.0744, -0.0029, -0.1977,\n",
       "          0.2039,  0.0480, -0.0221,  0.0208,  0.0025, -0.0114,  0.0599, -0.0364,\n",
       "          0.0677, -0.0777,  0.0057,  0.0870, -0.2138,  0.0900, -0.0403,  0.1525,\n",
       "         -0.0682, -0.2042, -0.1080,  0.1171, -0.0807, -0.0609,  0.0789, -0.0417,\n",
       "         -0.1466, -0.0624,  0.0741,  0.0530, -0.0185, -0.0262,  0.1283, -0.0065,\n",
       "         -0.1699,  0.2564], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.self_attn.linears.0.weight': tensor([[-0.1205, -0.0744, -0.1473,  ..., -0.2967, -0.3194,  0.1124],\n",
       "         [ 0.0211,  0.0338,  0.0311,  ..., -0.1480,  0.1054,  0.1550],\n",
       "         [-0.1064, -0.1436, -0.0985,  ...,  0.2592, -0.0394,  0.2040],\n",
       "         ...,\n",
       "         [ 0.1021, -0.0383, -0.1335,  ..., -0.1159,  0.0090,  0.0039],\n",
       "         [ 0.0685,  0.0154, -0.2353,  ..., -0.1656, -0.2771,  0.2427],\n",
       "         [-0.0813,  0.0957,  0.0010,  ..., -0.1531, -0.1244,  0.1818]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.self_attn.linears.0.bias': tensor([-2.3453e-01, -3.3061e-01,  1.7340e-01, -1.6852e-01, -5.8871e-01,\n",
       "         -2.1147e-01, -3.2423e-03, -1.9302e-01, -1.0750e-01,  2.2972e-01,\n",
       "          4.3327e-01, -2.9507e-01, -2.1362e-01, -2.1662e-01, -3.2282e-01,\n",
       "         -1.6093e-01, -3.9274e-01,  3.5714e-01,  4.0746e-01,  4.2051e-02,\n",
       "         -1.0459e-01, -2.2547e-01,  1.6858e-01, -3.9366e-01, -1.2736e-01,\n",
       "          4.0932e-01, -3.1850e-02,  2.3049e-01,  4.8466e-02,  2.6652e-01,\n",
       "          7.8061e-03,  9.8698e-02, -4.2228e-01, -2.2002e-01, -2.3141e-01,\n",
       "          3.1131e-01, -2.5256e-01,  4.0169e-01,  4.7079e-04,  4.2877e-02,\n",
       "          6.0788e-01, -5.6296e-01, -2.9730e-01, -7.4917e-02,  4.4998e-01,\n",
       "         -4.0644e-01,  1.1341e-01,  4.0736e-01, -4.6143e-02, -1.9204e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.self_attn.linears.1.weight': tensor([[-3.1691e-02, -1.7824e-01,  1.3474e-01,  ..., -2.5013e-01,\n",
       "          -8.8708e-02, -1.1039e-01],\n",
       "         [-2.7606e-02, -1.0475e-01,  1.2257e-01,  ..., -8.9021e-02,\n",
       "           2.5803e-02,  2.0282e-02],\n",
       "         [-2.7298e-01, -3.7310e-01, -2.9838e-01,  ..., -2.7588e-01,\n",
       "           5.5482e-04,  5.8170e-01],\n",
       "         ...,\n",
       "         [-1.6331e-01,  2.0995e-02,  1.5307e-01,  ..., -2.9849e-01,\n",
       "          -1.0737e-01,  2.6269e-01],\n",
       "         [ 2.0006e-01, -8.9075e-02, -1.0187e-01,  ...,  4.6198e-02,\n",
       "           6.7354e-02,  2.8172e-01],\n",
       "         [ 2.3853e-01, -1.6884e-01,  1.8960e-01,  ...,  1.4917e-01,\n",
       "          -4.8906e-02, -1.0070e-01]], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.self_attn.linears.1.bias': tensor([-0.0789, -0.1411, -0.0460, -0.0866,  0.0874, -0.0903,  0.0955, -0.1204,\n",
       "         -0.0193, -0.1312,  0.1102, -0.1048,  0.0410, -0.1079,  0.0975, -0.0970,\n",
       "          0.1302,  0.0401, -0.0026,  0.1350,  0.0527, -0.0560,  0.1290, -0.1341,\n",
       "          0.1307,  0.1356,  0.1026, -0.0706, -0.0911,  0.0842,  0.0821,  0.1341,\n",
       "         -0.1218, -0.0806, -0.1367,  0.1334,  0.0300,  0.1203, -0.0412, -0.1075,\n",
       "          0.1184,  0.0117, -0.0881,  0.0003,  0.1279, -0.0429, -0.0396,  0.0975,\n",
       "         -0.0364,  0.0842], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.self_attn.linears.2.weight': tensor([[-0.0462, -0.2354,  0.0863,  ..., -0.0732, -0.2060, -0.1216],\n",
       "         [-0.0039,  0.0085,  0.2072,  ..., -0.0784,  0.0783, -0.0154],\n",
       "         [-0.0147, -0.0768,  0.0178,  ..., -0.0196,  0.1317,  0.2295],\n",
       "         ...,\n",
       "         [ 0.0567,  0.0535, -0.0219,  ...,  0.0088,  0.0153,  0.0954],\n",
       "         [ 0.0839, -0.0266,  0.1449,  ...,  0.0285,  0.0916,  0.0280],\n",
       "         [-0.1486,  0.1152,  0.0577,  ...,  0.0066,  0.0490,  0.1005]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.self_attn.linears.2.bias': tensor([-0.0531, -0.0885, -0.1670, -0.0221,  0.0415, -0.1672,  0.0580, -0.0973,\n",
       "         -0.0252, -0.0690,  0.0893, -0.1726,  0.0243, -0.0675,  0.0468, -0.1010,\n",
       "          0.0365,  0.0659, -0.0514,  0.1808, -0.0904,  0.0311,  0.2058, -0.0394,\n",
       "          0.1203,  0.0855,  0.0774, -0.0444, -0.0006,  0.0884, -0.0015,  0.1824,\n",
       "         -0.0006,  0.0469, -0.1534,  0.0315, -0.0311, -0.0409, -0.0586, -0.1170,\n",
       "         -0.0031,  0.1099, -0.1148,  0.0157, -0.0131, -0.0071,  0.0401,  0.0405,\n",
       "          0.0441,  0.1296], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.self_attn.linears.3.weight': tensor([[-0.0686, -0.1137,  0.0724,  ..., -0.1159, -0.0819,  0.0083],\n",
       "         [ 0.0884,  0.1644,  0.0375,  ...,  0.0545,  0.1031, -0.0229],\n",
       "         [-0.1482, -0.0954,  0.0602,  ..., -0.1162,  0.0009,  0.0292],\n",
       "         ...,\n",
       "         [ 0.0976,  0.1141, -0.0930,  ...,  0.0114, -0.0847,  0.0521],\n",
       "         [-0.0728, -0.1521,  0.2255,  ...,  0.0584,  0.2063,  0.0584],\n",
       "         [-0.0939,  0.0063, -0.0864,  ..., -0.0878, -0.0332,  0.1109]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.self_attn.linears.3.bias': tensor([-0.1910, -0.4270, -0.0037,  0.0365,  0.1350, -0.1637,  0.3672, -0.2910,\n",
       "         -0.0569,  0.0463,  0.0884, -0.1609, -0.0337, -0.1691,  0.1122, -0.0999,\n",
       "          0.0735, -0.0959,  0.0213,  0.2729,  0.0860, -0.1080, -0.0726, -0.0973,\n",
       "          0.1802,  0.3275,  0.3691, -0.2795, -0.2859,  0.1697,  0.1548, -0.0783,\n",
       "         -0.3362, -0.1305, -0.0674,  0.0899,  0.1127, -0.1367, -0.1547, -0.0370,\n",
       "          0.0360, -0.2841, -0.0459,  0.0551,  0.2025, -0.1120,  0.0641,  0.0766,\n",
       "          0.4351,  0.1119], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.feed_forward.bn.weight': tensor([0.8324, 0.6961, 1.2164, 0.8915, 1.1823, 1.1257, 1.1671, 0.7271, 0.9102,\n",
       "         0.8728, 1.1218, 0.7567, 0.6784, 0.6249, 1.1045, 0.7930, 0.9869, 0.7766,\n",
       "         0.9285, 1.1595, 0.9524, 0.9018, 0.7686, 0.8426, 0.9753, 1.0906, 1.2048,\n",
       "         0.9403, 1.1736, 1.1290, 0.9819, 0.6454, 0.7668, 1.1415, 0.8544, 1.1336,\n",
       "         0.9630, 1.1512, 1.0021, 1.0021, 1.0536, 1.0300, 0.9354, 0.8254, 1.1427,\n",
       "         1.1204, 0.8577, 0.8215, 1.4886, 1.2331], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.feed_forward.bn.bias': tensor([-0.2487, -0.3276,  0.0934, -0.1181, -0.0467, -0.0844,  0.1358, -0.3191,\n",
       "         -0.1853, -0.1044,  0.1131, -0.2418, -0.3602, -0.2507, -0.2189, -0.1925,\n",
       "         -0.1414, -0.2689, -0.1942,  0.0118,  0.0157, -0.1460, -0.2924, -0.2392,\n",
       "         -0.1220, -0.1111,  0.1869, -0.2655, -0.1982,  0.0266,  0.0934, -0.4094,\n",
       "         -0.2185, -0.0317, -0.0982,  0.0705, -0.2316, -0.1625, -0.0771,  0.0188,\n",
       "         -0.1680, -0.1892, -0.2352, -0.2038,  0.0103, -0.0308, -0.2317, -0.1325,\n",
       "          0.2875,  0.1025], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.feed_forward.bn.running_mean': tensor([ 0.1164, -0.0270, -0.0736, -0.0077,  0.2348, -0.0066,  0.1937,  0.0946,\n",
       "          0.1181,  0.2075,  0.1039,  0.0013,  0.0257,  0.1072,  0.0737,  0.1005,\n",
       "          0.1656,  0.2195,  0.1445,  0.1855,  0.0405,  0.0090,  0.0958,  0.0426,\n",
       "          0.0975,  0.0744,  0.0181, -0.0322,  0.0488,  0.1404,  0.1027,  0.1033,\n",
       "         -0.0245,  0.0724,  0.0076,  0.2296,  0.0328,  0.0544,  0.0736,  0.0608,\n",
       "          0.0359, -0.0825, -0.0004,  0.0717,  0.0950, -0.0884,  0.0598,  0.1196,\n",
       "          0.1207,  0.2874], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.feed_forward.bn.running_var': tensor([0.1100, 0.0322, 0.1059, 0.0636, 0.1044, 0.1278, 0.1565, 0.0915, 0.0894,\n",
       "         0.1068, 0.0611, 0.1156, 0.0407, 0.0779, 0.0404, 0.0409, 0.0592, 0.0890,\n",
       "         0.0588, 0.0800, 0.0865, 0.0623, 0.0636, 0.0597, 0.0591, 0.0431, 0.0745,\n",
       "         0.0631, 0.0409, 0.0581, 0.0479, 0.1310, 0.0271, 0.0851, 0.0546, 0.1602,\n",
       "         0.0303, 0.0227, 0.0463, 0.0830, 0.0743, 0.0451, 0.0449, 0.0289, 0.0529,\n",
       "         0.1548, 0.0465, 0.0767, 0.0313, 0.0850], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.feed_forward.bn.num_batches_tracked': tensor(213030),\n",
       " 'transformer_pre.model.layers.2.feed_forward.encoder_0.weight_ih_l0': tensor([[ 0.0933, -0.0532,  0.0336,  ..., -0.0674, -0.1839,  0.1694],\n",
       "         [ 0.1236,  0.0394,  0.0108,  ..., -0.1117,  0.0934, -0.0560],\n",
       "         [ 0.3210,  0.0970, -0.1732,  ...,  0.0390,  0.0082, -0.1114],\n",
       "         ...,\n",
       "         [ 0.0078,  0.3355,  0.3205,  ...,  0.0042, -0.3018, -0.2391],\n",
       "         [ 0.0157,  0.1042,  0.0143,  ...,  0.1129, -0.0580, -0.2004],\n",
       "         [ 0.0321, -0.1356,  0.0771,  ..., -0.1831, -0.1907, -0.0694]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.feed_forward.encoder_0.weight_hh_l0': tensor([[-0.0985,  0.0024, -0.0178,  ...,  0.0049, -0.0711,  0.0248],\n",
       "         [ 0.0346, -0.0654, -0.0658,  ...,  0.1559,  0.3594, -0.0979],\n",
       "         [ 0.0525, -0.1286, -0.0247,  ...,  0.1834,  0.1159,  0.0332],\n",
       "         ...,\n",
       "         [ 0.1987,  0.0874, -0.0536,  ...,  0.0589,  0.0284, -0.2058],\n",
       "         [ 0.0604, -0.1877, -0.2751,  ..., -0.0658, -0.3024,  0.1718],\n",
       "         [ 0.0256, -0.0084, -0.0936,  ...,  0.1237,  0.0926, -0.3897]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.feed_forward.encoder_0.bias_ih_l0': tensor([ 2.8760e-02, -3.6948e-02,  1.5777e-02, -1.4360e-01,  1.3909e-02,\n",
       "         -4.8772e-02,  3.1433e-02,  1.0676e-01,  2.8353e-02, -5.9287e-02,\n",
       "          2.0221e-01, -3.9856e-02, -7.2340e-02,  1.5844e-02, -7.8838e-02,\n",
       "         -2.6985e-01, -7.5127e-02, -9.4317e-02, -4.5801e-02, -1.6900e-02,\n",
       "          3.2462e-01, -1.6771e-01, -2.6804e-01, -1.1830e-01, -1.7628e-01,\n",
       "          2.9878e-02, -2.1047e-01, -9.5814e-02,  1.6398e-01, -1.0914e-01,\n",
       "         -1.4954e-02, -4.5770e-02, -1.6645e-02, -1.7827e-01, -4.8012e-02,\n",
       "         -3.1210e-01, -2.2887e-01, -3.0259e-01, -1.8855e-01,  1.7634e-01,\n",
       "         -6.4981e-02, -9.6754e-02, -4.2315e-01, -1.1631e-01, -1.8804e-01,\n",
       "          5.4904e-02, -3.0607e-01, -3.4612e-01,  1.0544e-01, -2.9550e-02,\n",
       "         -2.2265e-02, -2.6527e-04, -4.6965e-02, -2.4927e-02, -2.8774e-01,\n",
       "         -4.3767e-02, -2.1980e-01, -7.1931e-02,  6.0452e-02, -2.1756e-01,\n",
       "         -1.3322e-01, -7.7990e-02, -6.0077e-02, -1.6227e-01, -2.3497e-01,\n",
       "         -1.9584e-01, -2.5862e-01, -8.5710e-02, -2.3948e-01, -2.4252e-01,\n",
       "         -4.2663e-01, -1.7870e-01,  7.5999e-02, -5.7127e-02, -2.0180e-01,\n",
       "         -3.1871e-02, -3.8378e-02, -4.7386e-02,  9.5911e-02,  1.8571e-02,\n",
       "         -1.5749e-01, -1.6815e-01, -9.7975e-02,  2.1520e-01, -4.3738e-02,\n",
       "         -3.3778e-01, -1.2286e-02, -3.9433e-01, -1.3780e-01, -6.8206e-02,\n",
       "         -1.2414e-01, -1.1589e-01, -2.7233e-01, -3.9863e-03, -1.6870e-01,\n",
       "         -1.4883e-01, -3.1596e-01, -3.4253e-01, -3.4931e-01, -2.5235e-01,\n",
       "          2.2796e-01,  1.9964e-02,  1.8811e-01, -8.0776e-02,  2.2213e-02,\n",
       "         -1.4863e-01,  1.1259e-01,  1.1962e-02,  1.1710e-01,  2.3327e-02,\n",
       "          9.8349e-02,  1.7768e-01,  1.4744e-02, -1.8390e-01,  2.4942e-01,\n",
       "          2.0677e-01,  5.9514e-02, -4.9582e-02, -1.1411e-01,  6.2382e-02,\n",
       "          1.8805e-01,  5.8512e-02, -1.0243e-01, -9.6142e-02, -9.3669e-02,\n",
       "          9.7837e-02, -2.5901e-01, -5.4489e-03, -1.1815e-01, -2.5323e-02,\n",
       "         -7.5662e-02,  6.4989e-02, -3.5838e-02,  5.0796e-02,  6.9153e-02,\n",
       "         -1.0912e-01,  7.2733e-02, -1.1322e-02, -1.5933e-01,  2.1673e-02,\n",
       "          1.9796e-01, -1.2956e-01, -2.1392e-03,  1.4514e-01, -2.2003e-02,\n",
       "         -8.1317e-02,  2.6164e-02,  7.9754e-02,  2.1701e-01,  1.6020e-01,\n",
       "          1.6169e-01, -2.0391e-01, -6.2182e-02, -5.5345e-02, -1.3451e-01,\n",
       "          2.9589e-01,  1.2116e-01,  6.4401e-03, -2.4968e-01, -1.9291e-01,\n",
       "         -1.6978e-01,  1.9694e-01, -1.2959e-01,  4.3926e-02, -9.4014e-02,\n",
       "         -4.3356e-02, -1.7326e-01, -3.0320e-02, -1.4320e-01, -8.9292e-02,\n",
       "          5.7608e-02, -1.5061e-01,  6.8215e-02,  7.3064e-02, -1.2030e-01,\n",
       "         -1.1048e-01, -6.7698e-02, -2.2077e-03, -8.1289e-02, -3.9399e-01,\n",
       "         -1.9098e-02, -1.9151e-02, -2.7580e-01, -4.0194e-02, -1.8255e-01,\n",
       "         -1.7949e-01,  6.1754e-02, -2.6626e-01, -1.3991e-01,  1.6276e-02,\n",
       "         -1.0430e-01, -9.9756e-02, -7.6763e-02, -1.5009e-02, -3.0677e-01,\n",
       "          2.0227e-01, -3.7029e-01, -7.8125e-02, -4.2634e-01,  1.4431e-02],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.feed_forward.encoder_0.bias_hh_l0': tensor([ 0.1843, -0.0238,  0.1403, -0.2481, -0.1305,  0.0742,  0.0280, -0.0138,\n",
       "          0.0719, -0.1370,  0.0904, -0.1197, -0.0056, -0.1630, -0.0639, -0.0541,\n",
       "         -0.0860, -0.0502, -0.0926,  0.1076,  0.3392, -0.1864, -0.1110, -0.1555,\n",
       "         -0.2805, -0.0572,  0.0199, -0.0628, -0.0523, -0.0327, -0.0345, -0.0733,\n",
       "          0.1085, -0.0340,  0.0774, -0.1245, -0.1992, -0.3732, -0.3533,  0.0910,\n",
       "         -0.1232, -0.2545, -0.4637, -0.0389, -0.0593,  0.1466, -0.2018, -0.1304,\n",
       "          0.0106,  0.0197, -0.1469,  0.0482, -0.0260, -0.1896, -0.2084,  0.0980,\n",
       "         -0.2733,  0.1169, -0.0893, -0.1560, -0.0901,  0.0866, -0.0979, -0.2249,\n",
       "         -0.3115, -0.3318, -0.3629, -0.0815, -0.2395, -0.1285, -0.3332, -0.2842,\n",
       "         -0.1036, -0.2725, -0.2474, -0.1866, -0.1964,  0.1489, -0.0695, -0.0134,\n",
       "         -0.0744,  0.0188, -0.3547,  0.0581, -0.2028, -0.4101, -0.2204, -0.2736,\n",
       "         -0.2950, -0.1660, -0.1157, -0.0832, -0.3110,  0.1508, -0.1110,  0.0537,\n",
       "         -0.3235, -0.3917, -0.4534, -0.3240, -0.0349,  0.0678,  0.0666, -0.1098,\n",
       "         -0.0386, -0.1208,  0.1740,  0.0384, -0.0649, -0.1123,  0.0867,  0.2159,\n",
       "          0.0347, -0.0165,  0.2415,  0.0467,  0.1585,  0.0049,  0.1528,  0.0778,\n",
       "         -0.0156,  0.0664,  0.0187,  0.0208, -0.2795, -0.0601, -0.1429, -0.0250,\n",
       "         -0.1392,  0.1716, -0.0371, -0.0272,  0.0518, -0.2164,  0.0688, -0.0245,\n",
       "          0.0637, -0.0148, -0.1576, -0.0347,  0.2257, -0.0006, -0.0560,  0.0557,\n",
       "          0.0269,  0.0159, -0.2325, -0.0538,  0.0947,  0.1788,  0.1736, -0.3178,\n",
       "          0.0083,  0.0293, -0.2384,  0.1427,  0.1120, -0.1217, -0.0675, -0.0348,\n",
       "         -0.1180,  0.0070, -0.2332, -0.0350, -0.0012, -0.1310, -0.2029, -0.1218,\n",
       "         -0.3526, -0.2158, -0.0669, -0.1386, -0.1215, -0.1230, -0.2004, -0.1898,\n",
       "         -0.0229, -0.1676, -0.0227, -0.1441, -0.0714, -0.0231, -0.3080, -0.2504,\n",
       "         -0.1732, -0.0216,  0.1384, -0.2896, -0.1934,  0.2179,  0.0189, -0.1979,\n",
       "         -0.1482, -0.1735, -0.2815,  0.0839, -0.2569, -0.1124, -0.2939,  0.0229],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.feed_forward.encoder_1.weight_ih_l0': tensor([[-0.1686, -0.1727, -0.2764,  ..., -0.1063,  0.0917,  0.0057],\n",
       "         [-0.0530,  0.1754, -0.2162,  ..., -0.1820, -0.1027, -0.0295],\n",
       "         [ 0.3782, -0.0174, -0.0977,  ...,  0.0892, -0.1403, -0.1160],\n",
       "         ...,\n",
       "         [-0.2572,  0.7502,  0.1151,  ..., -0.0037, -0.2125, -0.0023],\n",
       "         [ 0.0284,  0.0229,  0.2882,  ..., -0.0445,  0.5705, -0.2619],\n",
       "         [-0.0577, -0.0808, -0.4257,  ..., -0.2349, -0.1185, -0.2113]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.feed_forward.encoder_1.weight_hh_l0': tensor([[-0.0102,  0.0128, -0.0774,  ..., -0.1337, -0.0138,  0.0080],\n",
       "         [ 0.0756, -0.1029,  0.0824,  ..., -0.0322,  0.0093, -0.0188],\n",
       "         [-0.0439, -0.0431, -0.3456,  ...,  0.0200,  0.1073, -0.2486],\n",
       "         ...,\n",
       "         [ 0.1408, -0.0870,  0.0548,  ..., -0.1612,  0.0479, -0.0701],\n",
       "         [ 0.2212,  0.3712, -0.0799,  ...,  0.0445,  0.0272, -0.2574],\n",
       "         [ 0.0415,  0.0961, -0.1655,  ..., -0.2902, -0.1055, -0.5545]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.feed_forward.encoder_1.bias_ih_l0': tensor([ 0.2736, -0.0855, -0.1897, -0.2198, -0.0635,  0.0589,  0.0698, -0.0487,\n",
       "         -0.2053, -0.0436,  0.0297,  0.1443, -0.1825, -0.1137, -0.1818, -0.2582,\n",
       "          0.0043,  0.0384, -0.0348, -0.0248, -0.0490, -0.1430, -0.1144, -0.1445,\n",
       "         -0.2123, -0.1752,  0.1232, -0.1947, -0.4203, -0.0907, -0.1111,  0.0787,\n",
       "         -0.0195, -0.1181,  0.1433,  0.0447, -0.2125,  0.1778, -0.1553, -0.0601,\n",
       "          0.0428,  0.0902, -0.3349,  0.0113, -0.1079,  0.1865,  0.0415, -0.2936,\n",
       "         -0.1074, -0.3275,  0.0463, -0.3547, -0.3328, -0.1363, -0.3430,  0.0813,\n",
       "          0.0368, -0.1243, -0.1453, -0.1145, -0.2382, -0.0536, -0.4683, -0.3923,\n",
       "         -0.0688, -0.1758,  0.2485, -0.3712,  0.0820,  0.0914, -0.0700, -0.1680,\n",
       "         -0.0858, -0.1638, -0.0491, -0.0669,  0.2792, -0.0990, -0.2634, -0.2576,\n",
       "         -0.2772,  0.0097, -0.1320,  0.1111, -0.0638,  0.1356,  0.0043, -0.0597,\n",
       "         -0.0292, -0.0446,  0.0233, -0.2307, -0.1822, -0.1702, -0.1310, -0.3903,\n",
       "         -0.0176, -0.3146, -0.2588, -0.3039, -0.1258, -0.1188, -0.1367, -0.1276,\n",
       "          0.0256, -0.1457, -0.0415,  0.1155,  0.0542,  0.1712, -0.1527, -0.2329,\n",
       "         -0.1010,  0.0400,  0.0849, -0.0154,  0.0551,  0.0733,  0.1747, -0.2957,\n",
       "         -0.0625, -0.0467, -0.0412,  0.0806,  0.1623,  0.1524,  0.1466, -0.2078,\n",
       "         -0.1421,  0.0311,  0.0239,  0.1783, -0.1946, -0.0215,  0.1302,  0.2488,\n",
       "         -0.0906, -0.1845, -0.0193, -0.1225,  0.1614, -0.2852, -0.1645, -0.0941,\n",
       "          0.0888,  0.0011,  0.1798,  0.0854,  0.1292,  0.0156, -0.1792, -0.3812,\n",
       "         -0.2933, -0.2705, -0.0759,  0.0434, -0.1126, -0.2574,  0.0022,  0.0446,\n",
       "          0.1221,  0.2183, -0.2709, -0.1290, -0.1146, -0.2808, -0.0940, -0.0531,\n",
       "         -0.1005,  0.0206, -0.1929, -0.2560, -0.1412,  0.1197, -0.1365, -0.0866,\n",
       "         -0.0367, -0.4245, -0.2921,  0.0895, -0.2313,  0.0176, -0.1910,  0.0716,\n",
       "         -0.0902, -0.1240, -0.1890, -0.1663, -0.1713,  0.0728, -0.0347,  0.1609,\n",
       "         -0.2058, -0.3283, -0.2367,  0.2735, -0.0901, -0.2991, -0.3534, -0.2895],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.feed_forward.encoder_1.bias_hh_l0': tensor([ 0.0391, -0.2714, -0.2927, -0.3910, -0.0097,  0.0763,  0.0985, -0.1266,\n",
       "         -0.0925,  0.0705, -0.1918,  0.0810, -0.1682, -0.0464, -0.0882, -0.2313,\n",
       "         -0.0426, -0.1785,  0.0418,  0.0442, -0.2260, -0.2786, -0.1136, -0.1318,\n",
       "         -0.3016, -0.0615,  0.0007, -0.1309, -0.2620, -0.0235, -0.0470, -0.1281,\n",
       "         -0.1345,  0.0787,  0.1254,  0.0065, -0.1636,  0.0891, -0.0187, -0.1212,\n",
       "         -0.1208,  0.0681, -0.1168, -0.1150, -0.0043,  0.2779,  0.1158, -0.3077,\n",
       "         -0.2694, -0.2971,  0.0742, -0.2425, -0.3511, -0.3072, -0.3214,  0.1353,\n",
       "          0.0110, -0.0025, -0.3051, -0.3177, -0.2538,  0.0292, -0.3774, -0.4517,\n",
       "         -0.0148, -0.1303,  0.1472, -0.3063,  0.0080,  0.2174, -0.2067, -0.0687,\n",
       "         -0.1998, -0.2244, -0.1299,  0.0192,  0.1274, -0.0852, -0.2567, -0.1565,\n",
       "         -0.3929, -0.1540,  0.0223, -0.0351,  0.0112,  0.0677, -0.0683, -0.1199,\n",
       "         -0.1408, -0.0296, -0.0401, -0.2207, -0.2404, -0.0213, -0.2301, -0.2956,\n",
       "         -0.0128, -0.4209, -0.2082, -0.1931,  0.1116, -0.0056,  0.0285, -0.1950,\n",
       "          0.0274, -0.0138,  0.1366, -0.0217, -0.0033,  0.1902, -0.0701, -0.1843,\n",
       "         -0.1220,  0.1667,  0.0785, -0.1021,  0.0651,  0.1153,  0.2260, -0.1043,\n",
       "         -0.0158, -0.2173,  0.1037,  0.1330,  0.0805,  0.2316,  0.1693, -0.2436,\n",
       "         -0.2128, -0.0266, -0.0405,  0.1350, -0.0067, -0.0430,  0.1903,  0.2250,\n",
       "          0.0522, -0.0121, -0.1127, -0.1980,  0.1076, -0.3107,  0.0175, -0.0649,\n",
       "         -0.0501, -0.0305,  0.2656,  0.1184,  0.1110,  0.1780, -0.0455, -0.4768,\n",
       "         -0.2187, -0.1048, -0.2902,  0.1378, -0.1799, -0.1826, -0.0777, -0.0268,\n",
       "         -0.0621,  0.2318, -0.2137, -0.0842, -0.1861, -0.2144, -0.0376, -0.2903,\n",
       "         -0.1758,  0.0291, -0.1623, -0.3062,  0.0443, -0.0306, -0.0654, -0.0980,\n",
       "         -0.0902, -0.2436, -0.3118, -0.0982, -0.1233,  0.0148, -0.3021,  0.0154,\n",
       "         -0.0721, -0.1323, -0.3187, -0.1887, -0.0128,  0.1267, -0.0616,  0.2791,\n",
       "         -0.1882, -0.4337, -0.0156,  0.1685, -0.1673, -0.2903, -0.1930, -0.1606],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.feed_forward.encoder_2.weight_ih_l0': tensor([[-0.0722, -0.1260,  0.1048,  ...,  0.2636,  0.2327,  0.0471],\n",
       "         [ 0.1196,  0.3146, -0.2447,  ...,  0.1283,  0.2758, -0.3086],\n",
       "         [-0.1958, -0.0619, -0.1693,  ...,  0.0828, -0.0516,  0.2713],\n",
       "         ...,\n",
       "         [-0.1572, -0.1125,  0.0119,  ...,  0.1878, -0.0785,  0.0561],\n",
       "         [-0.3144, -0.1099,  0.1058,  ...,  0.1409,  0.1630, -0.1389],\n",
       "         [ 0.1092, -0.0499, -0.0637,  ..., -0.1361, -0.2518, -0.1583]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.feed_forward.encoder_2.weight_hh_l0': tensor([[ 0.0229,  0.0260,  0.2168,  ..., -0.1753,  0.0792,  0.0008],\n",
       "         [-0.1632, -0.0825,  0.0928,  ..., -0.0614, -0.1738, -0.0039],\n",
       "         [-0.1348, -0.0216, -0.5012,  ...,  0.0011,  0.2395, -0.0214],\n",
       "         ...,\n",
       "         [-0.1939,  0.0344, -0.0928,  ..., -0.0808, -0.0062,  0.2862],\n",
       "         [-0.0621, -0.2356,  0.2246,  ...,  0.1427, -0.3750,  0.1523],\n",
       "         [-0.0251,  0.2253,  0.1120,  ..., -0.1497, -0.1175, -0.3306]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.feed_forward.encoder_2.bias_ih_l0': tensor([ 0.0366, -0.1956, -0.0536,  0.0182,  0.1460, -0.0973, -0.0480,  0.0015,\n",
       "         -0.0935, -0.0210, -0.0697, -0.2201, -0.2431, -0.1456, -0.3193, -0.1055,\n",
       "         -0.2609,  0.0965, -0.1870, -0.2067, -0.0533, -0.2814,  0.0408,  0.0370,\n",
       "         -0.1727, -0.1353, -0.0860, -0.2233, -0.4254, -0.2211,  0.0560,  0.1501,\n",
       "         -0.0735,  0.0767,  0.0461,  0.0574, -0.1520,  0.0365, -0.3088,  0.1740,\n",
       "         -0.1531, -0.1494, -0.0945, -0.0582, -0.0457,  0.1705, -0.2193,  0.2201,\n",
       "         -0.1236,  0.1248,  0.1641,  0.0664,  0.0116, -0.2732, -0.1395,  0.0452,\n",
       "         -0.1509, -0.0849, -0.1339, -0.2277, -0.4152,  0.1182, -0.2702,  0.0649,\n",
       "         -0.3198, -0.0331,  0.0428,  0.0959, -0.3298, -0.2957, -0.2482, -0.1116,\n",
       "         -0.0990,  0.1043, -0.1238, -0.2011, -0.0878, -0.0807, -0.3115, -0.3661,\n",
       "         -0.1735,  0.0462, -0.1057, -0.0775, -0.1422,  0.3031, -0.1681, -0.2091,\n",
       "         -0.0666, -0.0058, -0.0682, -0.0084, -0.1359,  0.1470, -0.2134, -0.1150,\n",
       "          0.0129, -0.2622, -0.1852, -0.1671,  0.1498, -0.2290, -0.1116,  0.0871,\n",
       "          0.2086,  0.1670, -0.0250, -0.1188, -0.1146, -0.0967, -0.0978,  0.0179,\n",
       "         -0.1008,  0.0879, -0.0891,  0.0455, -0.0168,  0.0695, -0.0132, -0.0097,\n",
       "         -0.2557, -0.1033,  0.1169, -0.1582,  0.0320, -0.0876, -0.0285, -0.1286,\n",
       "          0.1128,  0.2268,  0.0093,  0.0949, -0.1849, -0.0064,  0.0116, -0.0038,\n",
       "         -0.0290,  0.0818, -0.0047,  0.0182, -0.1479, -0.1512, -0.0810,  0.1404,\n",
       "          0.0223,  0.2885, -0.0741,  0.0436,  0.1935,  0.0889, -0.0842, -0.0769,\n",
       "          0.1326, -0.2074,  0.0560, -0.2528, -0.1346, -0.1608, -0.0578, -0.1896,\n",
       "          0.1206, -0.3395,  0.0514, -0.0125, -0.3523, -0.0894, -0.2488,  0.0008,\n",
       "         -0.1689, -0.1428, -0.1377,  0.0234, -0.0317, -0.2454, -0.1099, -0.5090,\n",
       "         -0.1003, -0.1988, -0.2469, -0.1659,  0.0303,  0.0354, -0.3288, -0.1510,\n",
       "         -0.0284,  0.1433, -0.0840, -0.1179, -0.0753, -0.1984, -0.1333, -0.2543,\n",
       "         -0.1438, -0.2052, -0.2544,  0.0995, -0.0086,  0.0792, -0.2322, -0.0312],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.feed_forward.encoder_2.bias_hh_l0': tensor([-0.0774,  0.0400, -0.0715,  0.0426,  0.1818, -0.1220,  0.0555, -0.1940,\n",
       "         -0.0626, -0.2115, -0.1470, -0.3404, -0.2232, -0.1025, -0.3806, -0.0213,\n",
       "         -0.2766,  0.0305, -0.3414, -0.1480, -0.0488, -0.3173, -0.0751, -0.0240,\n",
       "         -0.0632, -0.2242, -0.0225, -0.3068, -0.3523, -0.0260, -0.0085,  0.0408,\n",
       "         -0.0660, -0.1825, -0.0046,  0.0753, -0.1822, -0.1485, -0.3114,  0.2309,\n",
       "         -0.0400, -0.1733, -0.1543,  0.1286, -0.2689,  0.1596, -0.0568,  0.1817,\n",
       "         -0.2112, -0.0161, -0.0556, -0.1590, -0.2010, -0.1340, -0.2070, -0.0393,\n",
       "         -0.1765, -0.0777, -0.1397, -0.2622, -0.4118,  0.1400, -0.2315, -0.1489,\n",
       "         -0.1087, -0.1384,  0.0333,  0.1773, -0.2083, -0.2943, -0.3111, -0.3332,\n",
       "         -0.0408, -0.0324, -0.1117, -0.3064, -0.1813, -0.2559, -0.1319, -0.2290,\n",
       "         -0.0962, -0.1180, -0.0098, -0.0674, -0.0124,  0.1932,  0.0062, -0.2818,\n",
       "          0.0194, -0.1822, -0.2224, -0.0977,  0.0365,  0.0817, -0.3611, -0.0445,\n",
       "         -0.0524, -0.2090, -0.2138, -0.1280,  0.1187, -0.2181, -0.3223,  0.1749,\n",
       "          0.0349, -0.0998,  0.1829,  0.0619, -0.0089,  0.1679, -0.1173,  0.0358,\n",
       "          0.0577,  0.0045,  0.1253,  0.1087,  0.1354,  0.1455, -0.1641,  0.1720,\n",
       "         -0.1516, -0.0362,  0.0842,  0.0700,  0.0767,  0.0649, -0.0548, -0.0556,\n",
       "         -0.0756,  0.1632, -0.0278, -0.0734,  0.0479,  0.0446, -0.1547,  0.1975,\n",
       "          0.0317,  0.1494,  0.0130,  0.0982, -0.1620, -0.0264,  0.0827, -0.0254,\n",
       "          0.0196,  0.2880, -0.0797, -0.0283,  0.0245, -0.0067, -0.0256, -0.0403,\n",
       "          0.0903, -0.0869,  0.0304, -0.1290,  0.0007, -0.0117, -0.1840, -0.1447,\n",
       "          0.0331, -0.2980,  0.0525, -0.0921, -0.3836,  0.0416, -0.0876,  0.1345,\n",
       "         -0.1679, -0.1505, -0.2713, -0.0398, -0.0133, -0.1705, -0.0114, -0.3552,\n",
       "         -0.1526, -0.4411, -0.1457, -0.0602, -0.1228, -0.0500, -0.2799, -0.1310,\n",
       "         -0.2119,  0.0099, -0.0392, -0.0121, -0.0159, -0.1091, -0.0424, -0.3743,\n",
       "         -0.0750, -0.0097, -0.1589,  0.0284, -0.2066,  0.1101, -0.0102, -0.2673],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.sublayer.0.norm.a_2': tensor([0.6247, 0.7281, 0.6344, 0.6445, 0.5213, 0.9513, 0.6629, 0.4356, 0.5966,\n",
       "         0.7210, 0.9507, 0.6938, 0.7659, 0.6209, 0.6440, 0.8055, 0.5079, 0.7328,\n",
       "         0.6528, 0.8457, 0.7614, 0.5190, 0.5748, 0.5841, 0.6862, 0.8021, 0.6162,\n",
       "         0.5816, 0.9425, 0.7003, 0.4861, 0.9252, 0.8399, 0.5867, 0.4091, 0.7337,\n",
       "         0.5198, 0.6620, 0.7782, 0.4919, 0.6447, 0.7214, 0.6309, 0.8204, 0.7480,\n",
       "         0.5706, 0.6372, 0.6870, 0.7717, 0.6541], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.sublayer.0.norm.b_2': tensor([-0.0189,  0.1914, -0.0738,  0.0824, -0.1053,  0.0395, -0.1113,  0.0758,\n",
       "          0.0780, -0.0254, -0.0229,  0.1095,  0.0972,  0.1334, -0.0017,  0.0165,\n",
       "         -0.0673,  0.1619, -0.0620, -0.1470, -0.1010,  0.1686,  0.1189,  0.0851,\n",
       "         -0.0374, -0.1622, -0.1476,  0.1082,  0.0054, -0.1557, -0.2172,  0.0502,\n",
       "          0.1904,  0.1780, -0.1025, -0.0778, -0.0261,  0.0212,  0.0402, -0.0694,\n",
       "         -0.0778,  0.2283, -0.0764, -0.0327, -0.0518,  0.1223,  0.0518,  0.0786,\n",
       "         -0.1249, -0.1641], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.sublayer.1.norm.a_2': tensor([1.0621, 1.0389, 1.2513, 1.1231, 0.9250, 1.3000, 1.2099, 0.4777, 0.7670,\n",
       "         1.0259, 0.8151, 1.0179, 0.8135, 0.5466, 1.1287, 1.2399, 0.6136, 0.9142,\n",
       "         0.8043, 0.9037, 1.1944, 0.7174, 0.7146, 0.7241, 0.6167, 1.1788, 0.9979,\n",
       "         0.9938, 1.0050, 0.9225, 0.6761, 0.9820, 1.0360, 1.2024, 0.7635, 0.7413,\n",
       "         0.6239, 1.3395, 1.0964, 0.8917, 1.1484, 0.8684, 0.9595, 0.8607, 1.0727,\n",
       "         1.2799, 0.8266, 0.8512, 0.9315, 0.9969], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.2.sublayer.1.norm.b_2': tensor([ 0.1352,  0.0543,  0.1724,  0.1362,  0.0556, -0.0031, -0.1916,  0.0126,\n",
       "          0.0311,  0.0323,  0.0601,  0.1954,  0.1156,  0.1375,  0.0296, -0.0796,\n",
       "         -0.0393,  0.0485, -0.0833, -0.0437, -0.0848,  0.0023, -0.0435,  0.0114,\n",
       "          0.0105, -0.0267, -0.0683,  0.1165,  0.0261,  0.0848,  0.0101, -0.0131,\n",
       "          0.0943, -0.0354, -0.2479,  0.0740,  0.0506, -0.2024,  0.1116, -0.1996,\n",
       "          0.0842,  0.0182, -0.0275,  0.0974, -0.0807, -0.0254, -0.0399, -0.0237,\n",
       "         -0.2153,  0.1613], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.self_attn.linears.0.weight': tensor([[-0.1304,  0.0892, -0.0533,  ..., -0.1004, -0.2994,  0.0375],\n",
       "         [ 0.1794,  0.1153, -0.0533,  ..., -0.4704, -0.0640,  0.1099],\n",
       "         [-0.3494,  0.0156, -0.1029,  ...,  0.3508,  0.1988,  0.1537],\n",
       "         ...,\n",
       "         [-0.2725, -0.2546, -0.2680,  ..., -0.2846, -0.1320,  0.5057],\n",
       "         [ 0.2047,  0.0139,  0.3966,  ...,  0.2113,  0.1949, -0.0227],\n",
       "         [-0.1313,  0.1171, -0.0415,  ..., -0.2020, -0.1469, -0.0349]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.self_attn.linears.0.bias': tensor([-0.5038, -0.3930, -0.0445, -0.5937,  0.0420, -0.1131,  0.1603, -0.3170,\n",
       "         -0.0126,  0.2698,  0.5360, -0.0786, -0.1503, -0.0507, -0.2729, -0.1811,\n",
       "         -0.2269,  0.5026,  0.2735, -0.0734,  0.1643, -0.6594,  0.2482,  0.0211,\n",
       "         -0.0462,  0.2176,  0.2871,  0.0302, -0.2656,  0.3147, -0.2351,  0.3344,\n",
       "         -0.3860, -0.5292, -0.2902,  0.6763, -0.5181,  0.2944, -0.2291,  0.1794,\n",
       "          0.6491, -0.2333, -0.1237,  0.1986,  0.2773, -0.2921,  0.3630,  0.2764,\n",
       "          0.0100, -0.0762], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.self_attn.linears.1.weight': tensor([[ 0.0426,  0.3639,  0.1958,  ..., -0.0912, -0.0183, -0.1153],\n",
       "         [ 0.1802,  0.2623,  0.2584,  ...,  0.0618,  0.2718, -0.2280],\n",
       "         [-0.3647,  0.1503, -0.1068,  ..., -0.0784, -0.1276,  0.2600],\n",
       "         ...,\n",
       "         [-0.3406, -0.1733,  0.0734,  ..., -0.0919,  0.1160, -0.0596],\n",
       "         [ 0.3221,  0.0036,  0.0531,  ..., -0.0067, -0.0095,  0.1143],\n",
       "         [ 0.0212,  0.4630,  0.2289,  ...,  0.2811, -0.1335,  0.0339]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.self_attn.linears.1.bias': tensor([-0.0789, -0.1411, -0.0460, -0.0866,  0.0874, -0.0903,  0.0955, -0.1204,\n",
       "         -0.0193, -0.1312,  0.1102, -0.1048,  0.0410, -0.1079,  0.0975, -0.0970,\n",
       "          0.1302,  0.0401, -0.0026,  0.1350,  0.0527, -0.0560,  0.1290, -0.1341,\n",
       "          0.1307,  0.1356,  0.1026, -0.0706, -0.0911,  0.0842,  0.0821,  0.1341,\n",
       "         -0.1218, -0.0806, -0.1367,  0.1334,  0.0300,  0.1203, -0.0412, -0.1075,\n",
       "          0.1184,  0.0117, -0.0881,  0.0003,  0.1279, -0.0429, -0.0396,  0.0975,\n",
       "         -0.0364,  0.0842], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.self_attn.linears.2.weight': tensor([[-0.0220, -0.2359,  0.0221,  ..., -0.1243, -0.0947,  0.0150],\n",
       "         [ 0.0057,  0.0903,  0.1721,  ..., -0.0230,  0.0969, -0.0291],\n",
       "         [-0.0529, -0.0639,  0.0757,  ...,  0.0045, -0.0045,  0.0658],\n",
       "         ...,\n",
       "         [ 0.0701,  0.0301, -0.0437,  ...,  0.0385, -0.0013,  0.1458],\n",
       "         [ 0.0911, -0.0688,  0.1147,  ...,  0.0078,  0.0377,  0.1153],\n",
       "         [-0.1359,  0.1462,  0.0264,  ...,  0.0437,  0.0753,  0.0142]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.self_attn.linears.2.bias': tensor([-0.1116, -0.0248, -0.1206,  0.0027,  0.0702, -0.1789,  0.0530, -0.0394,\n",
       "         -0.0248, -0.0261,  0.1375, -0.1628, -0.0220, -0.0707,  0.0173, -0.1614,\n",
       "          0.1048, -0.0149, -0.0531,  0.0819, -0.0518, -0.0023,  0.1388, -0.0740,\n",
       "          0.0981,  0.0313,  0.1579, -0.0050, -0.0136, -0.0055,  0.0936,  0.0829,\n",
       "         -0.0413,  0.0307, -0.0471,  0.0563,  0.0529,  0.0503, -0.0531, -0.1395,\n",
       "         -0.0457,  0.0490, -0.0818,  0.0244,  0.0382, -0.0278, -0.0371,  0.0601,\n",
       "         -0.0570,  0.0723], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.self_attn.linears.3.weight': tensor([[-0.0035, -0.1167,  0.0947,  ..., -0.0935, -0.0277,  0.0996],\n",
       "         [ 0.0893,  0.1274,  0.0868,  ...,  0.0691,  0.1456, -0.1194],\n",
       "         [-0.0603, -0.0279, -0.0381,  ..., -0.0483,  0.0817,  0.0669],\n",
       "         ...,\n",
       "         [-0.0365,  0.1888, -0.0312,  ..., -0.0550, -0.0678,  0.0240],\n",
       "         [ 0.0544, -0.1376,  0.2035,  ...,  0.0250,  0.1597,  0.0728],\n",
       "         [-0.1496,  0.0216, -0.0601,  ..., -0.1408,  0.0115,  0.1049]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.self_attn.linears.3.bias': tensor([-0.1886, -0.3680, -0.0649,  0.0048,  0.2499, -0.1899,  0.5405, -0.2209,\n",
       "         -0.0680,  0.0056,  0.0656, -0.0303, -0.1127, -0.1424,  0.0624, -0.0910,\n",
       "          0.0876, -0.1636,  0.1181,  0.2194,  0.0873, -0.1540, -0.0115, -0.1404,\n",
       "          0.2061,  0.2414,  0.3957, -0.3105, -0.2477,  0.1207,  0.1289, -0.1449,\n",
       "         -0.4972,  0.0383, -0.1145,  0.1428,  0.0439, -0.0689, -0.1062, -0.0071,\n",
       "          0.1217, -0.1894, -0.0397,  0.0497,  0.2386,  0.0241, -0.1138,  0.0098,\n",
       "          0.5543,  0.1858], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.feed_forward.bn.weight': tensor([0.8269, 0.7050, 1.1915, 1.0538, 1.0771, 1.0612, 1.1056, 0.7766, 0.7362,\n",
       "         0.8491, 1.1474, 0.9536, 0.6855, 0.7657, 1.2417, 1.0549, 0.8952, 0.7451,\n",
       "         0.9435, 0.9134, 0.8743, 0.8717, 0.7710, 1.0284, 1.0819, 1.0967, 1.1615,\n",
       "         0.9311, 1.1805, 1.0462, 0.8658, 0.6366, 0.7385, 1.1768, 0.7353, 1.1197,\n",
       "         0.8044, 1.0989, 0.8911, 1.0993, 1.0765, 1.0182, 0.8763, 0.9701, 1.0747,\n",
       "         1.1721, 0.6280, 0.8537, 1.4426, 1.0957], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.feed_forward.bn.bias': tensor([-0.2612, -0.3351,  0.0441, -0.2164, -0.0712, -0.0831,  0.0964, -0.3308,\n",
       "         -0.3282, -0.1596, -0.0025, -0.2595, -0.2926, -0.1855, -0.0461, -0.1500,\n",
       "         -0.2281, -0.2659, -0.1537, -0.0879,  0.0868, -0.1757, -0.3719, -0.1221,\n",
       "         -0.1993, -0.0203,  0.1253, -0.2340, -0.3364,  0.0057, -0.1047, -0.3896,\n",
       "         -0.2723,  0.1025, -0.3120, -0.0509, -0.1743, -0.3124, -0.2247,  0.0369,\n",
       "         -0.0530, -0.1797, -0.2264, -0.0930, -0.0213,  0.0915, -0.3135, -0.2495,\n",
       "          0.4878, -0.1275], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.feed_forward.bn.running_mean': tensor([ 0.1214, -0.0101,  0.0069,  0.0521,  0.2747, -0.0093,  0.1073,  0.0424,\n",
       "         -0.0808,  0.3199,  0.0769,  0.0202,  0.1644,  0.1312,  0.0053,  0.0459,\n",
       "         -0.0020,  0.1945,  0.0568,  0.0320,  0.4647,  0.0184,  0.1748,  0.0905,\n",
       "          0.1579,  0.0986,  0.1781,  0.0354, -0.0249,  0.1247,  0.1221,  0.0318,\n",
       "          0.1464,  0.1752,  0.0083,  0.1250,  0.2780,  0.0162, -0.0031, -0.0693,\n",
       "          0.2060, -0.0403,  0.1087,  0.1174,  0.1113, -0.0011,  0.1147,  0.0264,\n",
       "          0.1063,  0.1448], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.feed_forward.bn.running_var': tensor([0.1592, 0.1453, 0.1257, 0.0324, 0.1172, 0.1385, 0.0871, 0.0647, 0.0738,\n",
       "         0.1096, 0.0502, 0.0103, 0.0702, 0.0279, 0.0414, 0.0429, 0.0943, 0.0958,\n",
       "         0.0714, 0.0814, 0.1654, 0.0272, 0.0806, 0.0664, 0.0736, 0.0913, 0.0772,\n",
       "         0.0897, 0.0957, 0.0735, 0.0723, 0.0434, 0.0777, 0.0733, 0.1504, 0.1187,\n",
       "         0.1306, 0.0076, 0.0529, 0.0311, 0.1097, 0.0445, 0.0735, 0.0643, 0.0409,\n",
       "         0.1800, 0.0987, 0.0514, 0.0988, 0.0676], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.feed_forward.bn.num_batches_tracked': tensor(213030),\n",
       " 'transformer_pre.model.layers.3.feed_forward.encoder_0.weight_ih_l0': tensor([[ 0.0994, -0.1218,  0.0216,  ...,  0.2294, -0.0935, -0.0701],\n",
       "         [ 0.2695, -0.0411, -0.0135,  ..., -0.1321, -0.1942,  0.0961],\n",
       "         [-0.0632,  0.0666, -0.0301,  ...,  0.0962,  0.1172, -0.0184],\n",
       "         ...,\n",
       "         [ 0.0177,  0.2904, -0.0897,  ...,  0.1180, -0.3204, -0.4908],\n",
       "         [ 0.0445, -0.0553,  0.0825,  ...,  0.1725,  0.2229, -0.1421],\n",
       "         [ 0.0286, -0.0302, -0.0837,  ..., -0.3245, -0.2253, -0.3099]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.feed_forward.encoder_0.weight_hh_l0': tensor([[ 0.0160,  0.1159,  0.1577,  ...,  0.0200,  0.0427, -0.2910],\n",
       "         [ 0.1343,  0.0265,  0.1602,  ...,  0.0958, -0.0713,  0.0995],\n",
       "         [ 0.3110,  0.2364,  0.2142,  ..., -0.1181,  0.1210, -0.0305],\n",
       "         ...,\n",
       "         [-0.0952,  0.1975, -0.0991,  ..., -0.2371, -0.0947, -0.1710],\n",
       "         [ 0.0577,  0.0828, -0.1277,  ..., -0.1273, -0.2912, -0.0306],\n",
       "         [ 0.2457, -0.0983,  0.0529,  ...,  0.1153,  0.0104, -0.1629]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.feed_forward.encoder_0.bias_ih_l0': tensor([ 3.0845e-02,  7.1030e-02,  2.5308e-02, -2.0404e-01,  5.5285e-02,\n",
       "         -1.5004e-01,  1.1511e-02, -3.1661e-03,  5.6030e-02, -1.0823e-01,\n",
       "          5.5855e-02, -2.9999e-01,  1.3062e-01, -2.4232e-02,  9.4058e-02,\n",
       "         -3.2677e-01,  8.2020e-02, -1.1152e-01, -9.7046e-02, -9.9257e-03,\n",
       "          1.4468e-01, -2.2455e-01, -3.7317e-01, -8.0543e-02, -6.0459e-02,\n",
       "         -1.7168e-01, -5.9273e-02,  3.2432e-02,  1.3048e-01, -1.0358e-01,\n",
       "         -9.9100e-02,  7.1305e-04, -1.0989e-01, -1.3478e-01, -4.5360e-02,\n",
       "         -2.3023e-01, -6.4211e-03, -4.4620e-01,  1.8571e-02,  8.5453e-02,\n",
       "          7.2164e-03, -1.5172e-01, -4.6147e-01, -1.3425e-01,  6.1017e-02,\n",
       "          2.1233e-01, -2.0880e-01, -2.0869e-01,  9.7399e-02, -2.9965e-01,\n",
       "          1.0578e-01, -1.8323e-02,  7.2413e-02, -2.1003e-02, -3.1756e-01,\n",
       "         -2.8218e-01, -2.5336e-02, -1.4546e-01,  6.8421e-02, -2.3857e-01,\n",
       "         -9.6829e-02, -1.9187e-01,  3.0076e-01, -2.6511e-01, -1.8876e-01,\n",
       "         -2.5113e-01, -4.0130e-02, -4.8193e-02, -2.6986e-01, -2.0256e-02,\n",
       "         -2.6225e-01, -1.4352e-01, -4.3971e-02, -8.7863e-02, -9.9529e-02,\n",
       "         -1.7701e-01,  1.6574e-01,  6.2556e-02,  3.0436e-01,  4.0449e-03,\n",
       "         -6.1617e-02, -1.6498e-01,  8.3237e-03,  5.6679e-02,  1.3551e-01,\n",
       "         -2.0599e-01, -8.8009e-03, -5.1944e-01, -9.1464e-02,  1.1218e-01,\n",
       "         -1.1021e-01, -1.0427e-01, -2.3736e-01, -1.8816e-01, -1.0707e-01,\n",
       "         -1.5136e-01,  6.0297e-02, -1.3155e-01,  3.2104e-02, -3.6003e-01,\n",
       "          1.8335e-01, -3.7231e-02,  2.2390e-01,  4.2521e-02, -6.1662e-04,\n",
       "         -1.5198e-01,  1.9426e-01,  4.2551e-02,  1.7319e-01,  1.0478e-01,\n",
       "         -2.1623e-02,  4.1099e-02,  1.8734e-01, -7.9889e-02,  1.2585e-01,\n",
       "          1.1137e-01, -6.2282e-03,  4.3936e-02, -2.4431e-01,  2.6790e-02,\n",
       "          1.5529e-01,  4.8408e-02, -1.4919e-01, -1.7673e-02,  6.0143e-02,\n",
       "          1.2804e-01, -4.6379e-02, -1.9036e-02, -1.6877e-01, -3.4686e-02,\n",
       "         -1.8961e-01, -3.2494e-02, -6.4182e-02,  1.7644e-01, -1.1902e-02,\n",
       "          2.8564e-02,  4.9783e-02,  3.7055e-02, -6.9052e-02, -3.3839e-02,\n",
       "          1.1272e-01, -4.1738e-02, -1.3781e-03,  2.0674e-01, -6.9735e-02,\n",
       "         -4.4667e-02,  2.1052e-01,  1.3386e-01,  3.3391e-01,  1.0275e-01,\n",
       "         -3.8546e-02, -5.2983e-02,  5.3072e-05, -1.7601e-01, -1.1551e-01,\n",
       "          4.3598e-02, -1.1068e-02,  1.3394e-01, -2.6992e-01, -1.8863e-01,\n",
       "         -1.0831e-01, -6.7827e-02, -7.7491e-03, -2.7865e-01,  1.3854e-03,\n",
       "         -1.7770e-01, -5.1655e-02,  1.5333e-02, -7.1759e-02, -3.2944e-02,\n",
       "         -4.2152e-03, -1.8183e-01, -5.0073e-02, -3.5516e-02, -7.1892e-02,\n",
       "         -1.2157e-01, -7.8169e-03,  1.4612e-01,  6.9806e-02, -3.1072e-01,\n",
       "         -1.1481e-01, -5.6296e-02, -2.4743e-01,  5.2337e-02, -1.2185e-01,\n",
       "         -1.7732e-01,  1.5159e-01, -3.2977e-01, -1.4585e-01, -1.0589e-01,\n",
       "         -3.1667e-01, -2.0507e-01, -1.6579e-01,  1.6342e-01,  8.2103e-03,\n",
       "          3.5911e-01, -2.0434e-01, -1.8549e-01, -2.2519e-01, -3.5255e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.feed_forward.encoder_0.bias_hh_l0': tensor([ 1.8636e-01,  8.4206e-02,  1.4987e-01, -3.0852e-01, -8.9083e-02,\n",
       "         -2.7051e-02,  8.0488e-03, -1.2377e-01,  9.9529e-02, -1.8595e-01,\n",
       "         -5.6002e-02, -3.7982e-01,  1.9738e-01, -2.0305e-01,  1.0899e-01,\n",
       "         -1.1103e-01,  7.1102e-02, -6.7424e-02, -1.4383e-01,  1.1455e-01,\n",
       "          1.5926e-01, -2.4322e-01, -2.1611e-01, -1.1773e-01, -1.6472e-01,\n",
       "         -2.5872e-01,  1.7110e-01,  6.5423e-02, -8.5796e-02, -2.7164e-02,\n",
       "         -1.1862e-01, -2.6856e-02,  1.5307e-02,  9.4449e-03,  8.0094e-02,\n",
       "         -4.2670e-02,  2.3234e-02, -5.1680e-01, -1.4616e-01,  1.5993e-04,\n",
       "         -5.0988e-02, -3.0942e-01, -5.0201e-01, -5.6814e-02,  1.8973e-01,\n",
       "          3.0405e-01, -1.0454e-01,  7.0305e-03,  2.5539e-03, -2.5039e-01,\n",
       "         -1.8824e-02,  3.0140e-02,  9.3413e-02, -1.8563e-01, -2.3827e-01,\n",
       "         -1.4043e-01, -7.8804e-02,  4.3337e-02, -8.1354e-02, -1.7697e-01,\n",
       "         -5.3662e-02, -2.7257e-02,  2.6290e-01, -3.2779e-01, -2.6526e-01,\n",
       "         -3.8709e-01, -1.4441e-01, -4.3954e-02, -2.6992e-01,  9.3808e-02,\n",
       "         -1.6885e-01, -2.4898e-01, -2.2355e-01, -3.0326e-01, -1.4514e-01,\n",
       "         -3.3177e-01,  7.7283e-03,  2.5882e-01,  1.3894e-01, -2.7973e-02,\n",
       "          2.1504e-02,  2.1928e-02, -2.4845e-01, -1.0046e-01, -2.3595e-02,\n",
       "         -2.7832e-01, -2.1687e-01, -3.9867e-01, -2.4868e-01,  1.4419e-02,\n",
       "         -1.0175e-01, -7.1567e-02, -2.7603e-01, -3.3385e-02, -4.9369e-02,\n",
       "          5.1210e-02,  5.2742e-02, -1.8072e-01, -7.1996e-02, -4.3168e-01,\n",
       "         -7.9537e-02,  1.0651e-02,  1.0243e-01,  1.3499e-02, -6.1467e-02,\n",
       "         -1.2412e-01,  2.5564e-01,  6.8989e-02, -8.8411e-03, -3.0835e-02,\n",
       "         -3.3293e-02,  7.9292e-02,  2.0732e-01,  8.7560e-02,  1.1789e-01,\n",
       "         -4.8727e-02,  9.2721e-02,  9.8412e-02,  2.2601e-02,  4.2170e-02,\n",
       "         -4.8355e-02,  5.6308e-02, -2.8075e-02,  9.9309e-02, -1.2568e-01,\n",
       "         -2.9916e-02,  6.9750e-02, -3.8624e-02, -1.8979e-01,  1.6222e-01,\n",
       "         -1.5106e-01, -1.2471e-01,  2.3454e-02, -9.0711e-02, -1.2250e-02,\n",
       "          1.1321e-01,  4.0797e-02,  3.3581e-02, -6.7301e-02, -9.0248e-02,\n",
       "          1.4046e-01,  8.7228e-02, -5.5243e-02,  1.1732e-01, -2.0848e-02,\n",
       "          5.2519e-02, -4.8115e-02,  2.7183e-04,  2.1161e-01,  1.2135e-01,\n",
       "         -2.6652e-02, -1.6690e-01,  7.0548e-02, -9.1417e-02, -2.1938e-01,\n",
       "         -1.0960e-01, -2.0261e-02,  5.8112e-03, -8.7777e-02, -3.0519e-02,\n",
       "         -5.6556e-02, -2.5778e-01, -1.1135e-01, -3.5762e-01,  9.4196e-02,\n",
       "         -2.6536e-01, -8.1325e-02, -7.6112e-02, -2.8113e-01, -1.5946e-01,\n",
       "         -1.2871e-01, -1.6979e-01, -2.3979e-01, -2.3162e-01, -1.5201e-01,\n",
       "         -2.0091e-01,  3.6990e-02, -1.9292e-02,  1.2839e-01, -6.0862e-02,\n",
       "         -1.6710e-01, -6.0208e-02, -2.7963e-01, -1.5790e-01, -1.1254e-01,\n",
       "         -1.9456e-02,  2.2823e-01, -3.5309e-01, -1.9937e-01,  9.5705e-02,\n",
       "         -1.9343e-01, -3.0326e-01, -2.3719e-01,  4.9399e-03,  3.3444e-02,\n",
       "          2.4074e-01, -9.0926e-02, -2.1980e-01, -9.2704e-02, -3.4413e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.feed_forward.encoder_1.weight_ih_l0': tensor([[ 0.0974, -0.2557,  0.0698,  ..., -0.1810,  0.1966, -0.1318],\n",
       "         [ 0.1079,  0.0307,  0.2226,  ..., -0.0944,  0.0162, -0.1761],\n",
       "         [ 0.4717, -0.0050,  0.0958,  ..., -0.0983, -0.1361, -0.0590],\n",
       "         ...,\n",
       "         [-0.0699,  0.3545,  0.4656,  ...,  0.0092, -0.1938,  0.0363],\n",
       "         [-0.0132,  0.0397, -0.0491,  ...,  0.0053,  0.2088, -0.4181],\n",
       "         [-0.1189, -0.1199, -0.0846,  ..., -0.3902, -0.0020,  0.1519]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.feed_forward.encoder_1.weight_hh_l0': tensor([[ 0.1267,  0.0680, -0.0597,  ..., -0.0744,  0.0504, -0.0473],\n",
       "         [ 0.1462,  0.0492, -0.0268,  ..., -0.1020, -0.2256, -0.0356],\n",
       "         [-0.0781,  0.0749, -0.2348,  ...,  0.2011, -0.1547, -0.1926],\n",
       "         ...,\n",
       "         [-0.0108,  0.0576, -0.1019,  ..., -0.0388,  0.1317,  0.0033],\n",
       "         [ 0.0241,  0.2263, -0.2822,  ..., -0.1216,  0.1917, -0.2697],\n",
       "         [-0.0340,  0.2470,  0.0900,  ..., -0.0864, -0.1443, -0.0772]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.feed_forward.encoder_1.bias_ih_l0': tensor([ 0.2095,  0.0034, -0.1295, -0.0699,  0.0207,  0.0067, -0.0388, -0.2671,\n",
       "         -0.2878, -0.1175, -0.0267, -0.4486, -0.0854,  0.0228, -0.0943, -0.1331,\n",
       "         -0.2220, -0.0348, -0.0749, -0.2656,  0.3007, -0.0179, -0.3051, -0.1528,\n",
       "         -0.2057, -0.2739, -0.0298, -0.1319, -0.5367, -0.1573,  0.0224, -0.0370,\n",
       "         -0.0042, -0.1620,  0.0808, -0.0460, -0.0868, -0.2721, -0.0637, -0.1250,\n",
       "         -0.1628,  0.0174, -0.1462,  0.1330, -0.1630,  0.1766,  0.1184, -0.3055,\n",
       "         -0.2356, -0.0582,  0.0633, -0.0669, -0.1746, -0.0691, -0.4134,  0.1793,\n",
       "         -0.0509,  0.0157, -0.1211,  0.0190, -0.3008, -0.2833, -0.0170, -0.3061,\n",
       "         -0.0056,  0.1538,  0.0010, -0.1631, -0.1373, -0.1132,  0.1542, -0.0981,\n",
       "         -0.2598, -0.1481, -0.2290, -0.2091, -0.0213, -0.3082, -0.3780, -0.2318,\n",
       "         -0.1124, -0.1380, -0.2422,  0.0319, -0.0366, -0.0265,  0.0769, -0.1867,\n",
       "         -0.0191, -0.2392, -0.1486, -0.2087, -0.2605, -0.0741,  0.0042, -0.1407,\n",
       "          0.1226, -0.2235, -0.3613, -0.1206, -0.1053, -0.0853, -0.0033,  0.0419,\n",
       "          0.1046,  0.0216, -0.1013, -0.0521, -0.0457,  0.1012, -0.1218, -0.3037,\n",
       "          0.0674,  0.2075,  0.1607, -0.1429, -0.0350, -0.0349,  0.2272, -0.3064,\n",
       "         -0.0817,  0.0438, -0.1269,  0.3597, -0.1180, -0.0283,  0.1058, -0.0812,\n",
       "         -0.1482, -0.0681,  0.0011,  0.1147, -0.2726,  0.1017, -0.1202,  0.2934,\n",
       "          0.0053, -0.1323,  0.1080, -0.0453,  0.1271, -0.1591, -0.2596, -0.0435,\n",
       "          0.1671,  0.0612,  0.1561,  0.0325,  0.1065, -0.0704, -0.1701, -0.1743,\n",
       "         -0.2342, -0.4728, -0.1073, -0.0106, -0.1888, -0.3040, -0.1838, -0.1049,\n",
       "          0.0249, -0.1734, -0.2181, -0.0919, -0.0290, -0.0451, -0.3222, -0.0139,\n",
       "         -0.1349,  0.0943,  0.0067, -0.0403, -0.3676,  0.1518, -0.2833, -0.2063,\n",
       "         -0.1752, -0.5391, -0.3299,  0.0319, -0.2346,  0.0613, -0.2192,  0.0510,\n",
       "         -0.2300, -0.4132, -0.1553, -0.4680, -0.2986,  0.0277, -0.2181,  0.0811,\n",
       "          0.0106, -0.0302, -0.4269,  0.1522,  0.1194, -0.2323, -0.3881,  0.0737],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.feed_forward.encoder_1.bias_hh_l0': tensor([-0.0250, -0.1825, -0.2325, -0.2412,  0.0746,  0.0241, -0.0101, -0.3450,\n",
       "         -0.1749, -0.0034, -0.2482, -0.5120, -0.0711,  0.0902, -0.0007, -0.1062,\n",
       "         -0.2689, -0.2518,  0.0016, -0.1965,  0.1238, -0.1535, -0.3043, -0.1401,\n",
       "         -0.2950, -0.1601, -0.1523, -0.0681, -0.3784, -0.0901,  0.0865, -0.2438,\n",
       "         -0.1191,  0.0347,  0.0629, -0.0842, -0.0378, -0.3608,  0.0729, -0.1861,\n",
       "         -0.3264, -0.0047,  0.0720,  0.0066, -0.0593,  0.2680,  0.1928, -0.3196,\n",
       "         -0.3976, -0.0278,  0.0912,  0.0453, -0.1929, -0.2399, -0.3919,  0.2333,\n",
       "         -0.0767,  0.1376, -0.2809, -0.1842, -0.3164, -0.2004,  0.0739, -0.3655,\n",
       "          0.0483,  0.1993, -0.1003, -0.0982, -0.2113,  0.0128,  0.0175,  0.0012,\n",
       "         -0.3738, -0.2088, -0.3099, -0.1230, -0.1731, -0.2945, -0.3712, -0.1308,\n",
       "         -0.2281, -0.3017, -0.0879, -0.1142,  0.0384, -0.0945,  0.0043, -0.2469,\n",
       "         -0.1306, -0.2242, -0.2121, -0.1987, -0.3186,  0.0747, -0.0949, -0.0460,\n",
       "          0.1275, -0.3297, -0.3107, -0.0098,  0.1321,  0.0278,  0.1619, -0.0256,\n",
       "          0.1064,  0.1536,  0.0769, -0.1892, -0.1032,  0.1202, -0.0392, -0.2551,\n",
       "          0.0464,  0.3342,  0.1543, -0.2296, -0.0250,  0.0070,  0.2786, -0.1150,\n",
       "         -0.0350, -0.1268,  0.0181,  0.4121, -0.1998,  0.0509,  0.1286, -0.1171,\n",
       "         -0.2190, -0.1258, -0.0633,  0.0713, -0.0847,  0.0802, -0.0600,  0.2695,\n",
       "          0.1481,  0.0401,  0.0146, -0.1208,  0.0734, -0.1846, -0.0776, -0.0143,\n",
       "          0.0282,  0.0296,  0.2418,  0.0655,  0.0883,  0.0921, -0.0365, -0.2699,\n",
       "         -0.1597, -0.3071, -0.3216,  0.0838, -0.2562, -0.2293, -0.2638, -0.1763,\n",
       "         -0.1593, -0.1598, -0.1609, -0.0471, -0.1006,  0.0213, -0.2658, -0.2511,\n",
       "         -0.2102,  0.1028,  0.0373, -0.0906, -0.1821,  0.0016, -0.2123, -0.2177,\n",
       "         -0.2287, -0.3582, -0.3496, -0.1557, -0.1266,  0.0585, -0.3303, -0.0052,\n",
       "         -0.2119, -0.4216, -0.2851, -0.4904, -0.1401,  0.0816, -0.2450,  0.1993,\n",
       "          0.0282, -0.1356, -0.2058,  0.0472,  0.0423, -0.2235, -0.2276,  0.2026],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.feed_forward.encoder_2.weight_ih_l0': tensor([[ 0.1620, -0.1421, -0.0639,  ..., -0.0075,  0.0227, -0.1730],\n",
       "         [ 0.3177,  0.1367, -0.1162,  ...,  0.0849,  0.2271, -0.1504],\n",
       "         [-0.3979,  0.0387, -0.1674,  ..., -0.0078, -0.0622,  0.3304],\n",
       "         ...,\n",
       "         [-0.0950, -0.0015, -0.1111,  ...,  0.1860,  0.0915, -0.1290],\n",
       "         [ 0.0161, -0.2034,  0.1364,  ...,  0.1369,  0.1066, -0.1279],\n",
       "         [ 0.1459,  0.0446, -0.1680,  ..., -0.1185, -0.2053, -0.2389]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.feed_forward.encoder_2.weight_hh_l0': tensor([[-0.1588, -0.1254,  0.0943,  ..., -0.1465,  0.1359,  0.0663],\n",
       "         [-0.1692, -0.0536,  0.1235,  ...,  0.0295, -0.0257, -0.0163],\n",
       "         [-0.2266,  0.0451, -0.2747,  ..., -0.0843,  0.2595,  0.1881],\n",
       "         ...,\n",
       "         [-0.2774,  0.2759, -0.0318,  ..., -0.0128,  0.1182,  0.0530],\n",
       "         [ 0.2426, -0.3628,  0.2269,  ..., -0.3392, -0.4528,  0.1276],\n",
       "         [ 0.0923,  0.1865, -0.0342,  ...,  0.0543,  0.0336,  0.1706]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.feed_forward.encoder_2.bias_ih_l0': tensor([ 0.1479, -0.2617, -0.0708, -0.2298,  0.1537, -0.0609,  0.0674,  0.0822,\n",
       "         -0.1173,  0.0947, -0.1150, -0.1984, -0.2497, -0.0690, -0.1813, -0.1864,\n",
       "         -0.0706,  0.1261, -0.0843, -0.1232,  0.2350, -0.2063,  0.1602, -0.0974,\n",
       "         -0.1419, -0.0472, -0.0602, -0.0390, -0.4106, -0.0857, -0.0241, -0.1295,\n",
       "          0.1699,  0.0743,  0.2133,  0.0931,  0.0489, -0.0225, -0.3371, -0.1304,\n",
       "         -0.0311, -0.0590, -0.0666, -0.3351, -0.1442,  0.3107, -0.2915,  0.0681,\n",
       "          0.0408, -0.0803,  0.1074,  0.0595,  0.0624, -0.3611, -0.1296,  0.0294,\n",
       "         -0.0613,  0.1342, -0.0096, -0.0955, -0.2556, -0.0080, -0.3992,  0.0039,\n",
       "         -0.3278, -0.1490,  0.1638, -0.1551, -0.2550, -0.1314,  0.0943, -0.1521,\n",
       "          0.0289,  0.0980, -0.0875,  0.0735, -0.0745,  0.2913, -0.2045, -0.3103,\n",
       "         -0.1622,  0.0873,  0.1072, -0.0376, -0.0685,  0.0243,  0.1658, -0.0941,\n",
       "         -0.2808, -0.2285,  0.1895,  0.0598, -0.2687, -0.2103, -0.2468, -0.1385,\n",
       "         -0.0589,  0.0305, -0.0259, -0.1757,  0.1564, -0.0615, -0.1234,  0.0388,\n",
       "          0.1409,  0.2079, -0.3086, -0.0569, -0.1757, -0.0138,  0.0454, -0.0307,\n",
       "         -0.1630,  0.1614, -0.1296,  0.0987, -0.0066, -0.0310,  0.0606, -0.0439,\n",
       "          0.1145, -0.0795,  0.2574, -0.2989,  0.0159,  0.0983, -0.0869,  0.1637,\n",
       "          0.0056,  0.1216, -0.0068, -0.0847, -0.0296,  0.0813, -0.0621, -0.0897,\n",
       "          0.2626,  0.0365, -0.1936, -0.2231,  0.0964, -0.0855,  0.1310,  0.0694,\n",
       "          0.1762,  0.3813, -0.0322, -0.0091,  0.1762, -0.0971, -0.0625, -0.0903,\n",
       "          0.0310, -0.5280,  0.0297,  0.0211, -0.0754, -0.1996, -0.0339, -0.1193,\n",
       "         -0.0196, -0.2595, -0.0359, -0.0411, -0.3057, -0.0886, -0.2349, -0.0419,\n",
       "         -0.0899, -0.2193,  0.2072,  0.0129,  0.0821, -0.1956, -0.1642, -0.1353,\n",
       "         -0.0773, -0.0488, -0.2030,  0.1017,  0.0238, -0.1576,  0.0704, -0.1743,\n",
       "          0.0742, -0.0132,  0.1954, -0.2024, -0.0108, -0.2515,  0.0991, -0.1513,\n",
       "         -0.0074, -0.7058, -0.3572,  0.3136, -0.2939, -0.0949, -0.1908, -0.1904],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.feed_forward.encoder_2.bias_hh_l0': tensor([ 0.0338, -0.0262, -0.0888, -0.2055,  0.1895, -0.0856,  0.1709, -0.1133,\n",
       "         -0.0864, -0.0958, -0.1923, -0.3187, -0.2298, -0.0259, -0.2426, -0.1021,\n",
       "         -0.0863,  0.0601, -0.2387, -0.0645,  0.2395, -0.2422,  0.0442, -0.1584,\n",
       "         -0.0324, -0.1361,  0.0033, -0.1225, -0.3376,  0.1093, -0.0886, -0.2388,\n",
       "          0.1774, -0.1850,  0.1626,  0.1110,  0.0187, -0.2074, -0.3396, -0.0736,\n",
       "          0.0820, -0.0829, -0.1264, -0.1482, -0.3675,  0.2998, -0.1289,  0.0297,\n",
       "         -0.0468, -0.2211, -0.1122, -0.1658, -0.1501, -0.2219, -0.1971, -0.0551,\n",
       "         -0.0868,  0.1415, -0.0154, -0.1301, -0.2521,  0.0138, -0.3605, -0.2099,\n",
       "         -0.1167, -0.2543,  0.1542, -0.0737, -0.1336, -0.1300,  0.0315, -0.3736,\n",
       "          0.0871, -0.0386, -0.0754, -0.0319, -0.1680,  0.1161, -0.0248, -0.1732,\n",
       "         -0.0848, -0.0769,  0.2032, -0.0275,  0.0614, -0.0855,  0.3401, -0.1669,\n",
       "         -0.1948, -0.4049,  0.0354, -0.0294, -0.0963, -0.2755, -0.3945, -0.0680,\n",
       "         -0.1242,  0.0838, -0.0545, -0.1365,  0.1253, -0.0507, -0.3342,  0.1266,\n",
       "         -0.0328, -0.0589, -0.1007,  0.1238, -0.0701,  0.2508,  0.0258, -0.0129,\n",
       "         -0.0046,  0.0780,  0.0848,  0.1618,  0.1456,  0.0451, -0.0902,  0.1377,\n",
       "          0.2186, -0.0124,  0.2246, -0.0707,  0.0606,  0.2508, -0.1133,  0.2366,\n",
       "         -0.1828,  0.0579, -0.0438, -0.2530,  0.2031,  0.1322, -0.2284,  0.1115,\n",
       "          0.3233,  0.1042, -0.1758, -0.1431,  0.0823,  0.0393,  0.2946, -0.0964,\n",
       "          0.1735,  0.3808, -0.0379, -0.0810,  0.0071, -0.1927, -0.0039, -0.0537,\n",
       "         -0.0113, -0.4075,  0.0041,  0.1450,  0.0599, -0.0504, -0.1601, -0.0745,\n",
       "         -0.1071, -0.2181, -0.0348, -0.1207, -0.3370,  0.0423, -0.0737,  0.0919,\n",
       "         -0.0889, -0.2270,  0.0736, -0.0502,  0.1004, -0.1208, -0.0657,  0.0186,\n",
       "         -0.1296, -0.2911, -0.1018,  0.2074, -0.1293, -0.2430,  0.1193, -0.1542,\n",
       "         -0.1093, -0.1467,  0.2403, -0.0966,  0.0486, -0.1622,  0.1900, -0.2712,\n",
       "          0.0613, -0.5103, -0.2616,  0.2424, -0.4918, -0.0641,  0.0312, -0.4265],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.sublayer.0.norm.a_2': tensor([0.4560, 0.7828, 0.7090, 0.6172, 0.4812, 0.9151, 0.6425, 0.4265, 0.4851,\n",
       "         0.5972, 0.8659, 0.7996, 0.7153, 0.4201, 0.4862, 0.9436, 0.5475, 0.6244,\n",
       "         0.4533, 0.4863, 0.4772, 0.3336, 0.5376, 0.6385, 0.5834, 0.8230, 0.6030,\n",
       "         0.4567, 0.6483, 0.4313, 0.2874, 0.7573, 0.5596, 0.4151, 0.5047, 0.6782,\n",
       "         0.4138, 0.5061, 0.6404, 0.3963, 0.6233, 0.6728, 0.5224, 0.7663, 0.6130,\n",
       "         0.3034, 0.6181, 0.5068, 0.3425, 0.3933], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.sublayer.0.norm.b_2': tensor([-0.0474,  0.2183, -0.0624,  0.0220, -0.0651, -0.0010, -0.1900,  0.1314,\n",
       "          0.0091, -0.0208, -0.0358,  0.1338,  0.1242,  0.1068,  0.0266,  0.0541,\n",
       "          0.0238,  0.0631, -0.0885, -0.1389, -0.0616,  0.1676,  0.0849,  0.0706,\n",
       "         -0.0264, -0.1276, -0.2077,  0.1395,  0.0239, -0.1568, -0.1432,  0.0753,\n",
       "          0.2325,  0.1071, -0.1250, -0.0791,  0.0322,  0.0336, -0.0093, -0.1623,\n",
       "         -0.0013,  0.2406, -0.0759, -0.0494, -0.0559,  0.1168,  0.0636,  0.0755,\n",
       "         -0.2365, -0.1363], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.sublayer.1.norm.a_2': tensor([1.1364, 0.9320, 1.1698, 0.9321, 1.0362, 1.2784, 1.0958, 0.5837, 0.7649,\n",
       "         1.0072, 0.8583, 1.1855, 0.7235, 0.6016, 0.9158, 1.3752, 0.5900, 0.9981,\n",
       "         0.7387, 0.8241, 1.1366, 0.6592, 0.6511, 0.6101, 0.8526, 1.3417, 1.0265,\n",
       "         1.3856, 1.1397, 0.9739, 0.5970, 1.0091, 1.0946, 1.1712, 0.9171, 0.5867,\n",
       "         0.6059, 1.3193, 1.2075, 0.7948, 1.0250, 0.8124, 0.8157, 0.8487, 1.0621,\n",
       "         1.0282, 0.6794, 0.8710, 0.9080, 1.0295], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.3.sublayer.1.norm.b_2': tensor([ 0.0497,  0.1230,  0.1020,  0.1589, -0.0440,  0.1033, -0.0256,  0.0295,\n",
       "         -0.0571,  0.0822, -0.0163,  0.1490,  0.0398,  0.0987, -0.0581, -0.3230,\n",
       "          0.0668,  0.0548,  0.0455,  0.0576, -0.0562,  0.0035, -0.0041, -0.0292,\n",
       "          0.1596, -0.0391, -0.0571, -0.0285, -0.0489,  0.0537,  0.2092, -0.1672,\n",
       "          0.1172, -0.0275, -0.0291, -0.0231,  0.0445, -0.2249,  0.0097, -0.1353,\n",
       "          0.1515,  0.0748,  0.0689,  0.0695,  0.0994,  0.0874, -0.0371,  0.1953,\n",
       "         -0.1721,  0.0966], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.self_attn.linears.0.weight': tensor([[-0.1439, -0.2358, -0.2657,  ..., -0.1510, -0.3698,  0.0030],\n",
       "         [ 0.1337,  0.3080,  0.0484,  ..., -0.2079, -0.0161,  0.1646],\n",
       "         [-0.3746,  0.0913, -0.3090,  ...,  0.3761, -0.0969,  0.1748],\n",
       "         ...,\n",
       "         [ 0.0123,  0.1226,  0.0515,  ...,  0.2934,  0.0834, -0.0508],\n",
       "         [ 0.2429, -0.0659,  0.2327,  ...,  0.2567,  0.2065, -0.2369],\n",
       "         [ 0.1380,  0.1352,  0.2444,  ..., -0.1412, -0.0191, -0.2080]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.self_attn.linears.0.bias': tensor([-0.1490, -0.5043, -0.1810, -0.2442,  0.1783, -0.0085, -0.0888, -0.2299,\n",
       "          0.4240,  0.3515,  0.7573,  0.0828,  0.2290, -0.6583,  0.3633, -0.0527,\n",
       "          0.1187, -0.0221, -0.1968,  0.1725,  0.0160, -0.5529,  0.1873,  0.0970,\n",
       "         -0.1775,  0.0859,  0.5565,  0.0586,  0.0760,  0.3174, -0.3991, -0.0178,\n",
       "         -0.2361, -0.3410,  0.0283,  0.6715, -0.4945,  0.1258, -0.7158,  0.1135,\n",
       "          0.7050, -0.4421, -0.0732,  0.1223,  0.2661, -0.2318,  0.2335,  0.3058,\n",
       "          0.2126,  0.0839], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.self_attn.linears.1.weight': tensor([[ 0.1212, -0.0869, -0.1461,  ..., -0.3227, -0.1430,  0.2310],\n",
       "         [ 0.1044,  0.2791,  0.1793,  ..., -0.0238,  0.0999, -0.0949],\n",
       "         [-0.2862,  0.1260, -0.4774,  ..., -0.1602,  0.0229,  0.0693],\n",
       "         ...,\n",
       "         [-0.2023, -0.1559, -0.0065,  ..., -0.0550, -0.0616, -0.0152],\n",
       "         [-0.1333, -0.3799,  0.0063,  ...,  0.0556, -0.0262, -0.0269],\n",
       "         [-0.2591, -0.0861,  0.2090,  ..., -0.1358,  0.0699, -0.1570]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.self_attn.linears.1.bias': tensor([-0.0789, -0.1411, -0.0460, -0.0866,  0.0874, -0.0903,  0.0955, -0.1204,\n",
       "         -0.0193, -0.1312,  0.1102, -0.1048,  0.0410, -0.1079,  0.0975, -0.0970,\n",
       "          0.1302,  0.0401, -0.0026,  0.1350,  0.0527, -0.0560,  0.1290, -0.1341,\n",
       "          0.1307,  0.1356,  0.1026, -0.0706, -0.0911,  0.0842,  0.0821,  0.1341,\n",
       "         -0.1218, -0.0806, -0.1367,  0.1334,  0.0300,  0.1203, -0.0412, -0.1075,\n",
       "          0.1184,  0.0117, -0.0881,  0.0003,  0.1279, -0.0429, -0.0396,  0.0975,\n",
       "         -0.0364,  0.0842], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.self_attn.linears.2.weight': tensor([[-0.0256, -0.2531,  0.0354,  ..., -0.1459, -0.0535,  0.0166],\n",
       "         [ 0.0354,  0.0282,  0.0745,  ..., -0.0602,  0.1123,  0.0150],\n",
       "         [-0.0571, -0.0012,  0.0644,  ..., -0.0126, -0.0567,  0.0485],\n",
       "         ...,\n",
       "         [ 0.0875,  0.0884,  0.0089,  ...,  0.0790, -0.0233,  0.1023],\n",
       "         [ 0.0800, -0.0568,  0.0575,  ...,  0.0102,  0.0382, -0.0482],\n",
       "         [-0.1563,  0.1174, -0.0014,  ..., -0.0108,  0.0318,  0.0414]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.self_attn.linears.2.bias': tensor([-0.1360, -0.0714, -0.0278, -0.0445,  0.0796, -0.1063,  0.0413, -0.0363,\n",
       "         -0.0599, -0.0172,  0.0635, -0.1165, -0.0266, -0.0244,  0.0099, -0.1924,\n",
       "          0.1234,  0.0381, -0.0187,  0.1679,  0.0456, -0.0079,  0.1330, -0.0793,\n",
       "          0.1228,  0.0027,  0.1966,  0.0311, -0.0280, -0.0020,  0.1152,  0.0796,\n",
       "         -0.1061,  0.0221, -0.0105,  0.0579,  0.0593,  0.0189, -0.0141, -0.0804,\n",
       "          0.0312,  0.0639, -0.0455,  0.0667,  0.1173, -0.0367,  0.0030,  0.0829,\n",
       "         -0.0222,  0.0640], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.self_attn.linears.3.weight': tensor([[ 0.0613, -0.0770, -0.0015,  ..., -0.0301, -0.1248, -0.0007],\n",
       "         [ 0.0820,  0.0366,  0.0589,  ..., -0.0196,  0.0838, -0.0586],\n",
       "         [-0.0607, -0.0771, -0.0723,  ..., -0.0076, -0.0235,  0.0809],\n",
       "         ...,\n",
       "         [-0.0646,  0.0845,  0.0328,  ...,  0.0031, -0.0508,  0.0602],\n",
       "         [ 0.1243, -0.1501,  0.1667,  ..., -0.0505,  0.1842, -0.0018],\n",
       "         [-0.1524,  0.0372, -0.0491,  ..., -0.0879, -0.0006,  0.0659]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.self_attn.linears.3.bias': tensor([-0.1902, -0.3487,  0.0257, -0.0219,  0.2095, -0.2814,  0.5065, -0.2038,\n",
       "         -0.0390, -0.0095, -0.0513, -0.0585, -0.1334, -0.1566,  0.0779, -0.0551,\n",
       "          0.0057, -0.0943,  0.0906,  0.2870,  0.1168, -0.2454, -0.1088, -0.1285,\n",
       "          0.0605,  0.2403,  0.4338, -0.2668, -0.2639,  0.0918,  0.1302, -0.2261,\n",
       "         -0.6439, -0.0050, -0.1484,  0.2231,  0.1046, -0.1255, -0.1081,  0.0219,\n",
       "          0.0869, -0.1596, -0.0411, -0.0755,  0.2451,  0.0292, -0.1397,  0.0522,\n",
       "          0.5707,  0.2532], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.feed_forward.bn.weight': tensor([0.8099, 0.6722, 1.1281, 1.0768, 1.0984, 1.0605, 1.0973, 0.8576, 0.8394,\n",
       "         1.0847, 1.1154, 0.8553, 0.8960, 0.5970, 1.3758, 1.1591, 0.8234, 0.7145,\n",
       "         0.8808, 0.9395, 0.8618, 0.9332, 0.7613, 0.7916, 1.1676, 1.0667, 1.1367,\n",
       "         0.8857, 1.1674, 1.0052, 1.0489, 0.7528, 0.6719, 1.2533, 0.7473, 1.0366,\n",
       "         0.8626, 1.1715, 0.9034, 1.0049, 1.0316, 0.9745, 1.0536, 0.8632, 1.0855,\n",
       "         1.2620, 0.8459, 0.8761, 1.4607, 0.9749], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.feed_forward.bn.bias': tensor([-0.2707, -0.3708, -0.0172, -0.0275,  0.0047, -0.0157,  0.1270, -0.2785,\n",
       "         -0.2563,  0.0065,  0.0974, -0.1458, -0.1513, -0.2782, -0.2095, -0.2123,\n",
       "         -0.2054, -0.2089, -0.2232, -0.0868, -0.1574, -0.0558, -0.4429, -0.1772,\n",
       "         -0.0334, -0.1026,  0.1070, -0.2843, -0.3208, -0.1803,  0.0571, -0.3528,\n",
       "         -0.4146,  0.0919, -0.3355, -0.0300, -0.2258, -0.1221, -0.1321, -0.0248,\n",
       "         -0.0557, -0.1941, -0.3737, -0.1649, -0.0252,  0.0878, -0.1182, -0.1656,\n",
       "          0.5967, -0.1735], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.feed_forward.bn.running_mean': tensor([ 0.0685,  0.0206, -0.0314, -0.0098,  0.2665, -0.0471,  0.1527,  0.2216,\n",
       "          0.1005,  0.0786,  0.0952,  0.0220,  0.2554,  0.0952,  0.0378,  0.0767,\n",
       "          0.1376,  0.1010,  0.1698,  0.1280,  0.0864,  0.0313,  0.0678,  0.1185,\n",
       "          0.0926,  0.0775,  0.0615,  0.0140,  0.1824,  0.1546,  0.0109, -0.0068,\n",
       "          0.0472,  0.1091,  0.0093,  0.1609,  0.0949, -0.0122,  0.0214,  0.0186,\n",
       "          0.0635, -0.1658,  0.0470,  0.0591,  0.1068, -0.0076, -0.0342, -0.0219,\n",
       "         -0.0004,  0.1474], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.feed_forward.bn.running_var': tensor([0.2192, 0.1185, 0.1579, 0.0420, 0.1115, 0.2235, 0.2043, 0.1005, 0.1118,\n",
       "         0.1413, 0.0455, 0.1445, 0.1278, 0.1170, 0.0206, 0.0540, 0.0619, 0.1283,\n",
       "         0.1254, 0.0962, 0.0376, 0.0211, 0.0558, 0.0757, 0.0876, 0.0428, 0.0540,\n",
       "         0.0401, 0.0641, 0.0853, 0.1586, 0.0236, 0.0994, 0.0797, 0.1527, 0.0871,\n",
       "         0.0883, 0.0105, 0.0919, 0.0617, 0.0542, 0.0740, 0.0230, 0.0314, 0.0614,\n",
       "         0.1591, 0.0318, 0.0977, 0.1330, 0.0850], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.feed_forward.bn.num_batches_tracked': tensor(213030),\n",
       " 'transformer_pre.model.layers.4.feed_forward.encoder_0.weight_ih_l0': tensor([[ 0.2098, -0.1469,  0.0689,  ...,  0.0041, -0.0396,  0.0345],\n",
       "         [-0.1653, -0.0485, -0.1565,  ..., -0.0185, -0.0704,  0.3207],\n",
       "         [-0.1060,  0.0654,  0.0085,  ...,  0.1516,  0.1218, -0.0163],\n",
       "         ...,\n",
       "         [-0.0834,  0.1973,  0.0335,  ...,  0.0344, -0.0056, -0.2096],\n",
       "         [-0.0270, -0.0790,  0.0289,  ...,  0.2019,  0.0100,  0.0110],\n",
       "         [-0.0459, -0.0748, -0.1464,  ..., -0.3947, -0.2872, -0.1091]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.feed_forward.encoder_0.weight_hh_l0': tensor([[-0.2280, -0.1709,  0.0150,  ...,  0.2796,  0.0017, -0.1403],\n",
       "         [-0.1064, -0.0139, -0.0686,  ..., -0.0960,  0.1321, -0.1560],\n",
       "         [ 0.1579, -0.1990,  0.1234,  ...,  0.0501,  0.1140,  0.3805],\n",
       "         ...,\n",
       "         [-0.0618,  0.0046, -0.1787,  ..., -0.2472,  0.1947, -0.2178],\n",
       "         [ 0.1143,  0.2711, -0.0144,  ...,  0.3148,  0.1989, -0.0396],\n",
       "         [ 0.0673, -0.1141, -0.0395,  ...,  0.1898,  0.0093,  0.1612]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.feed_forward.encoder_0.bias_ih_l0': tensor([-0.0482,  0.2077,  0.1370, -0.1638,  0.0935, -0.0828, -0.0801,  0.0567,\n",
       "         -0.0089, -0.0208,  0.0145,  0.0512,  0.0307, -0.0522, -0.1700, -0.2441,\n",
       "          0.0725, -0.3230,  0.0431,  0.0466, -0.1472, -0.1372, -0.4240,  0.0186,\n",
       "         -0.0861, -0.1870, -0.1972, -0.1498,  0.2851, -0.2360, -0.1981, -0.1540,\n",
       "         -0.2136, -0.2683,  0.0733, -0.0388, -0.1131, -0.2240, -0.0026, -0.0103,\n",
       "         -0.1418, -0.0063, -0.4248, -0.1108,  0.0286,  0.1734, -0.3174, -0.2541,\n",
       "         -0.0048, -0.5656, -0.0848, -0.1636,  0.1415,  0.1006, -0.2854, -0.0294,\n",
       "         -0.1187,  0.0174,  0.0613, -0.1399, -0.0790, -0.1222,  0.2017, -0.1732,\n",
       "         -0.2643, -0.1294, -0.1156, -0.2297, -0.0707,  0.1574, -0.3516, -0.1685,\n",
       "          0.0202,  0.1498,  0.1080, -0.0464, -0.0108, -0.0160,  0.2719, -0.2246,\n",
       "         -0.2481, -0.2451,  0.1863, -0.1260,  0.0210,  0.0448,  0.0989, -0.3991,\n",
       "         -0.0464, -0.0449, -0.0571, -0.0209, -0.2529,  0.1498, -0.1220,  0.0112,\n",
       "         -0.2134, -0.2351, -0.3790, -0.2854,  0.1937,  0.0424,  0.1645, -0.2061,\n",
       "          0.0337, -0.0963,  0.0068, -0.0258,  0.0813,  0.0899,  0.1382,  0.1015,\n",
       "          0.1744, -0.2374, -0.0690,  0.1726,  0.1083, -0.1420, -0.1208,  0.0293,\n",
       "         -0.0078, -0.0587, -0.2905, -0.0227, -0.0924,  0.0835, -0.1826,  0.0085,\n",
       "          0.0503, -0.0030, -0.0239, -0.0451, -0.0368,  0.1148,  0.0422,  0.0072,\n",
       "          0.0361,  0.0686, -0.2823,  0.0074,  0.1668, -0.0244,  0.0572,  0.0932,\n",
       "         -0.1505, -0.0874,  0.1260,  0.0726,  0.2247,  0.1249, -0.1072,  0.0323,\n",
       "          0.0286, -0.1811, -0.0501, -0.0267,  0.0425,  0.1587, -0.2216, -0.2347,\n",
       "         -0.3421,  0.0253,  0.1326, -0.1821, -0.3472, -0.1965, -0.0421,  0.0774,\n",
       "         -0.0598,  0.2446, -0.0358, -0.2339, -0.0513,  0.1585, -0.0378, -0.1203,\n",
       "         -0.1972,  0.0802,  0.0645, -0.4856, -0.1450, -0.1218, -0.2744, -0.1908,\n",
       "         -0.0663, -0.1508,  0.0045, -0.2924, -0.1288, -0.0946, -0.1564, -0.0997,\n",
       "         -0.2060,  0.0973, -0.1001,  0.2687, -0.5476, -0.1081, -0.0950, -0.2331],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.feed_forward.encoder_0.bias_hh_l0': tensor([ 0.1073,  0.2209,  0.2616, -0.2683, -0.0508,  0.0402, -0.0836, -0.0639,\n",
       "          0.0346, -0.0985, -0.0973, -0.0286,  0.0974, -0.2311, -0.1550, -0.0284,\n",
       "          0.0616, -0.2789, -0.0037,  0.1711, -0.1326, -0.1559, -0.2669, -0.0185,\n",
       "         -0.1903, -0.2741,  0.0332, -0.1168,  0.0689, -0.1596, -0.2176, -0.1816,\n",
       "         -0.0884, -0.1241,  0.1988,  0.1488, -0.0834, -0.2946, -0.1673, -0.0956,\n",
       "         -0.2000, -0.1640, -0.4654, -0.0333,  0.1573,  0.2651, -0.2132, -0.0384,\n",
       "         -0.0996, -0.5163, -0.2094, -0.1151,  0.1625, -0.0641, -0.2061,  0.1124,\n",
       "         -0.1721,  0.2062, -0.0885, -0.0783, -0.0358,  0.0424,  0.1639, -0.2359,\n",
       "         -0.3408, -0.2654, -0.2199, -0.2255, -0.0707,  0.2714, -0.2582, -0.2739,\n",
       "         -0.1594, -0.0656,  0.0624, -0.2012, -0.1688,  0.1802,  0.1065, -0.2566,\n",
       "         -0.1649, -0.0582, -0.0705, -0.2831, -0.1381, -0.0275, -0.1092, -0.2783,\n",
       "         -0.2036, -0.1427, -0.0487,  0.0118, -0.2916,  0.3045, -0.0643,  0.2138,\n",
       "         -0.2209, -0.2843, -0.4831, -0.3571, -0.0691,  0.0902,  0.0430, -0.2351,\n",
       "         -0.0271, -0.0684,  0.0681,  0.0006, -0.1007, -0.0458,  0.1265,  0.1397,\n",
       "          0.1944, -0.0699, -0.0770,  0.0125,  0.2073, -0.0875,  0.1461,  0.0447,\n",
       "         -0.2115, -0.0508, -0.1694,  0.0943, -0.2783, -0.0745, -0.0665, -0.0111,\n",
       "          0.0293,  0.1939,  0.0147, -0.1373,  0.0509, -0.1523,  0.0418,  0.0919,\n",
       "          0.0271,  0.0651, -0.2805, -0.0490,  0.1946,  0.1046,  0.0033,  0.0037,\n",
       "         -0.1016,  0.0098, -0.1326, -0.0610,  0.1024,  0.1435, -0.0953, -0.0816,\n",
       "          0.0991, -0.0965, -0.1540, -0.1799,  0.0333,  0.0306, -0.0395, -0.0766,\n",
       "         -0.2903, -0.1647,  0.0290, -0.2610, -0.2544, -0.2842, -0.0718, -0.0141,\n",
       "         -0.2692,  0.1181, -0.1603, -0.2219, -0.2411, -0.0376, -0.1179, -0.1997,\n",
       "         -0.1524, -0.0852,  0.1231, -0.2357, -0.1973, -0.1257, -0.3067, -0.4011,\n",
       "         -0.0570,  0.0071,  0.0811, -0.3158, -0.1823,  0.1070, -0.0332, -0.1979,\n",
       "         -0.2774, -0.0612, -0.0748,  0.1503, -0.4342, -0.1425,  0.0374, -0.2247],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.feed_forward.encoder_1.weight_ih_l0': tensor([[-0.1587, -0.3402, -0.0767,  ..., -0.1534,  0.2667,  0.2761],\n",
       "         [-0.0389,  0.0365,  0.0817,  ...,  0.0103, -0.0269, -0.1466],\n",
       "         [ 0.4559, -0.0509,  0.0282,  ...,  0.1689, -0.1757, -0.1726],\n",
       "         ...,\n",
       "         [ 0.0584,  0.3078,  0.1146,  ..., -0.1705, -0.3306, -0.2384],\n",
       "         [ 0.1164, -0.0161, -0.0179,  ..., -0.1756,  0.3037, -0.2579],\n",
       "         [-0.2061, -0.0469, -0.4117,  ..., -0.1809, -0.0254,  0.0945]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.feed_forward.encoder_1.weight_hh_l0': tensor([[ 5.3386e-02,  7.5378e-02,  1.1971e-01,  ..., -2.2511e-01,\n",
       "           7.6363e-02, -1.0029e-01],\n",
       "         [ 3.2505e-02,  2.7150e-02, -2.7468e-02,  ..., -3.7268e-01,\n",
       "           8.2046e-02,  3.6994e-02],\n",
       "         [-8.4287e-02, -7.4453e-02, -1.5745e-01,  ..., -2.4193e-02,\n",
       "          -1.1646e-02, -1.9668e-01],\n",
       "         ...,\n",
       "         [ 1.1742e-01,  2.7247e-02, -9.4954e-02,  ..., -2.5455e-02,\n",
       "          -8.9803e-02,  4.8100e-02],\n",
       "         [ 2.0688e-01,  2.4873e-01, -3.0030e-04,  ...,  1.5766e-01,\n",
       "           1.2436e-01, -5.2148e-02],\n",
       "         [-2.4012e-02,  1.3916e-01,  8.8781e-03,  ..., -7.9015e-02,\n",
       "           2.0363e-01, -2.8923e-01]], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.feed_forward.encoder_1.bias_ih_l0': tensor([ 0.1214, -0.0321, -0.0881,  0.0211,  0.1791,  0.1550,  0.1024, -0.0430,\n",
       "         -0.0208,  0.0065,  0.0787, -0.0017,  0.0064,  0.1077, -0.2624, -0.2526,\n",
       "          0.0140,  0.1527, -0.1429, -0.2170,  0.0015,  0.0415, -0.1301, -0.0354,\n",
       "         -0.1753, -0.3445,  0.0327, -0.3167, -0.4483, -0.0882,  0.0500, -0.1023,\n",
       "         -0.1677, -0.1749,  0.0750, -0.0901, -0.1208, -0.1720, -0.0164, -0.1575,\n",
       "         -0.0283,  0.0830, -0.6114,  0.2404, -0.0527,  0.1963, -0.1232, -0.2649,\n",
       "         -0.0455, -0.1736,  0.0267, -0.4258, -0.0649, -0.1609, -0.3322,  0.2036,\n",
       "          0.1240, -0.0180, -0.0180, -0.0801, -0.3119,  0.0227,  0.0622,  0.1008,\n",
       "          0.0116, -0.1408, -0.0402, -0.0970, -0.0066, -0.1964,  0.0772, -0.0440,\n",
       "         -0.0267, -0.1339, -0.1370, -0.2111,  0.0331, -0.3743, -0.3481, -0.0546,\n",
       "          0.1434, -0.1275, -0.2090, -0.0451, -0.0232,  0.0176,  0.1629,  0.0072,\n",
       "          0.0776, -0.3663, -0.0327, -0.1556, -0.3429, -0.0674,  0.1068,  0.0458,\n",
       "         -0.0756, -0.1462,  0.0091,  0.0088, -0.1090, -0.0705, -0.0453, -0.0231,\n",
       "          0.0605, -0.0636, -0.1619,  0.1465,  0.1338,  0.0515, -0.0166, -0.0905,\n",
       "          0.1120,  0.1688,  0.1292,  0.0654, -0.1066,  0.0227,  0.1742, -0.1772,\n",
       "          0.0071, -0.0086, -0.1538,  0.0435, -0.0132,  0.3096,  0.1620, -0.1314,\n",
       "         -0.1827,  0.0468,  0.0070,  0.0458, -0.2054,  0.1553,  0.0499,  0.2818,\n",
       "         -0.1246, -0.2920,  0.1666, -0.0102,  0.1569, -0.2206, -0.2069,  0.0026,\n",
       "          0.1832,  0.0353,  0.1406,  0.1735,  0.0273, -0.0624, -0.0348, -0.2325,\n",
       "         -0.0771, -0.1611,  0.1408,  0.2492, -0.0194, -0.1874,  0.0494, -0.1105,\n",
       "          0.0026,  0.1605,  0.0419,  0.1976, -0.0386, -0.2043, -0.1652,  0.1205,\n",
       "         -0.1347, -0.1301, -0.1766, -0.0016, -0.2018,  0.1616, -0.3941, -0.1491,\n",
       "         -0.0653, -0.4805, -0.3862,  0.1413, -0.0524, -0.0740, -0.1215,  0.0341,\n",
       "         -0.1460, -0.4209, -0.0750, -0.3142, -0.2775, -0.1086, -0.0142,  0.3060,\n",
       "         -0.5004, -0.1376, -0.2697,  0.1252, -0.0433, -0.2091, -0.1976, -0.1688],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.feed_forward.encoder_1.bias_hh_l0': tensor([-0.1131, -0.2180, -0.1910, -0.1502,  0.2330,  0.1725,  0.1311, -0.1209,\n",
       "          0.0920,  0.1206, -0.1428, -0.0650,  0.0208,  0.1751, -0.1687, -0.2257,\n",
       "         -0.0329, -0.0642, -0.0664, -0.1479, -0.1754, -0.0940, -0.1293, -0.0227,\n",
       "         -0.2647, -0.2307, -0.0898, -0.2529, -0.2900, -0.0210,  0.1140, -0.3091,\n",
       "         -0.2826,  0.0219,  0.0571, -0.1283, -0.0719, -0.2607,  0.1202, -0.2186,\n",
       "         -0.1919,  0.0609, -0.3932,  0.1140,  0.0509,  0.2877, -0.0489, -0.2790,\n",
       "         -0.2075, -0.1432,  0.0546, -0.3136, -0.0832, -0.3317, -0.3107,  0.2576,\n",
       "          0.0982,  0.1039, -0.1778, -0.2833, -0.3275,  0.1056,  0.1531,  0.0414,\n",
       "          0.0656, -0.0953, -0.1415, -0.0320, -0.0807, -0.0704, -0.0594,  0.0553,\n",
       "         -0.1407, -0.1945, -0.2179, -0.1250, -0.1187, -0.3606, -0.3413,  0.0464,\n",
       "          0.0277, -0.2911, -0.0547, -0.1912,  0.0518, -0.0503,  0.0903, -0.0531,\n",
       "         -0.0340, -0.3512, -0.0961, -0.1455, -0.4011,  0.0815,  0.0077,  0.1405,\n",
       "         -0.0708, -0.2525,  0.0596,  0.1196,  0.1284,  0.0426,  0.1199, -0.0906,\n",
       "          0.0623,  0.0683,  0.0162,  0.0093,  0.0763,  0.0705,  0.0659, -0.0418,\n",
       "          0.0909,  0.2955,  0.1228, -0.0213, -0.0965,  0.0647,  0.2255,  0.0143,\n",
       "          0.0538, -0.1792, -0.0089,  0.0959, -0.0950,  0.3888,  0.1847, -0.1672,\n",
       "         -0.2534, -0.0109, -0.0575,  0.0024, -0.0175,  0.1338,  0.1101,  0.2579,\n",
       "          0.0182, -0.1196,  0.0732, -0.0858,  0.1031, -0.2461, -0.0249,  0.0318,\n",
       "          0.0443,  0.0037,  0.2263,  0.2065,  0.0090,  0.1000,  0.0988, -0.3281,\n",
       "         -0.0026,  0.0046, -0.0735,  0.3436, -0.0868, -0.1126, -0.0306, -0.1818,\n",
       "         -0.1816,  0.1741,  0.0991,  0.2425, -0.1101, -0.1379, -0.1088, -0.1167,\n",
       "         -0.2100, -0.1217, -0.1459, -0.0518, -0.0164,  0.0113, -0.3230, -0.1605,\n",
       "         -0.1188, -0.2996, -0.4059, -0.0464,  0.0556, -0.0768, -0.2326, -0.0221,\n",
       "         -0.1279, -0.4292, -0.2047, -0.3366, -0.1190, -0.0548, -0.0411,  0.4242,\n",
       "         -0.4829, -0.2430, -0.0486,  0.0202, -0.1204, -0.2004, -0.0372, -0.0399],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.feed_forward.encoder_2.weight_ih_l0': tensor([[ 0.0946, -0.1377, -0.1380,  ..., -0.1547, -0.0333, -0.0238],\n",
       "         [ 0.1455,  0.1948, -0.0069,  ...,  0.0636,  0.1644,  0.1560],\n",
       "         [-0.2347,  0.0010, -0.1146,  ...,  0.0467,  0.0062,  0.2476],\n",
       "         ...,\n",
       "         [ 0.1405,  0.0471,  0.2374,  ...,  0.1189, -0.1381, -0.1245],\n",
       "         [-0.1343, -0.1757, -0.0198,  ...,  0.2183,  0.1220,  0.0638],\n",
       "         [ 0.0527,  0.0003, -0.0781,  ...,  0.0876,  0.0922,  0.1385]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.feed_forward.encoder_2.weight_hh_l0': tensor([[-0.1220,  0.1596, -0.0227,  ..., -0.4012,  0.0789,  0.0549],\n",
       "         [-0.3199, -0.0664, -0.0960,  ..., -0.0479, -0.0005, -0.1017],\n",
       "         [-0.1095,  0.0525, -0.0743,  ...,  0.0359,  0.0775,  0.0922],\n",
       "         ...,\n",
       "         [-0.0725, -0.0247,  0.1294,  ...,  0.2049,  0.1847, -0.0018],\n",
       "         [ 0.0724, -0.1173,  0.1941,  ..., -0.1476, -0.3014,  0.1820],\n",
       "         [ 0.1803,  0.1435,  0.0990,  ...,  0.0947,  0.0471, -0.1132]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.feed_forward.encoder_2.bias_ih_l0': tensor([ 0.1333, -0.2565,  0.0093, -0.0790, -0.0099, -0.2115, -0.0049,  0.1038,\n",
       "         -0.1796,  0.2855, -0.1506, -0.0375, -0.2495, -0.1318, -0.4080, -0.0480,\n",
       "         -0.2089, -0.0973, -0.0813, -0.2495, -0.2749, -0.2469,  0.0530, -0.1157,\n",
       "         -0.2497, -0.0302, -0.0252, -0.1195, -0.3584, -0.3153, -0.0040, -0.1837,\n",
       "          0.2322,  0.0179,  0.1284, -0.0215, -0.2061, -0.3070, -0.2121,  0.1909,\n",
       "         -0.2022, -0.1146, -0.2734, -0.4017, -0.0465,  0.1762, -0.3415,  0.1053,\n",
       "         -0.0434,  0.0041,  0.3546, -0.1095, -0.0461, -0.0740, -0.2475, -0.0008,\n",
       "         -0.2974, -0.0193, -0.2940, -0.1994, -0.5964,  0.0545, -0.2242,  0.0331,\n",
       "         -0.2647, -0.1312,  0.0268, -0.0612, -0.2702, -0.1380, -0.4892, -0.1164,\n",
       "         -0.1225, -0.2354, -0.3004, -0.1338, -0.1014,  0.0975, -0.2498, -0.2334,\n",
       "         -0.0735,  0.1320,  0.1516, -0.1678, -0.1017, -0.0902, -0.3511, -0.2173,\n",
       "          0.0461,  0.0521, -0.0356, -0.0680, -0.2780, -0.1234, -0.1019, -0.2672,\n",
       "         -0.2214, -0.1475, -0.2468, -0.1739,  0.1500,  0.0253, -0.1791,  0.0752,\n",
       "          0.1587,  0.2173,  0.0184, -0.0131, -0.0432, -0.3425,  0.0783, -0.0066,\n",
       "         -0.0349,  0.0054, -0.1250, -0.0678,  0.0148,  0.0409,  0.0682, -0.0786,\n",
       "         -0.0531, -0.1480,  0.1337, -0.3182, -0.0111,  0.0512, -0.0205, -0.0359,\n",
       "          0.0991,  0.1440,  0.0291,  0.0490, -0.1094, -0.0622, -0.0075, -0.0752,\n",
       "         -0.1996, -0.0620,  0.0173, -0.0331, -0.0648, -0.0878, -0.0957,  0.0328,\n",
       "          0.1540,  0.2606, -0.0298, -0.1446,  0.1470, -0.0438,  0.0823, -0.0828,\n",
       "          0.0766, -0.2415, -0.0307, -0.1335, -0.1003, -0.2903, -0.1036, -0.0880,\n",
       "          0.0559, -0.1670, -0.0456, -0.0175, -0.2192, -0.0272, -0.2327, -0.2126,\n",
       "          0.0062, -0.2804, -0.4529, -0.1205, -0.0093, -0.1688, -0.1791, -0.1271,\n",
       "         -0.1628,  0.0552, -0.3361, -0.1388,  0.0373, -0.2554,  0.0048, -0.2177,\n",
       "         -0.0082, -0.0586, -0.3784, -0.3756,  0.1477, -0.2011, -0.1755, -0.2040,\n",
       "         -0.1967, -0.2026, -0.4396,  0.2019, -0.1573, -0.0979, -0.1089, -0.0081],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.feed_forward.encoder_2.bias_hh_l0': tensor([ 0.0193, -0.0210, -0.0086, -0.0547,  0.0259, -0.2362,  0.0986, -0.0917,\n",
       "         -0.1487,  0.0950, -0.2279, -0.1578, -0.2296, -0.0887, -0.4693,  0.0362,\n",
       "         -0.2247, -0.1632, -0.2357, -0.1908, -0.2703, -0.2827, -0.0630, -0.1767,\n",
       "         -0.1402, -0.1191,  0.0384, -0.2031, -0.2853, -0.1203, -0.0686, -0.2930,\n",
       "          0.2396, -0.2413,  0.0777, -0.0037, -0.2363, -0.4920, -0.2146,  0.2477,\n",
       "         -0.0891, -0.1385, -0.3331, -0.2148, -0.2698,  0.1653, -0.1790,  0.0670,\n",
       "         -0.1310, -0.1368,  0.1349, -0.3349, -0.2586,  0.0652, -0.3150, -0.0854,\n",
       "         -0.3230, -0.0120, -0.2998, -0.2339, -0.5930,  0.0763, -0.1855, -0.1808,\n",
       "         -0.0536, -0.2365,  0.0172,  0.0202, -0.1488, -0.1367, -0.5521, -0.3380,\n",
       "         -0.0642, -0.3721, -0.2883, -0.2392, -0.1949, -0.0777, -0.0702, -0.0963,\n",
       "          0.0038, -0.0321,  0.2475, -0.1577,  0.0281, -0.2000, -0.1767, -0.2901,\n",
       "          0.1321, -0.1244, -0.1897, -0.1572, -0.1055, -0.1886, -0.2496, -0.1967,\n",
       "         -0.2867, -0.0942, -0.2754, -0.1347,  0.1189,  0.0362, -0.3899,  0.1630,\n",
       "         -0.0150, -0.0495,  0.2263,  0.1676,  0.0624, -0.0779,  0.0587,  0.0113,\n",
       "          0.1235, -0.0780,  0.0894, -0.0047,  0.1670,  0.1169, -0.0827,  0.1031,\n",
       "          0.0510, -0.0809,  0.1009, -0.0900,  0.0336,  0.2036, -0.0469,  0.0370,\n",
       "         -0.0893,  0.0804, -0.0080, -0.1194,  0.1234, -0.0112, -0.1738,  0.1260,\n",
       "         -0.1390,  0.0056,  0.0351,  0.0469, -0.0790,  0.0370,  0.0679, -0.1331,\n",
       "          0.1512,  0.2601, -0.0354, -0.2164, -0.0220, -0.1394,  0.1409, -0.0462,\n",
       "          0.0344, -0.1211, -0.0563, -0.0097,  0.0349, -0.1412, -0.2298, -0.0431,\n",
       "         -0.0316, -0.1255, -0.0445, -0.0971, -0.2504,  0.1038, -0.0715, -0.0788,\n",
       "          0.0072, -0.2881, -0.5864, -0.1837,  0.0090, -0.0939, -0.0805,  0.0267,\n",
       "         -0.2151, -0.1870, -0.2349, -0.0330, -0.1158, -0.3409,  0.0537, -0.1977,\n",
       "         -0.1917, -0.1920, -0.3335, -0.2698,  0.2071, -0.1119, -0.0846, -0.3239,\n",
       "         -0.1280, -0.0071, -0.3440,  0.1307, -0.3552, -0.0671,  0.1131, -0.2442],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.sublayer.0.norm.a_2': tensor([0.4098, 0.7054, 0.5845, 0.5014, 0.4064, 0.8490, 0.6415, 0.3339, 0.6321,\n",
       "         0.2014, 0.8710, 0.7736, 0.6853, 0.3382, 0.5407, 0.8363, 0.6139, 0.5971,\n",
       "         0.3526, 0.5263, 0.3717, 0.2722, 0.5865, 0.5495, 0.3191, 0.6367, 0.6147,\n",
       "         0.5681, 0.7119, 0.4159, 0.2050, 0.7176, 0.4374, 0.2993, 0.3778, 0.5802,\n",
       "         0.2812, 0.5428, 0.5667, 0.2001, 0.5832, 0.3723, 0.4291, 0.6414, 0.4692,\n",
       "         0.2491, 0.4018, 0.7072, 0.3755, 0.3867], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.sublayer.0.norm.b_2': tensor([-7.2116e-02,  2.8571e-01, -3.3658e-02,  3.2976e-02, -1.2052e-01,\n",
       "         -1.1889e-02, -2.0166e-01,  1.0186e-02,  1.4817e-02, -5.4366e-02,\n",
       "          3.1082e-02,  9.0581e-02,  8.9560e-02,  1.1767e-01,  1.1983e-03,\n",
       "          4.9396e-02,  2.8023e-02,  6.0398e-02, -7.3572e-02, -1.6595e-01,\n",
       "         -8.0371e-02,  1.7140e-01,  9.1384e-02,  2.7855e-02, -3.7990e-02,\n",
       "         -1.6745e-01, -1.6888e-01,  1.5408e-01,  6.2633e-02, -1.6840e-01,\n",
       "         -8.7555e-02,  8.6802e-02,  2.1972e-01,  1.3046e-01, -5.3209e-02,\n",
       "         -6.4948e-02, -2.2264e-02,  8.1577e-02, -3.5131e-02, -1.2412e-01,\n",
       "         -1.0894e-03,  2.2673e-01, -8.6405e-02, -9.4059e-05, -1.0922e-01,\n",
       "          6.9729e-02,  5.8040e-02,  1.0089e-01, -2.4522e-01, -1.2936e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.sublayer.1.norm.a_2': tensor([1.1644, 0.9849, 1.2346, 1.0772, 1.0388, 1.1995, 0.9511, 0.7037, 0.8704,\n",
       "         0.9774, 0.9734, 1.2452, 0.7279, 0.4433, 1.0061, 1.3127, 0.7454, 1.0858,\n",
       "         0.6844, 0.8972, 1.2063, 0.7332, 0.7958, 0.5819, 0.9250, 1.3357, 0.8969,\n",
       "         1.3066, 1.0325, 1.1305, 0.6124, 1.0524, 1.0708, 1.0858, 0.7450, 0.6708,\n",
       "         0.7057, 1.2882, 1.1963, 0.9665, 1.0250, 0.9353, 0.6019, 0.6267, 0.9437,\n",
       "         1.1465, 0.7307, 0.9132, 0.5715, 0.8757], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.4.sublayer.1.norm.b_2': tensor([ 0.0112,  0.1244,  0.0522,  0.1032, -0.0083,  0.0464,  0.0061, -0.0326,\n",
       "          0.0436,  0.0738, -0.0078,  0.1373, -0.0010,  0.0732, -0.0432, -0.1128,\n",
       "          0.0237,  0.1125, -0.0330,  0.0460, -0.0341,  0.0077,  0.0232,  0.0655,\n",
       "          0.1280, -0.1010, -0.0876,  0.1021,  0.0280,  0.0670,  0.0201, -0.0510,\n",
       "          0.2251,  0.1074, -0.1789,  0.0803, -0.0154, -0.1672, -0.0966, -0.1930,\n",
       "          0.1957,  0.0251, -0.1061,  0.1005,  0.0724,  0.0503,  0.0178,  0.0977,\n",
       "         -0.3983,  0.1307], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.self_attn.linears.0.weight': tensor([[-0.3550, -0.0918, -0.0261,  ..., -0.0339, -0.0525,  0.0321],\n",
       "         [ 0.2145,  0.1981, -0.2168,  ..., -0.1219, -0.2746, -0.1102],\n",
       "         [-0.2743, -0.0303, -0.0080,  ...,  0.0288,  0.1861,  0.0969],\n",
       "         ...,\n",
       "         [-0.0159, -0.1212, -0.0474,  ...,  0.1172,  0.1209,  0.1238],\n",
       "         [-0.0304, -0.2319, -0.0201,  ...,  0.0093,  0.4715,  0.0866],\n",
       "         [-0.0217,  0.2703, -0.0474,  ..., -0.0014, -0.3106, -0.1438]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.self_attn.linears.0.bias': tensor([-0.2720, -0.4405,  0.0612, -0.4808,  0.0676,  0.0437,  0.3196, -0.4740,\n",
       "         -0.0278,  0.1043,  0.0531,  0.0189,  0.0232,  0.0010,  0.0646, -0.4328,\n",
       "          0.1444,  0.1071, -0.3181,  0.2842,  0.0234, -0.5035,  0.0309, -0.2333,\n",
       "         -0.0316,  0.2319,  0.4333, -0.1651, -0.3164,  0.0698, -0.1474,  0.5856,\n",
       "         -0.1081, -0.2980, -0.2021,  0.0834, -0.2971,  0.1100, -0.4641, -0.0439,\n",
       "          0.5890, -0.4280, -0.0415,  0.3571,  0.1166, -0.2953,  0.3309,  0.3205,\n",
       "          0.1951, -0.0080], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.self_attn.linears.1.weight': tensor([[ 0.0177, -0.0402, -0.0975,  ..., -0.3111, -0.0600,  0.0878],\n",
       "         [ 0.0145,  0.1211, -0.0464,  ...,  0.2652, -0.0119, -0.1476],\n",
       "         [-0.0778, -0.0696, -0.1341,  ..., -0.1998,  0.1344,  0.2625],\n",
       "         ...,\n",
       "         [ 0.0034,  0.0591, -0.0246,  ..., -0.3550,  0.1750,  0.1549],\n",
       "         [ 0.1369,  0.1702,  0.1015,  ..., -0.0596, -0.0130,  0.2862],\n",
       "         [-0.2290, -0.2913, -0.0334,  ..., -0.0511,  0.1592, -0.2097]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.self_attn.linears.1.bias': tensor([-0.0789, -0.1411, -0.0460, -0.0866,  0.0874, -0.0903,  0.0955, -0.1204,\n",
       "         -0.0193, -0.1312,  0.1102, -0.1048,  0.0410, -0.1079,  0.0975, -0.0970,\n",
       "          0.1302,  0.0401, -0.0026,  0.1350,  0.0527, -0.0560,  0.1290, -0.1341,\n",
       "          0.1307,  0.1356,  0.1026, -0.0706, -0.0911,  0.0842,  0.0821,  0.1341,\n",
       "         -0.1218, -0.0806, -0.1367,  0.1334,  0.0300,  0.1203, -0.0412, -0.1075,\n",
       "          0.1184,  0.0117, -0.0881,  0.0003,  0.1279, -0.0429, -0.0396,  0.0975,\n",
       "         -0.0364,  0.0842], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.self_attn.linears.2.weight': tensor([[-0.0398, -0.1855,  0.0413,  ..., -0.0459, -0.0880,  0.0320],\n",
       "         [ 0.0020,  0.0643,  0.0677,  ..., -0.0477,  0.1607, -0.0202],\n",
       "         [-0.0655,  0.0193,  0.0014,  ...,  0.0669, -0.0879,  0.1078],\n",
       "         ...,\n",
       "         [ 0.1088,  0.0866, -0.0017,  ...,  0.0083, -0.0273,  0.0995],\n",
       "         [ 0.0744, -0.0902,  0.0611,  ...,  0.0217,  0.0466, -0.0845],\n",
       "         [-0.0958,  0.1728, -0.0129,  ..., -0.0628,  0.0022,  0.0003]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.self_attn.linears.2.bias': tensor([-0.0199, -0.0536, -0.0364, -0.0874,  0.0693, -0.1104,  0.1207, -0.1003,\n",
       "         -0.0024,  0.0553,  0.0653, -0.0981, -0.0078, -0.0306,  0.0447, -0.1436,\n",
       "          0.1649,  0.0338, -0.0117,  0.0747,  0.0550,  0.0011,  0.0442, -0.1088,\n",
       "          0.1024,  0.0056,  0.1436,  0.0095,  0.0173, -0.0407,  0.0896,  0.0764,\n",
       "         -0.0979, -0.0231, -0.0121,  0.1097,  0.1226,  0.0141, -0.0165, -0.1521,\n",
       "         -0.0599,  0.0359, -0.0728,  0.0445,  0.1259, -0.0097,  0.0139,  0.0658,\n",
       "         -0.0546,  0.0411], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.self_attn.linears.3.weight': tensor([[ 0.0510, -0.0697,  0.0307,  ..., -0.0966, -0.0881, -0.0373],\n",
       "         [ 0.0046,  0.0094,  0.1380,  ..., -0.0175,  0.1118, -0.0862],\n",
       "         [-0.0057,  0.0124, -0.0682,  ..., -0.0132, -0.0663,  0.0459],\n",
       "         ...,\n",
       "         [-0.0018,  0.1316,  0.0376,  ..., -0.0542, -0.0226,  0.0888],\n",
       "         [ 0.0718, -0.1395,  0.0935,  ..., -0.0736,  0.2088,  0.0450],\n",
       "         [-0.1053,  0.1358, -0.0452,  ..., -0.1793,  0.0173,  0.0695]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.self_attn.linears.3.bias': tensor([-1.9600e-01, -2.5114e-01, -4.7472e-02, -2.9944e-02,  1.9125e-01,\n",
       "         -2.4845e-01,  5.4322e-01, -1.9943e-01, -1.1481e-01,  4.4583e-02,\n",
       "         -2.1691e-04,  6.6274e-02, -1.4915e-01, -7.1856e-02,  1.1367e-01,\n",
       "         -1.3343e-01, -4.3106e-02, -1.0905e-01,  8.1063e-02,  1.7905e-01,\n",
       "          1.1831e-01, -2.4412e-01, -3.2431e-02, -1.4948e-01,  1.0941e-01,\n",
       "          1.2947e-01,  2.9619e-01, -3.8708e-01, -1.6143e-01,  6.4724e-02,\n",
       "          1.8539e-01, -1.9505e-01, -7.4884e-01,  9.5822e-02, -1.8013e-01,\n",
       "          1.5541e-01,  1.1143e-01, -4.6167e-02, -4.5317e-02,  1.2551e-02,\n",
       "         -9.6537e-03, -5.4085e-02, -2.8056e-02, -1.3313e-01,  2.7662e-01,\n",
       "         -2.9900e-02, -9.4957e-02, -6.1359e-02,  5.7650e-01,  1.5965e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.feed_forward.bn.weight': tensor([0.6726, 0.7688, 0.9873, 0.8938, 0.8886, 0.8886, 1.1276, 0.9115, 0.8391,\n",
       "         0.9193, 1.0291, 0.9405, 0.9455, 0.6579, 1.4207, 1.0125, 0.6698, 1.0662,\n",
       "         0.7330, 0.9784, 0.7947, 1.0072, 0.6224, 0.7630, 1.0864, 0.9307, 0.9589,\n",
       "         0.5502, 1.2154, 0.9066, 0.9048, 0.7437, 0.5917, 1.3503, 0.6816, 0.8380,\n",
       "         0.6906, 1.2248, 1.1397, 0.9687, 0.9941, 1.1652, 1.0120, 0.6767, 1.0091,\n",
       "         1.2333, 0.9112, 0.7962, 1.5702, 1.0729], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.feed_forward.bn.bias': tensor([-0.3199, -0.2730, -0.1442, -0.1681, -0.2469, -0.1236,  0.1774, -0.2562,\n",
       "         -0.2897, -0.0129, -0.0240, -0.0378, -0.0863, -0.4536,  0.0324, -0.1411,\n",
       "         -0.3902, -0.0293, -0.2112,  0.0072, -0.1849, -0.0968, -0.2845, -0.2429,\n",
       "         -0.2002, -0.1775, -0.0942, -0.4287, -0.2279, -0.2067, -0.1922, -0.4862,\n",
       "         -0.5253,  0.2103, -0.1859, -0.2591, -0.2732, -0.2077,  0.1160, -0.1048,\n",
       "         -0.0829, -0.0525, -0.3743, -0.2312,  0.0370, -0.0504, -0.1028, -0.2585,\n",
       "          0.3959, -0.0400], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.feed_forward.bn.running_mean': tensor([-0.1674,  0.0330, -0.0573,  0.0118,  0.0388,  0.0169,  0.0136,  0.1242,\n",
       "          0.1237,  0.0769,  0.0444,  0.1347,  0.2500,  0.1678,  0.1057,  0.0269,\n",
       "         -0.1414,  0.0788,  0.0737,  0.0170,  0.0976,  0.0116,  0.0887,  0.0746,\n",
       "          0.1698,  0.1127,  0.0676,  0.0617, -0.1004,  0.1232,  0.0119,  0.1132,\n",
       "          0.0385,  0.1227, -0.0271,  0.0705, -0.1709,  0.0116,  0.0319,  0.1262,\n",
       "          0.0418, -0.0799,  0.0258,  0.1153,  0.1587, -0.0382, -0.0384, -0.0567,\n",
       "          0.1047,  0.2243], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.feed_forward.bn.running_var': tensor([0.1732, 0.0957, 0.1325, 0.0649, 0.1587, 0.1226, 0.1449, 0.1958, 0.0856,\n",
       "         0.3003, 0.0368, 0.1084, 0.1154, 0.1608, 0.0636, 0.0605, 0.1508, 0.0686,\n",
       "         0.1645, 0.1560, 0.0926, 0.0272, 0.1673, 0.1102, 0.0548, 0.1184, 0.1280,\n",
       "         0.1446, 0.0511, 0.0750, 0.2238, 0.0683, 0.0283, 0.0405, 0.0482, 0.0311,\n",
       "         0.0952, 0.0041, 0.1227, 0.0680, 0.2289, 0.0697, 0.0737, 0.0985, 0.0930,\n",
       "         0.0538, 0.0677, 0.1147, 0.0950, 0.1097], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.feed_forward.bn.num_batches_tracked': tensor(213030),\n",
       " 'transformer_pre.model.layers.5.feed_forward.encoder_0.weight_ih_l0': tensor([[ 0.0467, -0.1336, -0.0169,  ..., -0.0608, -0.1244,  0.1105],\n",
       "         [-0.0109, -0.1000,  0.0236,  ..., -0.1398,  0.0734,  0.1235],\n",
       "         [ 0.1599,  0.0315, -0.1289,  ...,  0.0815, -0.0366, -0.1521],\n",
       "         ...,\n",
       "         [ 0.1443,  0.1512,  0.1805,  ...,  0.0787, -0.0245, -0.4004],\n",
       "         [-0.0377, -0.0119, -0.0705,  ...,  0.1947,  0.0550, -0.4084],\n",
       "         [-0.0208,  0.0100,  0.0417,  ..., -0.2006, -0.0989,  0.1592]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.feed_forward.encoder_0.weight_hh_l0': tensor([[-0.2355, -0.1108, -0.0469,  ..., -0.1108,  0.0527, -0.0622],\n",
       "         [ 0.0794,  0.1331,  0.1247,  ..., -0.0649,  0.0985,  0.1982],\n",
       "         [-0.0393, -0.1547,  0.0589,  ..., -0.1509,  0.2282,  0.0517],\n",
       "         ...,\n",
       "         [ 0.1304,  0.1849, -0.0156,  ..., -0.2027,  0.4256, -0.0851],\n",
       "         [-0.0059, -0.1516, -0.2793,  ...,  0.1677, -0.0350, -0.1586],\n",
       "         [ 0.0342, -0.1213, -0.1683,  ...,  0.1715,  0.0443, -0.3620]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.feed_forward.encoder_0.bias_ih_l0': tensor([ 5.6640e-03,  7.5295e-02,  3.9097e-02, -2.4530e-01,  2.6557e-01,\n",
       "         -2.0673e-01, -1.9218e-01,  2.2526e-01, -3.6158e-01,  1.4248e-01,\n",
       "         -1.2967e-01,  1.3990e-01, -4.2661e-03,  1.1349e-01,  7.4311e-02,\n",
       "         -1.3087e-01, -2.6100e-02, -1.6631e-01,  2.9230e-02,  9.0822e-02,\n",
       "         -1.2831e-01, -9.8258e-02, -3.1321e-01, -1.2067e-01, -3.9359e-04,\n",
       "         -1.0080e-01, -2.1908e-01, -2.5865e-01,  9.6221e-02, -1.9816e-02,\n",
       "         -1.0854e-01, -5.6943e-02, -4.8336e-01, -8.5185e-02, -1.2865e-01,\n",
       "         -2.8408e-01, -2.2925e-01, -4.2622e-01, -1.5021e-01, -1.2309e-02,\n",
       "         -1.0692e-01, -1.8865e-01, -5.5859e-01, -9.7695e-02,  1.5617e-03,\n",
       "         -1.1142e-01,  4.8125e-02, -6.8799e-02, -2.5132e-01, -1.7318e-01,\n",
       "          3.9424e-04,  1.5814e-01,  1.3679e-01, -1.2347e-01,  1.7063e-02,\n",
       "          2.8977e-02, -1.0783e-01, -1.3915e-01, -5.4187e-02,  8.5424e-02,\n",
       "         -2.1072e-01, -1.2505e-01,  2.4743e-01, -6.1732e-02, -6.8796e-02,\n",
       "         -2.8814e-01, -2.9658e-01, -9.9604e-02, -1.3712e-01, -1.6031e-01,\n",
       "         -1.5342e-01, -9.4470e-02, -6.6474e-02,  5.1348e-02,  1.4652e-01,\n",
       "          5.5345e-02, -1.7211e-01, -2.6797e-01,  2.9862e-02, -1.7887e-01,\n",
       "         -2.4101e-01, -2.8566e-01, -7.5892e-02,  1.3168e-01, -2.2028e-02,\n",
       "         -2.6019e-01, -2.3494e-02, -6.3690e-01, -1.3549e-01,  8.7415e-02,\n",
       "          5.1256e-02, -2.1301e-01, -3.0907e-01, -4.6756e-02,  4.3541e-02,\n",
       "         -3.9717e-01,  9.6593e-02,  3.4745e-03, -3.7448e-01, -8.4324e-02,\n",
       "          9.2171e-02,  1.7082e-01,  5.4561e-02, -7.0059e-02, -3.6896e-01,\n",
       "         -2.6341e-02, -9.4029e-02,  4.2165e-02, -7.9589e-02,  1.3030e-01,\n",
       "          2.6414e-02,  1.8142e-01,  1.7941e-01,  1.5010e-02,  3.4246e-02,\n",
       "          5.2985e-02,  2.7675e-02, -6.5882e-02,  1.7816e-02, -1.4422e-01,\n",
       "          1.0499e-01,  7.3065e-02, -2.2012e-01, -4.7313e-02,  1.7237e-02,\n",
       "          2.0066e-01, -1.1850e-01, -1.2509e-01, -2.1157e-01, -6.2624e-02,\n",
       "         -9.5288e-02,  3.3056e-02, -1.8138e-01,  3.0769e-01, -9.7118e-02,\n",
       "         -4.1287e-02,  1.1838e-02,  4.4315e-02, -1.3197e-01,  5.0460e-02,\n",
       "          1.5819e-01, -6.6634e-02, -2.9752e-02,  2.1980e-01, -1.1540e-01,\n",
       "          4.6350e-03,  1.4807e-01, -1.5178e-02,  1.8140e-01,  1.1421e-01,\n",
       "          2.7735e-02,  5.4763e-02,  5.6906e-02, -1.4477e-01,  6.5766e-02,\n",
       "         -2.2283e-01,  9.1555e-02,  2.9087e-01, -4.9499e-01,  6.2133e-02,\n",
       "         -3.5615e-01,  2.1933e-01, -1.6564e-02, -6.4312e-02,  2.2918e-04,\n",
       "         -1.9134e-01, -1.5904e-01, -4.3756e-02,  5.9866e-02,  8.3061e-02,\n",
       "          4.6249e-02, -1.2120e-01, -7.4589e-02,  6.4571e-02, -3.5331e-01,\n",
       "         -4.0829e-02, -1.7881e-01, -7.9994e-02, -3.1969e-01, -2.5010e-01,\n",
       "         -4.8692e-02, -1.7612e-01, -3.0141e-01,  8.7467e-02, -2.9938e-01,\n",
       "         -2.6436e-01, -8.3629e-02, -3.4458e-01, -2.4050e-01, -4.4395e-02,\n",
       "         -1.7919e-01, -4.2666e-01, -4.7522e-01,  8.7268e-02, -1.2663e-01,\n",
       "          1.0038e-01, -1.2335e-01,  1.9722e-02, -4.4847e-01, -1.7281e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.feed_forward.encoder_0.bias_hh_l0': tensor([ 1.6118e-01,  8.8471e-02,  1.6366e-01, -3.4978e-01,  1.2120e-01,\n",
       "         -8.3738e-02, -1.9564e-01,  1.0466e-01, -3.1808e-01,  6.4761e-02,\n",
       "         -2.4152e-01,  6.0075e-02,  6.2493e-02, -6.5328e-02,  8.9240e-02,\n",
       "          8.4863e-02, -3.7018e-02, -1.2221e-01, -1.7551e-02,  2.1530e-01,\n",
       "         -1.1373e-01, -1.1692e-01, -1.5615e-01, -1.5786e-01, -1.0466e-01,\n",
       "         -1.8785e-01,  1.1294e-02, -2.2566e-01, -1.2005e-01,  5.6600e-02,\n",
       "         -1.2806e-01, -8.4513e-02, -3.5816e-01,  5.9043e-02, -3.1944e-03,\n",
       "         -9.6523e-02, -1.9960e-01, -4.9682e-01, -3.1495e-01, -9.7603e-02,\n",
       "         -1.6512e-01, -3.4636e-01, -5.9913e-01, -2.0257e-02,  1.3027e-01,\n",
       "         -1.9705e-02,  1.5238e-01,  1.4692e-01, -3.4616e-01, -1.2391e-01,\n",
       "         -1.2421e-01,  2.0660e-01,  1.5779e-01, -2.8810e-01,  9.6356e-02,\n",
       "          1.7073e-01, -1.6130e-01,  4.9643e-02, -2.0396e-01,  1.4702e-01,\n",
       "         -1.6755e-01,  3.9569e-02,  2.0958e-01, -1.2441e-01, -1.4530e-01,\n",
       "         -4.2410e-01, -4.0085e-01, -9.5365e-02, -1.3717e-01, -4.6247e-02,\n",
       "         -6.0010e-02, -1.9993e-01, -2.4606e-01, -1.6405e-01,  1.0091e-01,\n",
       "         -9.9406e-02, -3.3013e-01, -7.1707e-02, -1.3555e-01, -2.1088e-01,\n",
       "         -1.5789e-01, -9.8753e-02, -3.3266e-01, -2.5466e-02, -1.8113e-01,\n",
       "         -3.3251e-01, -2.3157e-01, -5.1614e-01, -2.9271e-01, -1.0343e-02,\n",
       "          5.9712e-02, -1.8031e-01, -3.4774e-01,  1.0802e-01,  1.0124e-01,\n",
       "         -1.9460e-01,  8.9038e-02, -4.5688e-02, -4.7858e-01, -1.5598e-01,\n",
       "         -1.7071e-01,  2.1870e-01, -6.6914e-02, -9.9081e-02, -4.2981e-01,\n",
       "          1.5210e-03, -3.2656e-02,  6.8603e-02, -2.6162e-01, -5.3158e-03,\n",
       "          1.4744e-02,  2.1961e-01,  1.9938e-01,  1.8246e-01,  2.6289e-02,\n",
       "         -1.0711e-01,  1.2662e-01, -1.1406e-02,  2.8472e-01, -1.2884e-01,\n",
       "         -9.8664e-02,  8.0965e-02, -9.9006e-02,  6.9669e-02, -1.6859e-01,\n",
       "          4.2703e-02, -2.3733e-03, -1.4468e-01, -2.3259e-01,  1.3429e-01,\n",
       "         -5.6735e-02, -5.9158e-02, -9.3744e-02,  4.0538e-02, -9.7466e-02,\n",
       "          4.3355e-02,  2.8522e-03,  4.0841e-02, -1.3022e-01, -5.9497e-03,\n",
       "          1.8592e-01,  6.2332e-02, -8.3618e-02,  1.3038e-01, -6.6510e-02,\n",
       "          1.0182e-01, -1.1056e-01, -1.4876e-01,  5.9097e-02,  1.3282e-01,\n",
       "          3.9630e-02, -5.9155e-02,  1.2740e-01, -6.0175e-02, -3.8099e-02,\n",
       "         -3.7603e-01,  8.2362e-02,  1.6274e-01, -3.1284e-01,  2.2025e-01,\n",
       "         -3.0440e-01,  2.9370e-02, -1.2017e-01, -1.4329e-01,  9.3040e-02,\n",
       "         -2.7900e-01, -1.8871e-01, -1.3520e-01, -1.4951e-01, -4.3450e-02,\n",
       "         -7.8250e-02, -1.0917e-01, -2.6431e-01, -1.3154e-01, -4.3343e-01,\n",
       "         -1.2016e-01, -1.3400e-01, -2.4540e-01, -2.6111e-01, -2.4049e-04,\n",
       "         -1.0098e-01, -1.8003e-01, -3.3362e-01, -1.2277e-01, -2.9007e-01,\n",
       "         -1.0649e-01, -6.9890e-03, -3.6791e-01, -2.9402e-01,  1.5720e-01,\n",
       "         -5.5952e-02, -5.2484e-01, -5.4662e-01, -7.1214e-02, -1.0139e-01,\n",
       "         -1.7995e-02, -9.9355e-03, -1.4584e-02, -3.1598e-01, -1.6439e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.feed_forward.encoder_1.weight_ih_l0': tensor([[-0.0808, -0.1828, -0.2218,  ..., -0.3347,  0.0939,  0.0210],\n",
       "         [-0.0499, -0.1096,  0.0270,  ..., -0.3378, -0.0868,  0.1114],\n",
       "         [ 0.3567, -0.1049,  0.0690,  ...,  0.1057, -0.1407, -0.0948],\n",
       "         ...,\n",
       "         [-0.0474,  0.4505,  0.0419,  ...,  0.0333, -0.2093, -0.1205],\n",
       "         [ 0.1818, -0.3979,  0.0937,  ..., -0.1138,  0.4173, -0.1170],\n",
       "         [-0.2984,  0.1151, -0.3834,  ..., -0.0914, -0.0219, -0.0016]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.feed_forward.encoder_1.weight_hh_l0': tensor([[-0.0037, -0.0564, -0.1978,  ..., -0.3323, -0.0792, -0.0869],\n",
       "         [-0.0272, -0.0903, -0.1634,  ..., -0.1989, -0.1431, -0.0153],\n",
       "         [ 0.0249, -0.1038, -0.1981,  ..., -0.0760,  0.1211, -0.2553],\n",
       "         ...,\n",
       "         [ 0.0123,  0.0084, -0.2567,  ..., -0.2055, -0.0615, -0.1080],\n",
       "         [ 0.0423,  0.2094,  0.2793,  ...,  0.1588,  0.2205, -0.1059],\n",
       "         [-0.5770,  0.0027, -0.2623,  ..., -0.3055, -0.3538,  0.0028]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.feed_forward.encoder_1.bias_ih_l0': tensor([ 0.1386, -0.0386, -0.0843,  0.1753,  0.1543,  0.0408,  0.0390, -0.0375,\n",
       "         -0.1469, -0.0256,  0.0137, -0.1087,  0.0057, -0.3587, -0.0760, -0.2225,\n",
       "         -0.2195,  0.0323,  0.0315, -0.1442, -0.0519, -0.2664,  0.0736, -0.0290,\n",
       "          0.0134, -0.4124,  0.1032, -0.0338, -0.2313, -0.0463,  0.1183, -0.0280,\n",
       "          0.0092, -0.2901,  0.1508, -0.1032, -0.0272, -0.1411, -0.0618, -0.1492,\n",
       "          0.1455, -0.0280, -0.1752,  0.3172,  0.0244, -0.0152, -0.2160, -0.3423,\n",
       "          0.2574, -0.2978,  0.0561, -0.4384, -0.2269,  0.1835, -0.1571,  0.2737,\n",
       "          0.0808, -0.0218,  0.0653,  0.0461, -0.2964, -0.0640,  0.0590, -0.3367,\n",
       "          0.1008,  0.0788, -0.0743,  0.0434, -0.0567, -0.1149,  0.0271, -0.1281,\n",
       "         -0.0438, -0.1244,  0.0525, -0.2671,  0.0818, -0.0567, -0.3044, -0.1845,\n",
       "          0.1005,  0.0243, -0.1113, -0.2903,  0.2112, -0.2123,  0.1131, -0.1492,\n",
       "          0.0779, -0.2474,  0.1231, -0.1424, -0.1040, -0.0916,  0.1126, -0.1132,\n",
       "         -0.0574,  0.1203, -0.1235, -0.2841, -0.1571, -0.1594,  0.1334,  0.0009,\n",
       "          0.1515, -0.0072,  0.0156,  0.1278,  0.1039,  0.1303, -0.1693,  0.0880,\n",
       "          0.0605,  0.0014,  0.1865,  0.0791, -0.1932,  0.1133,  0.0988, -0.0814,\n",
       "         -0.1351,  0.0256, -0.0228,  0.0552,  0.2045, -0.0624,  0.1475, -0.1523,\n",
       "         -0.2794, -0.0507, -0.0018,  0.1343, -0.1732,  0.0014,  0.0204,  0.2292,\n",
       "         -0.2170, -0.0681,  0.1371,  0.0224,  0.0664, -0.1262, -0.2662,  0.0372,\n",
       "          0.1083, -0.0070, -0.0235,  0.1115,  0.0909, -0.3000, -0.1225, -0.0382,\n",
       "         -0.1423,  0.0347,  0.0437,  0.0083, -0.0418, -0.0706, -0.0175,  0.0048,\n",
       "          0.0937,  0.1375,  0.0074, -0.1612, -0.0226, -0.1798, -0.1492,  0.2027,\n",
       "         -0.0780,  0.0520, -0.0994, -0.3267,  0.0470, -0.0902, -0.1677, -0.2453,\n",
       "         -0.0548, -0.2062, -0.1177,  0.0616, -0.0473, -0.0114, -0.0846, -0.1040,\n",
       "         -0.2121, -0.2220,  0.1339, -0.3719, -0.1781, -0.0254,  0.3861, -0.0560,\n",
       "         -0.0104,  0.0541, -0.1957, -0.1187, -0.3489, -0.1265,  0.0463, -0.2563],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.feed_forward.encoder_1.bias_hh_l0': tensor([-0.0958, -0.2244, -0.1873,  0.0041,  0.2082,  0.0582,  0.0677, -0.1154,\n",
       "         -0.0341,  0.0885, -0.2077, -0.1720,  0.0200, -0.2914,  0.0177, -0.1956,\n",
       "         -0.2664, -0.1846,  0.1081, -0.0752, -0.2288, -0.4019,  0.0744, -0.0163,\n",
       "         -0.0759, -0.2987, -0.0193,  0.0299, -0.0730,  0.0208,  0.1824, -0.2348,\n",
       "         -0.1057, -0.0933,  0.1329, -0.1414,  0.0217, -0.2298,  0.0748, -0.2103,\n",
       "         -0.0181, -0.0501,  0.0430,  0.1908,  0.1280,  0.0762, -0.1417, -0.3564,\n",
       "          0.0954, -0.2674,  0.0840, -0.3262, -0.2452,  0.0127, -0.1356,  0.3277,\n",
       "          0.0550,  0.1000, -0.0946, -0.1571, -0.3120,  0.0188,  0.1499, -0.3961,\n",
       "          0.1548,  0.1243, -0.1756,  0.1083, -0.1308,  0.0111, -0.1095, -0.0288,\n",
       "         -0.1578, -0.1850, -0.0283, -0.1810, -0.0699, -0.0430, -0.2977, -0.0834,\n",
       "         -0.0151, -0.1393,  0.0429, -0.4364,  0.2862, -0.2802,  0.0405, -0.2094,\n",
       "         -0.0336, -0.2324,  0.0596, -0.1324, -0.1622,  0.0572,  0.0135, -0.0185,\n",
       "         -0.0525,  0.0141, -0.0729, -0.1733,  0.0803, -0.0463,  0.2986, -0.0665,\n",
       "          0.1533,  0.1248,  0.1937, -0.0094,  0.0464,  0.1492, -0.0867,  0.1366,\n",
       "          0.0394,  0.1282,  0.1801, -0.0076, -0.1832,  0.1553,  0.1501,  0.1100,\n",
       "         -0.0885, -0.1450,  0.1222,  0.1076,  0.1227,  0.0168,  0.1702, -0.1881,\n",
       "         -0.3502, -0.1083, -0.0662,  0.0909,  0.0148, -0.0201,  0.0806,  0.2053,\n",
       "         -0.0742,  0.1043,  0.0437, -0.0532,  0.0126, -0.1517, -0.0841,  0.0664,\n",
       "         -0.0306, -0.0386,  0.0622,  0.1445,  0.0726, -0.1376,  0.0111, -0.1338,\n",
       "         -0.0678,  0.2003, -0.1706,  0.1027, -0.1091,  0.0041, -0.0975, -0.0665,\n",
       "         -0.0905,  0.1511,  0.0646, -0.1163, -0.0941, -0.1135, -0.0928, -0.0345,\n",
       "         -0.1533,  0.0604, -0.0688, -0.3770,  0.2325, -0.2405, -0.0967, -0.2567,\n",
       "         -0.1083, -0.0253, -0.1374, -0.1261,  0.0607, -0.0142, -0.1958, -0.1602,\n",
       "         -0.1939, -0.2304,  0.0042, -0.3942, -0.0196,  0.0285,  0.3592,  0.0622,\n",
       "          0.0071, -0.0512,  0.0254, -0.2236, -0.4261, -0.1177,  0.2067, -0.1273],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.feed_forward.encoder_2.weight_ih_l0': tensor([[-0.0792, -0.0004, -0.2092,  ..., -0.0610, -0.0183, -0.1056],\n",
       "         [-0.1798,  0.3563, -0.1173,  ...,  0.3357,  0.1068, -0.2043],\n",
       "         [-0.2962,  0.0901, -0.3428,  ..., -0.0226, -0.1083,  0.3049],\n",
       "         ...,\n",
       "         [ 0.1916,  0.0191,  0.0951,  ...,  0.1943, -0.0636, -0.1436],\n",
       "         [-0.2026, -0.2551,  0.0283,  ...,  0.1292,  0.0847, -0.1072],\n",
       "         [ 0.2142,  0.0487,  0.1377,  ...,  0.0328,  0.1625, -0.0809]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.feed_forward.encoder_2.weight_hh_l0': tensor([[ 0.0320, -0.2583,  0.0136,  ..., -0.1751, -0.0764, -0.1019],\n",
       "         [-0.0475,  0.0563, -0.0273,  ...,  0.0068, -0.0771,  0.0266],\n",
       "         [-0.1755, -0.1090, -0.2769,  ..., -0.0996,  0.1618,  0.0153],\n",
       "         ...,\n",
       "         [-0.0466, -0.0532,  0.0534,  ...,  0.4044,  0.1257,  0.0045],\n",
       "         [ 0.0322, -0.3742,  0.1317,  ..., -0.0869, -0.1283,  0.1221],\n",
       "         [ 0.2960,  0.4448,  0.1189,  ...,  0.1323, -0.0061,  0.1335]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.feed_forward.encoder_2.bias_ih_l0': tensor([ 0.0695, -0.2293, -0.1464, -0.1813,  0.1081, -0.2959, -0.1203, -0.0011,\n",
       "         -0.1492,  0.2466, -0.1103, -0.1027, -0.2036,  0.0082, -0.2277, -0.0502,\n",
       "         -0.0663, -0.2216,  0.0089, -0.1431, -0.0573, -0.0743,  0.0397,  0.1947,\n",
       "         -0.3093,  0.1425,  0.1554,  0.2363, -0.2885, -0.2929,  0.0138, -0.0883,\n",
       "         -0.0080,  0.0433, -0.1178, -0.2909, -0.3570, -0.4394, -0.2224,  0.1540,\n",
       "         -0.1288, -0.2303, -0.1889, -0.1039,  0.1399,  0.1387, -0.0464,  0.3125,\n",
       "         -0.1773, -0.0097,  0.1932,  0.1473, -0.1039, -0.3664, -0.0551, -0.0615,\n",
       "         -0.0332, -0.0858, -0.0361,  0.0632, -0.5419,  0.1125, -0.3202,  0.1027,\n",
       "         -0.3129, -0.1009,  0.1354, -0.1345, -0.1359, -0.1841, -0.1490,  0.0555,\n",
       "          0.0405, -0.0587, -0.1633, -0.0231, -0.1080,  0.2801, -0.1499, -0.3299,\n",
       "          0.0032,  0.1225, -0.1138, -0.1944, -0.0160, -0.1869, -0.2291, -0.2154,\n",
       "          0.1336,  0.0019,  0.0007,  0.0741, -0.2290, -0.0043,  0.0719, -0.0978,\n",
       "         -0.0703,  0.0915, -0.1058,  0.1060,  0.1143, -0.1978,  0.0233,  0.1502,\n",
       "          0.1334,  0.1032, -0.2033, -0.0441,  0.0155, -0.2083, -0.0969,  0.0321,\n",
       "         -0.0263,  0.0022, -0.0861, -0.0751, -0.1051, -0.0422, -0.0337, -0.0366,\n",
       "         -0.0494, -0.1430,  0.1232, -0.1279, -0.0464,  0.1365, -0.0696,  0.1645,\n",
       "         -0.0109, -0.0184,  0.0769,  0.0110, -0.0631,  0.0577,  0.0398, -0.2211,\n",
       "         -0.1126, -0.1426,  0.1158, -0.0050, -0.0943, -0.0585,  0.0701,  0.0843,\n",
       "          0.1038, -0.0540, -0.1498, -0.2015,  0.1882, -0.0636, -0.0482, -0.0493,\n",
       "          0.0458, -0.4260,  0.0063, -0.1310, -0.0616, -0.4175, -0.0314, -0.0654,\n",
       "         -0.0583, -0.1695,  0.0517,  0.2642, -0.1708, -0.0535,  0.0104, -0.2556,\n",
       "          0.3375, -0.2019, -0.0533, -0.1702,  0.0596, -0.0266, -0.2311, -0.0785,\n",
       "          0.0590,  0.2669, -0.3782, -0.2094, -0.1094, -0.3064, -0.3266, -0.2871,\n",
       "         -0.2787, -0.0279,  0.0176, -0.3122,  0.0122, -0.1333, -0.2563, -0.0907,\n",
       "         -0.1482, -0.2553, -0.1849, -0.0032, -0.0313, -0.0015, -0.0853,  0.0013],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.feed_forward.encoder_2.bias_hh_l0': tensor([-4.4473e-02,  6.2161e-03, -1.6431e-01, -1.5698e-01,  1.4387e-01,\n",
       "         -3.2065e-01, -1.6811e-02, -1.9657e-01, -1.1828e-01,  5.6055e-02,\n",
       "         -1.8758e-01, -2.2297e-01, -1.8366e-01,  5.1335e-02, -2.8900e-01,\n",
       "          3.4065e-02, -8.2078e-02, -2.8754e-01, -1.4549e-01, -8.4398e-02,\n",
       "         -5.2774e-02, -1.1011e-01, -7.6226e-02,  1.3373e-01, -1.9977e-01,\n",
       "          5.3627e-02,  2.1894e-01,  1.5281e-01, -2.1539e-01, -9.7828e-02,\n",
       "         -5.0792e-02, -1.9761e-01, -4.8983e-04, -2.1599e-01, -1.6854e-01,\n",
       "         -2.7304e-01, -3.8726e-01, -6.2431e-01, -2.2496e-01,  2.1082e-01,\n",
       "         -1.5781e-02, -2.5423e-01, -2.4872e-01,  8.2956e-02, -8.3323e-02,\n",
       "          1.2783e-01,  1.1615e-01,  2.7416e-01, -2.6499e-01, -1.5059e-01,\n",
       "         -2.6410e-02, -7.8008e-02, -3.1645e-01, -2.2721e-01, -1.2259e-01,\n",
       "         -1.4607e-01, -5.8704e-02, -7.8558e-02, -4.1874e-02,  2.8653e-02,\n",
       "         -5.3847e-01,  1.3432e-01, -2.8150e-01, -1.1113e-01, -1.0179e-01,\n",
       "         -2.0626e-01,  1.2585e-01, -5.3161e-02, -1.4436e-02, -1.8275e-01,\n",
       "         -2.1190e-01, -1.6604e-01,  9.8752e-02, -1.9534e-01, -1.5114e-01,\n",
       "         -1.2844e-01, -2.0146e-01,  1.0492e-01,  2.9758e-02, -1.9287e-01,\n",
       "          8.0521e-02, -4.1620e-02, -1.7834e-02, -1.8432e-01,  1.1381e-01,\n",
       "         -2.9673e-01, -5.4767e-02, -2.8823e-01,  2.1959e-01, -1.7459e-01,\n",
       "         -1.5342e-01, -1.5076e-02, -5.6556e-02, -6.9485e-02, -7.5847e-02,\n",
       "         -2.7340e-02, -1.3555e-01,  1.4474e-01, -1.3442e-01,  1.4522e-01,\n",
       "          8.3265e-02, -1.8691e-01, -1.8744e-01,  2.3793e-01, -4.0351e-02,\n",
       "         -1.6361e-01,  4.5989e-03,  1.3659e-01,  1.2110e-01,  5.6290e-02,\n",
       "         -1.1647e-01,  4.9904e-02,  1.3215e-01, -8.1195e-02,  1.2826e-01,\n",
       "         -1.1933e-02,  4.7137e-02,  3.3848e-02, -1.8460e-01,  1.4511e-01,\n",
       "          5.4635e-02, -7.5963e-02,  9.0468e-02,  1.0024e-01, -1.6794e-03,\n",
       "          2.8897e-01, -9.5932e-02,  2.3742e-01, -1.9932e-01, -8.2060e-02,\n",
       "          3.9843e-02, -1.5731e-01,  1.6962e-01,  1.0871e-01, -1.2648e-01,\n",
       "         -1.9891e-02, -5.1979e-02, -7.4964e-02,  1.3354e-01,  7.4977e-02,\n",
       "         -1.0844e-01,  6.6301e-02,  2.3379e-01, -8.1573e-02,  1.0107e-01,\n",
       "         -5.4454e-02, -1.5550e-01, -2.7331e-01,  1.9179e-02, -1.5920e-01,\n",
       "          1.0402e-02, -1.2680e-02,  3.5361e-03, -3.0551e-01, -1.9314e-02,\n",
       "         -7.0824e-03,  7.3675e-02, -2.6840e-01, -1.5766e-01, -2.0513e-02,\n",
       "         -1.4587e-01, -1.2803e-01,  5.2769e-02,  1.8454e-01, -2.0202e-01,\n",
       "          7.7451e-02,  1.7151e-01, -1.2190e-01,  3.3842e-01, -2.0962e-01,\n",
       "         -1.8688e-01, -2.3337e-01,  7.7936e-02,  4.8283e-02, -1.3258e-01,\n",
       "          7.5336e-02,  6.7475e-03,  2.4695e-02, -2.7699e-01, -1.0369e-01,\n",
       "         -2.6245e-01, -3.9183e-01, -2.7770e-01, -2.6705e-01, -4.6219e-01,\n",
       "         -1.6131e-01,  6.2477e-02, -2.0647e-01,  7.1604e-02, -4.4074e-02,\n",
       "         -1.6542e-01, -2.1065e-01, -7.9510e-02, -5.9880e-02, -8.9380e-02,\n",
       "         -7.4382e-02, -2.2920e-01,  2.9319e-02,  1.3674e-01, -2.3479e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.sublayer.0.norm.a_2': tensor([0.3208, 0.5038, 0.3973, 0.4694, 0.3408, 0.8594, 0.5764, 0.3811, 0.5996,\n",
       "         0.2331, 0.6047, 0.6042, 0.5994, 0.2284, 0.4572, 0.7290, 0.5277, 0.3812,\n",
       "         0.1524, 0.3619, 0.2951, 0.1962, 0.5474, 0.5704, 0.2696, 0.4200, 0.4629,\n",
       "         0.5893, 0.5378, 0.3330, 0.2038, 0.6507, 0.4892, 0.1998, 0.4101, 0.5927,\n",
       "         0.2406, 0.3975, 0.5742, 0.1585, 0.7056, 0.3107, 0.2174, 0.4095, 0.3607,\n",
       "         0.3541, 0.4071, 0.5938, 0.3820, 0.3654], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.sublayer.0.norm.b_2': tensor([-0.0066,  0.3339, -0.1097,  0.0758, -0.1902,  0.0251, -0.2686,  0.0682,\n",
       "          0.0743, -0.0899,  0.0333,  0.1800,  0.1008,  0.0734,  0.0147,  0.0720,\n",
       "         -0.0030,  0.0791, -0.0668, -0.1320, -0.1259,  0.1523,  0.1391,  0.0316,\n",
       "         -0.0459, -0.1624, -0.2523,  0.2579,  0.1321, -0.1541, -0.1141,  0.1471,\n",
       "          0.2846,  0.1348, -0.0936, -0.0929, -0.0037,  0.0379,  0.0142, -0.1168,\n",
       "         -0.0008,  0.2450, -0.0646,  0.0043, -0.0959,  0.0927,  0.0544,  0.0841,\n",
       "         -0.2827, -0.1426], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.sublayer.1.norm.a_2': tensor([1.1441, 0.9325, 1.1982, 1.0333, 0.8981, 1.1622, 0.6242, 0.7758, 0.9226,\n",
       "         1.0189, 1.1028, 1.1100, 0.7599, 0.6286, 1.0460, 1.4346, 0.9394, 1.0618,\n",
       "         0.8750, 0.7004, 1.0184, 0.7398, 1.1272, 0.6009, 0.8715, 1.1221, 0.8409,\n",
       "         1.1551, 1.0725, 1.0317, 0.6103, 0.9818, 1.0298, 1.1381, 0.9039, 0.5724,\n",
       "         0.9098, 1.2704, 1.1435, 0.9000, 1.1938, 0.8475, 0.8745, 0.9016, 0.8886,\n",
       "         1.0884, 0.7451, 0.8976, 0.4196, 1.1012], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.5.sublayer.1.norm.b_2': tensor([ 0.0502,  0.0970,  0.0577,  0.1940, -0.0845,  0.0557, -0.1568,  0.0564,\n",
       "          0.0860,  0.0837,  0.0215,  0.2541,  0.0505,  0.2309, -0.0846, -0.1074,\n",
       "          0.1631,  0.1357, -0.0229,  0.0356, -0.0993,  0.0298,  0.0115, -0.0227,\n",
       "          0.1540, -0.0278, -0.0860,  0.0621,  0.0321,  0.0194,  0.1615, -0.1359,\n",
       "          0.2751,  0.0651, -0.1454,  0.0854,  0.1286, -0.2179, -0.1130, -0.3403,\n",
       "          0.2316, -0.0083, -0.0994,  0.1393, -0.0078, -0.0252, -0.1541,  0.0201,\n",
       "         -0.3348,  0.2294], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.self_attn.linears.0.weight': tensor([[-0.2741, -0.1442, -0.0735,  ...,  0.2050, -0.0765, -0.1757],\n",
       "         [ 0.2416,  0.1674,  0.0665,  ..., -0.2008, -0.0683,  0.0433],\n",
       "         [-0.3063,  0.0687, -0.1867,  ...,  0.2618, -0.0110,  0.0230],\n",
       "         ...,\n",
       "         [ 0.0946, -0.2814,  0.0634,  ..., -0.0007,  0.1962, -0.0004],\n",
       "         [-0.1732, -0.0131, -0.2082,  ..., -0.1422,  0.2406,  0.2559],\n",
       "         [-0.0514,  0.0974,  0.0559,  ...,  0.0304, -0.1299, -0.1586]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.self_attn.linears.0.bias': tensor([-0.0887, -0.3870, -0.0513, -0.3574, -0.1526,  0.1714, -0.3964, -0.4895,\n",
       "          0.4176,  0.6601,  0.1889, -0.1406,  0.1766, -0.0174,  0.3467, -0.4125,\n",
       "         -0.0799,  0.0628, -0.5372,  0.3063, -0.0047, -0.4108, -0.0519, -0.4286,\n",
       "         -0.1104,  0.4804,  0.3766, -0.0280, -0.3778,  0.5137, -0.2438,  0.2641,\n",
       "         -0.3303,  0.3875, -0.3995,  0.5717,  0.1554,  0.3732, -0.6780, -0.5377,\n",
       "          0.2450, -0.2311,  0.1163,  0.2108,  0.1677, -0.1226,  0.4319,  0.6862,\n",
       "         -0.2450,  0.1070], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.self_attn.linears.1.weight': tensor([[ 0.1181, -0.1272, -0.0322,  ..., -0.2482, -0.1644,  0.0085],\n",
       "         [ 0.0878,  0.1654,  0.2136,  ...,  0.0204,  0.0060, -0.0799],\n",
       "         [-0.1176, -0.0679, -0.1286,  ..., -0.1507,  0.0627,  0.0949],\n",
       "         ...,\n",
       "         [ 0.0573,  0.2141,  0.0526,  ..., -0.5312,  0.1481,  0.1984],\n",
       "         [ 0.2501,  0.0356, -0.0447,  ...,  0.3186, -0.1395,  0.0570],\n",
       "         [-0.1259,  0.0866,  0.1498,  ..., -0.2726,  0.2246, -0.0757]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.self_attn.linears.1.bias': tensor([-0.0789, -0.1411, -0.0460, -0.0866,  0.0874, -0.0903,  0.0955, -0.1204,\n",
       "         -0.0193, -0.1312,  0.1102, -0.1048,  0.0410, -0.1079,  0.0975, -0.0970,\n",
       "          0.1302,  0.0401, -0.0026,  0.1350,  0.0527, -0.0560,  0.1290, -0.1341,\n",
       "          0.1307,  0.1356,  0.1026, -0.0706, -0.0911,  0.0842,  0.0821,  0.1341,\n",
       "         -0.1218, -0.0806, -0.1367,  0.1334,  0.0300,  0.1203, -0.0412, -0.1075,\n",
       "          0.1184,  0.0117, -0.0881,  0.0003,  0.1279, -0.0429, -0.0396,  0.0975,\n",
       "         -0.0364,  0.0842], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.self_attn.linears.2.weight': tensor([[-0.0386, -0.1135,  0.0685,  ..., -0.0849, -0.1121, -0.0068],\n",
       "         [-0.0212, -0.0097,  0.0557,  ..., -0.0023,  0.1561, -0.0124],\n",
       "         [-0.0144, -0.0407,  0.0400,  ..., -0.0475, -0.0757,  0.0141],\n",
       "         ...,\n",
       "         [ 0.0552,  0.0831, -0.0308,  ..., -0.0021, -0.0188,  0.0909],\n",
       "         [ 0.1203, -0.0828,  0.0771,  ...,  0.0065,  0.0555, -0.0522],\n",
       "         [-0.0646,  0.1159,  0.0082,  ..., -0.0741,  0.0589,  0.0006]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.self_attn.linears.2.bias': tensor([-0.0330, -0.0451, -0.0146, -0.0819,  0.0873, -0.0961,  0.0928, -0.1245,\n",
       "         -0.0107,  0.0155,  0.1098, -0.0945,  0.0320, -0.0697,  0.0041, -0.1548,\n",
       "          0.0772, -0.0160, -0.0599,  0.0693,  0.1072, -0.0123,  0.0724, -0.1241,\n",
       "          0.1120,  0.0394,  0.1640,  0.0020, -0.0129,  0.0292,  0.0840,  0.1428,\n",
       "         -0.0677, -0.0208, -0.0140,  0.0645,  0.0717,  0.0244, -0.0060, -0.1013,\n",
       "         -0.0274,  0.0467, -0.0717,  0.0875,  0.0475, -0.0345, -0.0110,  0.0195,\n",
       "         -0.0205,  0.0065], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.self_attn.linears.3.weight': tensor([[ 0.0242, -0.0999,  0.0727,  ..., -0.0845, -0.0855,  0.0140],\n",
       "         [ 0.0925,  0.0227,  0.1711,  ..., -0.0128,  0.1047, -0.0344],\n",
       "         [-0.0434, -0.0230, -0.0370,  ...,  0.0820, -0.0653,  0.0204],\n",
       "         ...,\n",
       "         [ 0.0089,  0.0868,  0.0698,  ...,  0.0561, -0.0395,  0.1317],\n",
       "         [ 0.0846, -0.1224,  0.1402,  ..., -0.1211,  0.1609, -0.0112],\n",
       "         [-0.1280,  0.0393, -0.0648,  ..., -0.0912, -0.0230,  0.0827]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.self_attn.linears.3.bias': tensor([-1.9020e-01, -2.0035e-01, -7.7341e-02,  2.6774e-02,  2.3227e-01,\n",
       "         -2.6383e-01,  5.1389e-01, -1.9810e-01, -4.7058e-02,  1.6968e-02,\n",
       "         -6.6101e-02,  2.6229e-02, -3.3605e-02, -2.0076e-01,  1.7356e-01,\n",
       "         -1.1563e-02,  4.9824e-04, -3.0305e-02,  1.4126e-01,  1.2587e-01,\n",
       "          2.5090e-01, -2.2263e-01,  2.2871e-02, -8.8961e-02,  1.3791e-01,\n",
       "          1.0303e-01,  3.5328e-01, -2.9109e-01, -1.8053e-01,  1.6701e-01,\n",
       "          1.7090e-01, -2.5100e-01, -8.1589e-01,  1.2552e-01, -1.6171e-01,\n",
       "          1.8053e-01,  1.2383e-01, -6.3161e-02, -7.8696e-02,  5.7809e-02,\n",
       "          3.2799e-02, -1.1466e-01, -4.8235e-02, -1.2838e-01,  2.3896e-01,\n",
       "         -1.9118e-02, -7.2710e-02, -5.8297e-02,  5.7154e-01,  1.8704e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.feed_forward.bn.weight': tensor([0.8657, 0.8776, 1.0530, 1.1966, 1.0777, 1.0194, 1.0742, 0.6445, 0.8210,\n",
       "         0.8589, 0.9916, 1.0554, 0.9235, 0.6881, 1.0607, 1.0559, 0.6707, 1.0682,\n",
       "         0.7592, 1.0922, 0.8972, 0.8081, 0.8271, 0.8894, 1.0465, 1.0338, 1.0961,\n",
       "         0.8485, 1.2444, 0.8569, 0.9680, 0.6841, 0.6690, 1.1263, 0.6733, 0.8801,\n",
       "         0.7504, 0.9366, 1.0762, 1.0374, 0.7430, 1.0319, 1.0716, 0.7796, 1.0463,\n",
       "         1.2985, 0.8765, 0.9139, 1.5775, 0.9085], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.feed_forward.bn.bias': tensor([-0.2187, -0.1527, -0.1247,  0.1287, -0.0923, -0.0497,  0.0926, -0.3392,\n",
       "         -0.2854, -0.1696, -0.1466, -0.0884, -0.1297, -0.3559, -0.0924, -0.1974,\n",
       "         -0.3848, -0.0448, -0.2739, -0.0587, -0.1550, -0.0941, -0.1862, -0.1230,\n",
       "         -0.0521, -0.1477, -0.0326, -0.2657, -0.2139, -0.1187,  0.0447, -0.3864,\n",
       "         -0.5388,  0.0988, -0.1397, -0.1051, -0.1488, -0.1457,  0.0312, -0.0968,\n",
       "         -0.3005, -0.0745, -0.2310, -0.1590, -0.0647,  0.0407, -0.1585, -0.0410,\n",
       "          0.5897, -0.2909], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.feed_forward.bn.running_mean': tensor([ 0.1026,  0.1920,  0.1298, -0.1579,  0.0944, -0.1659,  0.2608, -0.1022,\n",
       "          0.0305, -0.0586,  0.0361,  0.0443,  0.2697,  0.0383,  0.0536, -0.0767,\n",
       "          0.1268, -0.0111,  0.0769,  0.1103,  0.1916,  0.0316, -0.0367,  0.2521,\n",
       "          0.0978, -0.0207,  0.1350,  0.0730, -0.0051,  0.1884,  0.0527, -0.0338,\n",
       "         -0.0209,  0.2537,  0.1243,  0.1531, -0.0429,  0.0361, -0.0133, -0.0062,\n",
       "          0.1221, -0.1719, -0.0210,  0.1692,  0.2596, -0.0721, -0.0945, -0.0009,\n",
       "          0.1436,  0.0637], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.feed_forward.bn.running_var': tensor([0.1927, 0.2186, 0.0667, 0.1175, 0.0753, 0.1716, 0.2167, 0.1589, 0.1104,\n",
       "         0.1654, 0.0310, 0.0344, 0.1199, 0.2143, 0.0292, 0.0567, 0.0836, 0.1343,\n",
       "         0.0652, 0.1286, 0.1084, 0.0283, 0.1805, 0.1321, 0.0874, 0.0400, 0.0684,\n",
       "         0.0615, 0.0248, 0.1062, 0.1728, 0.1190, 0.0234, 0.1274, 0.0963, 0.1106,\n",
       "         0.0635, 0.0353, 0.0884, 0.0787, 0.1875, 0.1521, 0.0211, 0.0883, 0.1795,\n",
       "         0.1292, 0.1469, 0.1238, 0.1101, 0.1525], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.feed_forward.bn.num_batches_tracked': tensor(213030),\n",
       " 'transformer_pre.model.layers.6.feed_forward.encoder_0.weight_ih_l0': tensor([[-0.0913, -0.0210,  0.0112,  ...,  0.1397, -0.1095,  0.2302],\n",
       "         [-0.1511, -0.2229, -0.0148,  ..., -0.0901, -0.0319,  0.2898],\n",
       "         [ 0.1569,  0.0780, -0.1045,  ...,  0.1858,  0.0775, -0.2376],\n",
       "         ...,\n",
       "         [ 0.0614,  0.2013,  0.1823,  ...,  0.1130, -0.1153, -0.3300],\n",
       "         [-0.1940, -0.0990, -0.0824,  ...,  0.2901,  0.0614, -0.3887],\n",
       "         [ 0.0377,  0.2001,  0.1686,  ..., -0.0815, -0.0378, -0.1537]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.feed_forward.encoder_0.weight_hh_l0': tensor([[-0.2950, -0.0239, -0.0305,  ..., -0.0353, -0.0064, -0.1665],\n",
       "         [-0.0550,  0.1457,  0.0988,  ...,  0.0074, -0.0937,  0.1017],\n",
       "         [-0.0902, -0.0861, -0.0064,  ..., -0.0309,  0.2076,  0.0320],\n",
       "         ...,\n",
       "         [-0.0570,  0.1119, -0.2046,  ..., -0.1271,  0.1968, -0.1940],\n",
       "         [-0.0452,  0.0023, -0.1577,  ...,  0.1373, -0.0427, -0.1232],\n",
       "         [ 0.1607,  0.0109, -0.1279,  ...,  0.2218, -0.1628, -0.2673]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.feed_forward.encoder_0.bias_ih_l0': tensor([-3.0659e-02,  1.3408e-01,  1.1601e-02, -9.3599e-02,  3.9149e-02,\n",
       "         -2.5583e-01, -5.8496e-02, -7.7084e-02,  1.1126e-01, -1.1007e-01,\n",
       "         -1.9194e-02, -6.9829e-02,  2.9162e-02,  2.8384e-01,  3.9711e-03,\n",
       "         -2.6099e-01,  8.6221e-02, -2.1508e-01,  1.3221e-01, -1.7762e-01,\n",
       "          5.9598e-02, -1.5359e-01, -1.4478e-01, -1.0164e-01, -2.5299e-01,\n",
       "         -1.8868e-01, -7.9893e-02, -8.5607e-02,  6.0588e-02,  1.0724e-01,\n",
       "         -9.9923e-02,  4.4673e-02, -1.3449e-01,  3.4136e-02, -1.6795e-01,\n",
       "         -1.8419e-01, -7.4755e-02, -5.9704e-03, -1.7386e-01,  1.3716e-01,\n",
       "          8.3127e-02,  1.7087e-02, -5.8583e-01,  6.2136e-02, -4.1768e-02,\n",
       "          4.1735e-02, -3.7280e-02, -2.1541e-01, -3.5438e-03, -2.0151e-01,\n",
       "         -8.8442e-02,  5.5822e-02, -3.3859e-02,  6.8596e-02, -2.8207e-01,\n",
       "          5.4211e-03,  1.2113e-02, -2.0807e-01,  1.8718e-01,  1.1578e-01,\n",
       "         -4.6316e-02, -3.2420e-01,  1.2621e-01,  1.3387e-02, -3.3868e-01,\n",
       "         -1.0007e-01, -1.6829e-01, -9.1587e-02,  3.3185e-02, -2.2847e-01,\n",
       "         -4.6319e-01, -7.6060e-02,  1.3969e-01,  1.4115e-01, -1.7233e-01,\n",
       "         -7.1267e-02,  7.8828e-02, -4.7067e-02, -2.8255e-02, -1.3032e-01,\n",
       "         -2.4181e-01, -2.8325e-01, -5.2774e-02,  1.7151e-01,  8.2494e-02,\n",
       "          2.6955e-02,  7.0677e-03,  4.3315e-02,  6.5039e-02, -6.0746e-02,\n",
       "          2.2379e-02,  3.5417e-02, -3.9962e-01,  5.8242e-02,  1.7254e-01,\n",
       "          6.4450e-02,  1.6495e-01, -2.3596e-01, -1.4672e-01, -2.0712e-01,\n",
       "          1.4702e-01,  8.7685e-02,  1.7601e-01, -8.5570e-02,  8.5886e-03,\n",
       "         -3.8403e-01,  4.5066e-02, -1.0692e-02,  4.0031e-02,  1.2981e-02,\n",
       "          1.6761e-01,  1.4512e-01,  6.2190e-02, -1.5651e-02,  1.1956e-01,\n",
       "          9.2174e-02,  1.7712e-03,  1.6877e-02, -1.1916e-01,  7.1572e-02,\n",
       "          5.9979e-02,  1.4413e-01, -1.0168e-01,  6.5591e-02, -2.0498e-01,\n",
       "          1.5019e-01, -2.1064e-01,  1.1829e-01, -1.0775e-01,  1.1322e-01,\n",
       "         -1.0739e-01,  2.7406e-02, -1.2366e-01,  1.6972e-01,  9.3357e-02,\n",
       "         -1.4029e-01,  2.3443e-02,  3.3491e-04, -4.7658e-02,  4.5341e-03,\n",
       "          1.3690e-01, -3.1148e-01, -1.0549e-03,  2.7786e-01,  6.5849e-02,\n",
       "         -2.6748e-02, -2.7233e-02,  9.4051e-02,  2.3520e-01,  8.5293e-04,\n",
       "         -5.0390e-02,  1.8084e-01, -3.5304e-04, -1.4205e-01, -1.0651e-01,\n",
       "         -1.5606e-01,  7.0202e-02,  7.2562e-02, -2.0187e-01, -3.4306e-02,\n",
       "         -2.9817e-01, -5.1412e-02,  8.7473e-02, -3.9503e-02, -1.2406e-01,\n",
       "         -1.2121e-01,  8.6981e-02, -1.6892e-01,  1.8773e-02, -2.4461e-01,\n",
       "          4.5802e-02, -1.2801e-01,  1.1093e-01,  2.3847e-02, -4.4929e-01,\n",
       "         -8.5294e-02, -9.7878e-03, -6.9172e-02,  9.3276e-02, -1.7436e-01,\n",
       "         -7.1098e-02, -8.7949e-02, -2.3936e-01,  1.2844e-01, -5.2491e-02,\n",
       "         -1.5518e-01,  8.3860e-04, -5.4761e-02, -1.1997e-02,  1.2635e-01,\n",
       "         -1.0953e-01,  9.0828e-02, -4.0779e-01,  2.9856e-01, -7.0668e-02,\n",
       "          5.6396e-02, -4.4298e-02, -4.9751e-02, -2.9166e-01, -3.0378e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.feed_forward.encoder_0.bias_hh_l0': tensor([ 1.2486e-01,  1.4725e-01,  1.3616e-01, -1.9808e-01, -1.0522e-01,\n",
       "         -1.3284e-01, -6.1958e-02, -1.9769e-01,  1.5476e-01, -1.8780e-01,\n",
       "         -1.3105e-01, -1.4966e-01,  9.5922e-02,  1.0502e-01,  1.8900e-02,\n",
       "         -4.5257e-02,  7.5303e-02, -1.7097e-01,  8.5429e-02, -5.3145e-02,\n",
       "          7.4178e-02, -1.7226e-01,  1.2280e-02, -1.3883e-01, -3.5726e-01,\n",
       "         -2.7573e-01,  1.5048e-01, -5.2616e-02, -1.5568e-01,  1.8366e-01,\n",
       "         -1.1944e-01,  1.7103e-02, -9.2985e-03,  1.7836e-01, -4.2500e-02,\n",
       "          3.3664e-03, -4.5099e-02, -7.6569e-02, -3.3860e-01,  5.1871e-02,\n",
       "          2.4923e-02, -1.4062e-01, -6.2637e-01,  1.3957e-01,  8.6941e-02,\n",
       "          1.3345e-01,  6.6974e-02,  3.1551e-04, -9.8389e-02, -1.5224e-01,\n",
       "         -2.1305e-01,  1.0428e-01, -1.2858e-02, -9.6029e-02, -2.0278e-01,\n",
       "          1.4718e-01, -4.1355e-02, -1.9271e-02,  3.7408e-02,  1.7737e-01,\n",
       "         -3.1501e-03, -1.5958e-01,  8.8353e-02, -4.9291e-02, -4.1518e-01,\n",
       "         -2.3603e-01, -2.7257e-01, -8.7348e-02,  3.3134e-02, -1.1440e-01,\n",
       "         -3.6978e-01, -1.8152e-01, -3.9890e-02, -7.4246e-02, -2.1794e-01,\n",
       "         -2.2602e-01, -7.9188e-02,  1.4920e-01, -1.9367e-01, -1.6234e-01,\n",
       "         -1.5869e-01, -9.6345e-02, -3.0954e-01,  1.4371e-02, -7.6607e-02,\n",
       "         -4.5373e-02, -2.0101e-01,  1.6408e-01, -9.2181e-02, -1.5850e-01,\n",
       "          3.0835e-02,  6.8122e-02, -4.3829e-01,  2.1301e-01,  2.3025e-01,\n",
       "          2.6702e-01,  1.5739e-01, -2.8512e-01, -2.5082e-01, -2.7877e-01,\n",
       "         -1.1586e-01,  1.3557e-01,  5.4538e-02, -1.1459e-01, -5.2262e-02,\n",
       "         -3.5617e-01,  1.0644e-01,  1.5746e-02, -1.4200e-01, -1.2264e-01,\n",
       "          1.5594e-01,  1.8331e-01,  8.2166e-02,  1.5180e-01,  1.1160e-01,\n",
       "         -6.7920e-02,  1.0072e-01,  7.1354e-02,  1.4775e-01,  8.6951e-02,\n",
       "         -1.4367e-01,  1.5203e-01,  1.9439e-02,  1.8257e-01, -3.9080e-01,\n",
       "         -7.7621e-03, -9.4513e-02,  9.8704e-02, -1.2877e-01,  3.1013e-01,\n",
       "         -6.8838e-02, -6.4809e-02, -3.6022e-02, -9.7428e-02,  9.3009e-02,\n",
       "         -5.5643e-02,  1.4458e-02, -3.1395e-03, -4.5907e-02, -5.1876e-02,\n",
       "          1.6463e-01, -1.8252e-01, -5.4920e-02,  1.8844e-01,  1.1474e-01,\n",
       "          7.0437e-02, -2.8587e-01, -3.9535e-02,  1.1289e-01,  1.9457e-02,\n",
       "         -3.8496e-02,  6.6926e-02,  7.0142e-02, -5.7451e-02, -2.1038e-01,\n",
       "         -3.0925e-01,  6.1009e-02, -5.5562e-02, -1.9727e-02,  1.2381e-01,\n",
       "         -2.4642e-01, -2.4137e-01, -1.6131e-02, -1.1848e-01, -3.1250e-02,\n",
       "         -2.0887e-01,  5.7311e-02, -2.6037e-01, -1.9060e-01, -3.7112e-01,\n",
       "         -7.8697e-02, -1.1597e-01, -7.8785e-02, -1.7226e-01, -5.2941e-01,\n",
       "         -1.6463e-01,  3.5019e-02, -2.3458e-01,  1.5186e-01,  7.5505e-02,\n",
       "         -1.2339e-01, -9.1862e-02, -2.7157e-01, -8.1792e-02, -4.3181e-02,\n",
       "          2.6897e-03,  7.7479e-02, -7.8087e-02, -6.5516e-02,  3.2795e-01,\n",
       "          1.3704e-02, -7.3612e-03, -4.7919e-01,  1.4008e-01, -4.5434e-02,\n",
       "         -6.1982e-02,  6.9112e-02, -8.4057e-02, -1.5917e-01, -2.9536e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.feed_forward.encoder_1.weight_ih_l0': tensor([[-0.0346, -0.2465, -0.0975,  ..., -0.4192,  0.1062,  0.0499],\n",
       "         [-0.0313,  0.2348, -0.0045,  ..., -0.0694, -0.0617, -0.0106],\n",
       "         [ 0.4622, -0.0828,  0.1398,  ..., -0.0752, -0.1854, -0.0082],\n",
       "         ...,\n",
       "         [-0.0089,  0.3795,  0.1667,  ..., -0.0692, -0.2563, -0.1786],\n",
       "         [ 0.0705, -0.0914, -0.0169,  ...,  0.0935,  0.2491, -0.6298],\n",
       "         [-0.0427,  0.1357, -0.4090,  ..., -0.1933, -0.2609, -0.1860]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.feed_forward.encoder_1.weight_hh_l0': tensor([[-0.1908,  0.0169, -0.1711,  ..., -0.4259,  0.1313, -0.1699],\n",
       "         [ 0.0907,  0.0796,  0.1248,  ...,  0.0221, -0.2672,  0.0574],\n",
       "         [-0.0666, -0.0204, -0.1767,  ...,  0.0845,  0.1181, -0.2201],\n",
       "         ...,\n",
       "         [ 0.0683,  0.0683, -0.0374,  ..., -0.0269,  0.0479, -0.1469],\n",
       "         [ 0.1795, -0.0731, -0.0369,  ...,  0.1525,  0.0799, -0.3059],\n",
       "         [-0.0349, -0.2649, -0.2477,  ..., -0.1698,  0.1041,  0.2103]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.feed_forward.encoder_1.bias_ih_l0': tensor([ 0.1692,  0.0145, -0.0493,  0.3384,  0.1011,  0.0190,  0.0764, -0.0018,\n",
       "         -0.1758, -0.0374, -0.0369, -0.1473,  0.0474, -0.2662, -0.1442, -0.0686,\n",
       "         -0.1320,  0.0681, -0.1608,  0.0405,  0.0658, -0.1212,  0.1542, -0.0909,\n",
       "         -0.1371, -0.3584, -0.0236, -0.1021, -0.4973, -0.1235,  0.0127, -0.0805,\n",
       "         -0.1032, -0.1893,  0.1045, -0.0583, -0.3539, -0.0252, -0.1166, -0.1719,\n",
       "          0.1003,  0.1560, -0.2896,  0.1033, -0.1635,  0.0497,  0.0077, -0.3308,\n",
       "          0.0374, -0.4172,  0.1102, -0.0520, -0.1673,  0.0864, -0.2211,  0.2871,\n",
       "          0.0138,  0.0075,  0.0955,  0.0320, -0.1736,  0.0371,  0.0903, -0.3193,\n",
       "          0.0986,  0.2586, -0.0662, -0.2733, -0.2650, -0.1622,  0.1022, -0.1286,\n",
       "          0.0136, -0.1806, -0.0898, -0.1111,  0.0522, -0.0259, -0.5375, -0.0519,\n",
       "         -0.1217, -0.0818, -0.4155, -0.2396, -0.0103, -0.1862,  0.0316,  0.0189,\n",
       "         -0.0867, -0.1702,  0.0454,  0.1114, -0.1935, -0.2769, -0.1110,  0.1044,\n",
       "          0.0658,  0.0594, -0.1499, -0.2127, -0.0737,  0.1337,  0.0218, -0.0145,\n",
       "          0.1741, -0.1146, -0.0861,  0.0655,  0.1939, -0.0708, -0.1524, -0.0334,\n",
       "          0.1691,  0.0083,  0.1281, -0.1151, -0.0464,  0.0436,  0.0435, -0.2037,\n",
       "         -0.0266, -0.0021,  0.0408,  0.1958,  0.1384, -0.0856,  0.1058, -0.1584,\n",
       "         -0.2030,  0.0315, -0.0472,  0.0699, -0.2782,  0.0221, -0.0134,  0.2157,\n",
       "         -0.0885, -0.0750,  0.0093,  0.0284,  0.0803, -0.1168, -0.2920, -0.0494,\n",
       "          0.0191, -0.0283, -0.0704,  0.0445,  0.0986, -0.1902, -0.0122, -0.1788,\n",
       "         -0.1416,  0.1921,  0.0298,  0.0343, -0.0602, -0.0156, -0.0569,  0.0612,\n",
       "         -0.0552, -0.0565,  0.0611, -0.3828, -0.0398,  0.0887, -0.1690,  0.0720,\n",
       "         -0.2436,  0.2138,  0.0769, -0.0059,  0.0269,  0.0561, -0.3638, -0.2417,\n",
       "         -0.1824, -0.2805, -0.4073, -0.0217, -0.1212, -0.0098, -0.4177, -0.1636,\n",
       "          0.0354, -0.2414, -0.2113, -0.2614, -0.2756, -0.0617,  0.3013,  0.0925,\n",
       "         -0.1093, -0.2200, -0.3237, -0.0460,  0.0497, -0.2246, -0.2032, -0.3334],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.feed_forward.encoder_1.bias_hh_l0': tensor([-0.0653, -0.1714, -0.1523,  0.1672,  0.1549,  0.0364,  0.1051, -0.0797,\n",
       "         -0.0630,  0.0766, -0.2583, -0.2107,  0.0617, -0.1989, -0.0505, -0.0417,\n",
       "         -0.1788, -0.1489, -0.0843,  0.1096, -0.1111, -0.2568,  0.1550, -0.0782,\n",
       "         -0.2264, -0.2447, -0.1461, -0.0383, -0.3390, -0.0564,  0.0768, -0.2873,\n",
       "         -0.2181,  0.0075,  0.0866, -0.0965, -0.3049, -0.1139,  0.0200, -0.2330,\n",
       "         -0.0633,  0.1340, -0.0714, -0.0231, -0.0599,  0.1411,  0.0821, -0.3449,\n",
       "         -0.1246, -0.3868,  0.1381,  0.0602, -0.1856, -0.0844, -0.1996,  0.3411,\n",
       "         -0.0120,  0.1293, -0.0643, -0.1712, -0.1892,  0.1200,  0.1812, -0.3787,\n",
       "          0.1526,  0.3040, -0.1675, -0.2083, -0.3390, -0.0363, -0.0344, -0.0293,\n",
       "         -0.1004, -0.2412, -0.1706, -0.0250, -0.0995, -0.0122, -0.5308,  0.0492,\n",
       "         -0.2374, -0.2454, -0.2612, -0.3857,  0.0647, -0.2541, -0.0410, -0.0413,\n",
       "         -0.1983, -0.1552, -0.0181,  0.1214, -0.2516, -0.1280, -0.2100,  0.1991,\n",
       "          0.0707, -0.0468, -0.0993, -0.1019,  0.1638,  0.2469,  0.1870, -0.0819,\n",
       "          0.1759,  0.0173,  0.0921, -0.0717,  0.1364, -0.0519, -0.0698,  0.0152,\n",
       "          0.1480,  0.1351,  0.1217, -0.2018, -0.0364,  0.0856,  0.0948, -0.0123,\n",
       "          0.0201, -0.1727,  0.1858,  0.2482,  0.0566, -0.0064,  0.1286, -0.1942,\n",
       "         -0.2738, -0.0262, -0.1117,  0.0265, -0.0903,  0.0005,  0.0467,  0.1918,\n",
       "          0.0543,  0.0974, -0.0841, -0.0472,  0.0266, -0.1423, -0.1100, -0.0202,\n",
       "         -0.1198, -0.0599,  0.0153,  0.0775,  0.0803, -0.0278,  0.1215, -0.2744,\n",
       "         -0.0671,  0.3577, -0.1845,  0.1287, -0.1276,  0.0591, -0.1369, -0.0101,\n",
       "         -0.2394, -0.0429,  0.1183, -0.3379, -0.1113,  0.1551, -0.1126, -0.1652,\n",
       "         -0.3189,  0.2222,  0.1075, -0.0562,  0.2124, -0.0941, -0.2928, -0.2531,\n",
       "         -0.2358, -0.0996, -0.4270, -0.2093, -0.0132, -0.0126, -0.5288, -0.2198,\n",
       "          0.0535, -0.2498, -0.3411, -0.2838, -0.1171, -0.0079,  0.2744,  0.2107,\n",
       "         -0.0917, -0.3253, -0.1025, -0.1510, -0.0275, -0.2159, -0.0428, -0.2045],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.feed_forward.encoder_2.weight_ih_l0': tensor([[-0.0485,  0.0399, -0.0365,  ..., -0.1564,  0.2434,  0.1151],\n",
       "         [ 0.2491,  0.2491, -0.0810,  ..., -0.0442,  0.0313,  0.0944],\n",
       "         [ 0.0564,  0.2231, -0.0382,  ...,  0.0510,  0.0123,  0.0167],\n",
       "         ...,\n",
       "         [ 0.1297, -0.1790,  0.3318,  ...,  0.1563, -0.0744, -0.2530],\n",
       "         [-0.2265, -0.3151, -0.0010,  ...,  0.1745,  0.1978,  0.0931],\n",
       "         [ 0.0801,  0.0647,  0.0168,  ..., -0.0379,  0.1159,  0.0086]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.feed_forward.encoder_2.weight_hh_l0': tensor([[ 0.3364,  0.0335,  0.2229,  ..., -0.4697,  0.3388,  0.2833],\n",
       "         [-0.2727,  0.1072,  0.0275,  ..., -0.1074, -0.1093, -0.0687],\n",
       "         [-0.1691, -0.1885, -0.1430,  ...,  0.0100,  0.0163,  0.1271],\n",
       "         ...,\n",
       "         [ 0.0776, -0.0920,  0.1097,  ...,  0.2324, -0.1777,  0.3080],\n",
       "         [ 0.1377, -0.1165,  0.1234,  ..., -0.2000,  0.0110,  0.0957],\n",
       "         [ 0.2734,  0.0899, -0.1947,  ..., -0.1361,  0.0999, -0.0313]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.feed_forward.encoder_2.bias_ih_l0': tensor([ 0.1122, -0.2204, -0.4023, -0.0954, -0.0524, -0.3182,  0.0852,  0.1419,\n",
       "         -0.2135,  0.1901, -0.2570,  0.0109, -0.2853, -0.0015, -0.1268, -0.0881,\n",
       "         -0.1366, -0.0503, -0.0219, -0.3187, -0.2314, -0.2193, -0.1958,  0.1778,\n",
       "         -0.2225, -0.0238, -0.0267, -0.0834, -0.3582, -0.1844, -0.0753,  0.0844,\n",
       "         -0.0501,  0.1585, -0.1137, -0.0389, -0.3107, -0.0753, -0.2696, -0.1228,\n",
       "         -0.0803, -0.0702, -0.3535,  0.0482,  0.1329,  0.2867, -0.2435,  0.0135,\n",
       "         -0.0406,  0.0192,  0.2098,  0.0849, -0.2091, -0.5033, -0.1612, -0.0163,\n",
       "          0.0933, -0.1119, -0.1327, -0.2731, -0.3483,  0.1292, -0.3321,  0.1347,\n",
       "         -0.4087, -0.1335, -0.0255,  0.0362, -0.1584, -0.3266, -0.0583, -0.1441,\n",
       "         -0.2818,  0.2019, -0.0714,  0.1981,  0.0220,  0.0569, -0.1805, -0.2842,\n",
       "         -0.1830, -0.0122, -0.2318, -0.0063, -0.1986, -0.1171, -0.2544, -0.1039,\n",
       "         -0.1562, -0.2047,  0.0358,  0.1933, -0.2981,  0.0786,  0.2065,  0.1485,\n",
       "          0.0261,  0.1369, -0.0247,  0.0189,  0.2026, -0.0127, -0.0406, -0.0636,\n",
       "         -0.0385,  0.1946, -0.0806, -0.3709, -0.0716, -0.1194, -0.0238,  0.0392,\n",
       "         -0.0303,  0.1245, -0.0267, -0.0760, -0.0286,  0.0295,  0.0161, -0.1472,\n",
       "         -0.0296, -0.0886, -0.0572, -0.0426,  0.0436,  0.0104,  0.0074,  0.1224,\n",
       "          0.0529,  0.0656,  0.0532,  0.0068, -0.0993,  0.1336, -0.0122, -0.0204,\n",
       "         -0.1525,  0.0926, -0.1282, -0.0863, -0.0645,  0.0423, -0.0408,  0.1378,\n",
       "          0.2168,  0.0835, -0.1170, -0.1363,  0.1938, -0.0188, -0.0148, -0.0331,\n",
       "         -0.1688, -0.4109, -0.1583, -0.0687, -0.0343, -0.1443, -0.0063, -0.2351,\n",
       "         -0.1487, -0.2744, -0.0342,  0.2232, -0.1801, -0.1430, -0.1484, -0.0615,\n",
       "          0.0205, -0.2363, -0.1799, -0.0498, -0.1107,  0.1000, -0.0029, -0.2588,\n",
       "         -0.1513, -0.1216, -0.3030, -0.0108,  0.0945, -0.2094, -0.3661, -0.0955,\n",
       "         -0.2038, -0.0801, -0.3096, -0.1784,  0.0093, -0.5022, -0.2245, -0.1043,\n",
       "         -0.2208, -0.0634, -0.0936,  0.2230, -0.1392, -0.0006,  0.1345,  0.1055],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.feed_forward.encoder_2.bias_hh_l0': tensor([-1.8587e-03,  1.5124e-02, -4.2019e-01, -7.1088e-02, -1.6633e-02,\n",
       "         -3.4288e-01,  1.8871e-01, -5.3623e-02, -1.8264e-01, -3.8059e-04,\n",
       "         -3.3431e-01, -1.0936e-01, -2.6537e-01,  4.1669e-02, -1.8813e-01,\n",
       "         -3.8853e-03, -1.5232e-01, -1.1629e-01, -1.7631e-01, -2.5995e-01,\n",
       "         -2.2688e-01, -2.5512e-01, -3.1178e-01,  1.1681e-01, -1.1301e-01,\n",
       "         -1.1270e-01,  3.6831e-02, -1.6694e-01, -2.8508e-01,  1.0625e-02,\n",
       "         -1.3989e-01, -2.4872e-02, -4.2676e-02, -1.0073e-01, -1.6442e-01,\n",
       "         -2.1050e-02, -3.4092e-01, -2.6026e-01, -2.7219e-01, -6.5918e-02,\n",
       "          3.2783e-02, -9.4168e-02, -4.1327e-01,  2.3499e-01, -9.0413e-02,\n",
       "          2.7580e-01, -8.0971e-02, -2.4795e-02, -1.2824e-01, -1.2165e-01,\n",
       "         -9.8967e-03, -1.4048e-01, -4.2159e-01, -3.6409e-01, -2.2873e-01,\n",
       "         -1.0086e-01,  6.7800e-02, -1.0461e-01, -1.3851e-01, -3.0761e-01,\n",
       "         -3.4489e-01,  1.5097e-01, -2.9343e-01, -7.9180e-02, -1.9758e-01,\n",
       "         -2.3883e-01, -3.5077e-02,  1.1761e-01, -3.6990e-02, -3.2526e-01,\n",
       "         -1.2124e-01, -3.6563e-01, -2.2354e-01,  6.5217e-02, -5.9300e-02,\n",
       "          9.2684e-02, -7.1469e-02, -1.1828e-01, -8.5166e-04, -1.4717e-01,\n",
       "         -1.0566e-01, -1.7639e-01, -1.3587e-01,  3.8092e-03, -6.8764e-02,\n",
       "         -2.2691e-01, -8.0019e-02, -1.7669e-01, -7.0217e-02, -3.8119e-01,\n",
       "         -1.1829e-01,  1.0408e-01, -1.2570e-01,  1.3333e-02,  5.8824e-02,\n",
       "          2.1896e-01, -3.9186e-02,  1.9023e-01, -5.3372e-02,  5.8102e-02,\n",
       "          1.7153e-01, -1.8431e-03, -2.5138e-01,  2.4193e-02, -2.1223e-01,\n",
       "         -7.2191e-02,  1.2734e-01, -1.9014e-01,  3.4089e-02,  1.4513e-01,\n",
       "         -4.3362e-02,  5.7095e-02,  1.2813e-01,  4.1100e-02,  1.8771e-01,\n",
       "         -1.2836e-02,  1.2357e-01,  1.0552e-01, -1.3480e-01,  3.4501e-02,\n",
       "          7.4512e-02, -2.1550e-02, -8.9948e-02,  1.8560e-01,  8.8313e-02,\n",
       "          1.6292e-01, -1.9006e-02,  1.9534e-01, -1.3552e-01,  2.0087e-03,\n",
       "          1.6125e-02, -1.6151e-01,  1.3351e-01,  1.8458e-01, -1.7848e-01,\n",
       "          1.8080e-01, -9.1875e-02,  1.6028e-01, -1.1043e-01, -6.2847e-03,\n",
       "         -7.8680e-02,  1.6707e-01,  1.2288e-01, -2.8039e-02,  2.1410e-01,\n",
       "          8.2972e-02, -1.2264e-01, -2.0819e-01,  2.4755e-02, -1.1439e-01,\n",
       "          4.3789e-02,  3.4809e-03, -2.1111e-01, -2.9047e-01, -1.8391e-01,\n",
       "          5.5196e-02,  1.0094e-01,  4.8763e-03, -1.3255e-01, -1.9023e-01,\n",
       "         -2.3623e-01, -2.3297e-01, -3.3131e-02,  1.4352e-01, -2.1135e-01,\n",
       "         -1.2059e-02,  1.2778e-02,  7.2230e-02,  2.1435e-02, -2.4407e-01,\n",
       "         -3.1346e-01, -1.1294e-01, -9.2350e-02,  1.7493e-01,  9.5657e-02,\n",
       "         -1.0501e-01, -2.0360e-01, -3.6380e-01, -2.0171e-01,  9.4956e-02,\n",
       "         -5.8621e-02, -2.9485e-01, -3.1724e-01, -7.5449e-02, -3.8734e-01,\n",
       "         -2.1350e-01, -2.6478e-01, -7.2625e-02,  6.8702e-02, -4.1298e-01,\n",
       "         -1.3357e-01, -2.2421e-01, -1.5208e-01,  1.3202e-01,  1.9591e-03,\n",
       "          1.5183e-01, -3.3716e-01,  3.0201e-02,  3.5649e-01, -1.3054e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.sublayer.0.norm.a_2': tensor([0.2657, 0.5219, 0.3968, 0.5828, 0.3546, 0.8602, 0.5786, 0.4195, 0.5657,\n",
       "         0.4506, 0.5853, 0.6163, 0.7386, 0.2890, 0.2920, 0.7722, 0.5182, 0.3556,\n",
       "         0.3076, 0.2522, 0.2697, 0.4515, 0.5977, 0.5085, 0.2719, 0.3611, 0.3800,\n",
       "         0.5981, 0.5917, 0.2917, 0.3674, 0.7015, 0.4479, 0.2588, 0.4403, 0.5574,\n",
       "         0.1403, 0.4764, 0.5167, 0.1376, 0.8279, 0.3385, 0.3316, 0.3613, 0.3446,\n",
       "         0.4092, 0.4309, 0.6789, 0.3460, 0.2947], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.sublayer.0.norm.b_2': tensor([-0.0618,  0.3163, -0.1145,  0.1079, -0.2067,  0.0131, -0.2470,  0.0085,\n",
       "          0.0181, -0.1011,  0.0214,  0.1615,  0.0895,  0.1026,  0.0036,  0.0327,\n",
       "         -0.0059,  0.0650, -0.1039, -0.1240, -0.1119,  0.2198,  0.0819,  0.0123,\n",
       "         -0.0476, -0.1323, -0.2261,  0.2579,  0.1572, -0.1371, -0.1499,  0.1395,\n",
       "          0.3363,  0.1419, -0.0828, -0.1050,  0.0476,  0.1169,  0.0403, -0.0905,\n",
       "         -0.0280,  0.2494, -0.0685, -0.0103, -0.0932,  0.0859,  0.0640,  0.1090,\n",
       "         -0.2713, -0.1214], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.sublayer.1.norm.a_2': tensor([0.9470, 0.8470, 1.1490, 0.9879, 1.0292, 1.0554, 1.0305, 0.8056, 0.8672,\n",
       "         0.9024, 0.7718, 1.2827, 0.6169, 0.7181, 1.1265, 1.1860, 0.8680, 1.0405,\n",
       "         0.8744, 0.6445, 0.9453, 0.6728, 0.9653, 0.6242, 0.9075, 1.2436, 0.8312,\n",
       "         1.1567, 1.0167, 1.1393, 0.7610, 1.0985, 0.9084, 1.1558, 0.9048, 0.7505,\n",
       "         0.7867, 1.3297, 1.0842, 0.8418, 0.9358, 0.8785, 0.7112, 0.9641, 0.9961,\n",
       "         1.0119, 0.7055, 0.9697, 0.7781, 0.9598], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.6.sublayer.1.norm.b_2': tensor([-0.0423,  0.2684, -0.0570,  0.0077, -0.1432, -0.0325, -0.1489,  0.0324,\n",
       "         -0.0154, -0.0679,  0.0299,  0.1623,  0.1196,  0.0760, -0.0403, -0.1557,\n",
       "          0.0437,  0.0911, -0.1575,  0.0886, -0.1138,  0.2557,  0.0091, -0.1041,\n",
       "          0.1241, -0.0740, -0.2022,  0.1110, -0.0799,  0.0203,  0.0645, -0.0464,\n",
       "          0.3570,  0.1554, -0.0304, -0.0565,  0.1070, -0.1350, -0.1988, -0.2206,\n",
       "          0.2220,  0.1428,  0.0886,  0.0374,  0.1091,  0.0564, -0.0043,  0.1435,\n",
       "         -0.2328,  0.0526], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.self_attn.linears.0.weight': tensor([[-0.2423, -0.5606, -0.0843,  ..., -0.0426,  0.3294,  0.1875],\n",
       "         [ 0.1328,  0.2141,  0.0651,  ..., -0.3102, -0.1343, -0.0299],\n",
       "         [-0.1096, -0.2419,  0.0284,  ..., -0.0629,  0.3639,  0.3472],\n",
       "         ...,\n",
       "         [ 0.1110, -0.0553,  0.0644,  ..., -0.0580,  0.0852,  0.1787],\n",
       "         [ 0.0088,  0.0654, -0.1144,  ...,  0.0230,  0.1677, -0.0650],\n",
       "         [-0.1867,  0.2197,  0.0261,  ...,  0.0325,  0.0998,  0.0108]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.self_attn.linears.0.bias': tensor([ 0.5286, -0.5964,  0.3802,  0.1550, -0.6882, -0.0299, -0.3112, -0.2593,\n",
       "          0.1195,  0.4080, -0.1097, -0.1966,  0.0532, -0.0899,  0.2660, -0.2291,\n",
       "          0.0578, -0.1409, -0.2362,  0.1459, -0.0271, -0.3439, -0.0218, -0.2931,\n",
       "          0.0088,  0.3440,  0.6473,  0.1953, -0.4286,  0.5053, -0.2169,  0.6260,\n",
       "         -0.5393,  0.1755, -0.1219,  0.5657, -0.0664, -0.0113, -0.6673, -0.7261,\n",
       "          0.6261, -0.5320, -0.1608,  0.4915,  0.2919, -0.1316, -0.0374,  0.1860,\n",
       "         -0.0975,  0.1498], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.self_attn.linears.1.weight': tensor([[-0.0033, -0.2821, -0.0681,  ..., -0.4681, -0.0338, -0.0500],\n",
       "         [ 0.0018,  0.1530,  0.1967,  ...,  0.2797, -0.1238, -0.0588],\n",
       "         [-0.0589, -0.2871, -0.0852,  ..., -0.2321,  0.1564,  0.0090],\n",
       "         ...,\n",
       "         [ 0.0370,  0.1633,  0.0611,  ..., -0.0860,  0.3037, -0.0659],\n",
       "         [ 0.2036, -0.0253,  0.0127,  ..., -0.0578, -0.0256,  0.1337],\n",
       "         [-0.1878,  0.2613,  0.2159,  ...,  0.0250, -0.1549, -0.0514]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.self_attn.linears.1.bias': tensor([-0.0789, -0.1411, -0.0460, -0.0866,  0.0874, -0.0903,  0.0955, -0.1204,\n",
       "         -0.0193, -0.1312,  0.1102, -0.1048,  0.0410, -0.1079,  0.0975, -0.0970,\n",
       "          0.1302,  0.0401, -0.0026,  0.1350,  0.0527, -0.0560,  0.1290, -0.1341,\n",
       "          0.1307,  0.1356,  0.1026, -0.0706, -0.0911,  0.0842,  0.0821,  0.1341,\n",
       "         -0.1218, -0.0806, -0.1367,  0.1334,  0.0300,  0.1203, -0.0412, -0.1075,\n",
       "          0.1184,  0.0117, -0.0881,  0.0003,  0.1279, -0.0429, -0.0396,  0.0975,\n",
       "         -0.0364,  0.0842], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.self_attn.linears.2.weight': tensor([[-3.3838e-02, -1.8121e-01,  1.5397e-02,  ..., -7.9577e-02,\n",
       "          -9.0052e-02,  4.9022e-02],\n",
       "         [-6.4251e-02,  2.8826e-02,  1.3577e-01,  ..., -5.3664e-02,\n",
       "           1.8728e-01, -3.6388e-02],\n",
       "         [-1.0788e-02, -6.6730e-03, -3.8685e-02,  ..., -5.6981e-02,\n",
       "          -6.6144e-02,  2.9038e-01],\n",
       "         ...,\n",
       "         [ 1.0072e-01,  1.1186e-01, -6.9226e-03,  ..., -3.4413e-02,\n",
       "          -3.1715e-02,  8.9233e-02],\n",
       "         [ 1.2421e-01, -6.4129e-02,  4.5399e-02,  ..., -1.6329e-02,\n",
       "           6.9618e-02, -1.0151e-01],\n",
       "         [-3.2073e-02,  1.7854e-01,  4.6428e-03,  ..., -1.4121e-01,\n",
       "           3.9452e-02, -1.4442e-04]], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.self_attn.linears.2.bias': tensor([-6.1467e-02,  2.8007e-02, -6.2773e-02, -2.8967e-02,  4.6180e-02,\n",
       "         -9.6573e-02,  1.1178e-01, -1.3600e-01,  5.8377e-03, -3.9074e-02,\n",
       "          1.7566e-01, -1.1223e-01, -1.4244e-02, -2.1147e-02,  1.0832e-02,\n",
       "         -2.1751e-01,  1.8553e-01,  2.3053e-02, -4.0401e-02,  5.6333e-02,\n",
       "          5.5499e-02, -6.2870e-03,  1.6388e-01, -1.5069e-01,  1.0756e-01,\n",
       "          1.0904e-02,  1.7706e-01,  3.1353e-02,  1.8374e-02,  2.0043e-02,\n",
       "          9.9016e-02,  1.7642e-01, -7.5000e-02,  2.0106e-04, -3.6150e-02,\n",
       "          9.8729e-02,  4.7541e-02,  2.2282e-02,  6.6723e-03, -1.3333e-01,\n",
       "          1.0157e-02, -3.8111e-03, -3.4524e-02,  4.3191e-02,  1.0562e-01,\n",
       "         -1.1305e-02, -2.1245e-02,  3.0757e-02, -1.9941e-02,  1.7023e-03],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.self_attn.linears.3.weight': tensor([[-2.6785e-02, -7.1028e-02,  2.2193e-01,  ..., -9.3362e-02,\n",
       "          -5.4446e-02,  8.2191e-03],\n",
       "         [ 3.9509e-02, -6.0698e-02,  2.1526e-01,  ...,  1.6609e-02,\n",
       "           8.5765e-02,  3.8870e-02],\n",
       "         [ 3.8259e-03, -6.4955e-02,  5.0752e-02,  ...,  1.8679e-02,\n",
       "          -7.3594e-02, -4.9779e-02],\n",
       "         ...,\n",
       "         [ 6.1033e-02,  9.7203e-02, -9.7941e-02,  ...,  9.0799e-03,\n",
       "          -9.1730e-02,  7.3426e-02],\n",
       "         [ 5.3360e-03, -1.2028e-01,  1.6953e-01,  ..., -1.1168e-01,\n",
       "           1.4396e-01,  2.1713e-02],\n",
       "         [-1.0115e-01, -2.0524e-02, -4.1407e-03,  ..., -1.0878e-01,\n",
       "          -1.2030e-04, -9.8367e-03]], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.self_attn.linears.3.bias': tensor([-0.2270, -0.2075, -0.0524,  0.0115,  0.2070, -0.1394,  0.5542, -0.1814,\n",
       "         -0.0603, -0.0119, -0.0580,  0.0551, -0.1628, -0.1488,  0.1765, -0.1105,\n",
       "         -0.0137,  0.0276,  0.1133,  0.1440,  0.1594, -0.2107, -0.0009, -0.0865,\n",
       "          0.1012,  0.0573,  0.2936, -0.3056, -0.1815,  0.1842,  0.1042, -0.2573,\n",
       "         -0.8169,  0.0881, -0.1377,  0.0812,  0.0534,  0.0018, -0.1284,  0.0976,\n",
       "          0.0347,  0.0228, -0.0854, -0.1011,  0.2083, -0.0275,  0.0032, -0.0542,\n",
       "          0.6163,  0.1970], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.feed_forward.bn.weight': tensor([0.6139, 0.8658, 1.0364, 1.3251, 1.0974, 0.7545, 1.0205, 0.7955, 0.7719,\n",
       "         1.1221, 0.8416, 1.2055, 0.8008, 0.5057, 1.1602, 1.1171, 0.7997, 0.8509,\n",
       "         0.7366, 1.0805, 0.9731, 0.8085, 0.8397, 0.8414, 0.8624, 1.0622, 1.2355,\n",
       "         0.8438, 1.0337, 0.8352, 1.0036, 0.5754, 0.6841, 1.2597, 0.7107, 0.8155,\n",
       "         0.6354, 0.7868, 1.1509, 1.0765, 0.8243, 0.9201, 1.0787, 0.7841, 1.1055,\n",
       "         1.3315, 0.8307, 0.8535, 1.5693, 1.0004], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.feed_forward.bn.bias': tensor([-0.4476, -0.1655, -0.1800,  0.1786, -0.0517, -0.2254,  0.1718, -0.2307,\n",
       "         -0.3171,  0.0701, -0.1967,  0.1465, -0.3567, -0.4219, -0.0507, -0.1343,\n",
       "         -0.3209, -0.2473, -0.1691, -0.0533, -0.1197, -0.1348, -0.2603, -0.1746,\n",
       "         -0.2463, -0.1687,  0.2034, -0.3503, -0.3379, -0.1629, -0.1473, -0.3511,\n",
       "         -0.5496,  0.1563, -0.3348, -0.1152, -0.2682, -0.2173,  0.0224,  0.0234,\n",
       "         -0.2260, -0.1761, -0.3156, -0.3104,  0.1000, -0.0149, -0.1114, -0.2520,\n",
       "          0.5121, -0.0473], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.feed_forward.bn.running_mean': tensor([ 0.0579, -0.1030,  0.0150,  0.0168,  0.2603,  0.1857, -0.0293,  0.0497,\n",
       "          0.3330,  0.1656,  0.0460,  0.1785,  0.1182,  0.1957,  0.0731,  0.0337,\n",
       "          0.0522,  0.0738,  0.1081,  0.0018,  0.1040, -0.0452,  0.0435,  0.1661,\n",
       "          0.0606,  0.0614, -0.1097,  0.0559, -0.0106,  0.1265,  0.1006,  0.1535,\n",
       "         -0.0426, -0.0157, -0.1075,  0.0316,  0.2359,  0.0350,  0.0521, -0.1083,\n",
       "         -0.1128, -0.2155,  0.0284,  0.1188,  0.0890, -0.0871,  0.1412, -0.0662,\n",
       "         -0.0010,  0.1166], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.feed_forward.bn.running_var': tensor([0.2364, 0.1004, 0.1008, 0.0397, 0.1277, 0.1435, 0.3459, 0.0770, 0.1192,\n",
       "         0.0839, 0.0511, 0.1003, 0.0659, 0.1797, 0.0430, 0.1014, 0.0250, 0.0714,\n",
       "         0.1779, 0.0792, 0.1935, 0.0631, 0.1141, 0.0946, 0.0444, 0.0335, 0.1214,\n",
       "         0.0485, 0.1029, 0.1089, 0.0481, 0.1125, 0.1194, 0.0803, 0.0318, 0.0663,\n",
       "         0.1108, 0.0374, 0.0409, 0.0649, 0.1015, 0.0903, 0.0240, 0.0616, 0.0741,\n",
       "         0.1017, 0.2612, 0.1416, 0.2021, 0.1993], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.feed_forward.bn.num_batches_tracked': tensor(213030),\n",
       " 'transformer_pre.model.layers.7.feed_forward.encoder_0.weight_ih_l0': tensor([[ 0.2588, -0.0654,  0.1378,  ..., -0.1843, -0.0172,  0.0573],\n",
       "         [ 0.0102, -0.1685,  0.0251,  ...,  0.1412,  0.1076, -0.0890],\n",
       "         [-0.2087,  0.0236, -0.3229,  ...,  0.0796,  0.1774, -0.0396],\n",
       "         ...,\n",
       "         [ 0.0256,  0.0157,  0.1603,  ...,  0.1381, -0.0537, -0.1728],\n",
       "         [-0.2497, -0.3141, -0.0719,  ...,  0.2218,  0.0353, -0.1999],\n",
       "         [-0.0820, -0.0680,  0.0320,  ..., -0.3552, -0.0801,  0.1761]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.feed_forward.encoder_0.weight_hh_l0': tensor([[-0.1708, -0.1247,  0.0370,  ..., -0.0452,  0.0223, -0.0245],\n",
       "         [ 0.0020,  0.3720,  0.0606,  ..., -0.1604, -0.0074, -0.1079],\n",
       "         [-0.2692, -0.1862,  0.1120,  ...,  0.1021,  0.0955,  0.3316],\n",
       "         ...,\n",
       "         [-0.1280,  0.0409, -0.0911,  ..., -0.2916,  0.3351,  0.0330],\n",
       "         [-0.1721, -0.0898, -0.0110,  ...,  0.0921,  0.1459, -0.1802],\n",
       "         [ 0.0815, -0.2122, -0.0500,  ...,  0.2057, -0.2368, -0.0436]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.feed_forward.encoder_0.bias_ih_l0': tensor([-0.1218,  0.1371,  0.1065, -0.0777,  0.0632, -0.2449,  0.1002,  0.2846,\n",
       "          0.1105, -0.2918,  0.0829, -0.0585,  0.0963,  0.0937,  0.1799, -0.1326,\n",
       "          0.0426, -0.0256,  0.0282, -0.1679,  0.0631, -0.1347, -0.3933, -0.0249,\n",
       "         -0.0518, -0.1757, -0.2423, -0.2241,  0.1778, -0.2830, -0.1453, -0.1006,\n",
       "         -0.2626,  0.0687,  0.1136, -0.1130, -0.4166, -0.1182, -0.2652,  0.1294,\n",
       "         -0.0647,  0.0417, -0.4133, -0.1523,  0.0430,  0.1105, -0.2930,  0.0767,\n",
       "          0.0419, -0.1409,  0.0029,  0.1825, -0.0238, -0.0110, -0.4449, -0.3433,\n",
       "          0.0856,  0.1784,  0.1280, -0.2511,  0.0106, -0.2343,  0.2924, -0.0260,\n",
       "         -0.0478,  0.0503, -0.1764, -0.0519, -0.3112, -0.1414,  0.0139,  0.0127,\n",
       "          0.0151, -0.0019, -0.1902,  0.0193,  0.1149, -0.2248,  0.0050, -0.2509,\n",
       "         -0.2467, -0.1642, -0.0666,  0.0358,  0.2314, -0.2208, -0.0694, -0.1865,\n",
       "         -0.2705, -0.0837, -0.1039, -0.0902, -0.3242,  0.0509, -0.1684,  0.0583,\n",
       "         -0.0645, -0.0140, -0.2853, -0.0707,  0.2686, -0.0146,  0.0894,  0.0066,\n",
       "          0.0197, -0.0156,  0.0040,  0.0318,  0.1307,  0.1710,  0.1682,  0.1990,\n",
       "          0.0797,  0.0067,  0.1103,  0.1458,  0.0331,  0.0494, -0.0804,  0.0286,\n",
       "          0.1598,  0.0106, -0.1617,  0.0335,  0.0912,  0.1001, -0.1144,  0.1241,\n",
       "         -0.1402, -0.1801, -0.2148,  0.2356, -0.0543,  0.1210, -0.2824, -0.2315,\n",
       "          0.0187, -0.0328, -0.0722, -0.0771,  0.0933, -0.1794,  0.0043,  0.1226,\n",
       "          0.1070, -0.0836,  0.0965, -0.0542,  0.1944,  0.1334, -0.1652, -0.0631,\n",
       "          0.0514, -0.0503, -0.0311, -0.0822,  0.3052,  0.0790, -0.0300, -0.3099,\n",
       "         -0.2681,  0.0443,  0.0079, -0.0142, -0.0481,  0.0337, -0.1093, -0.0703,\n",
       "          0.1173, -0.0173,  0.0594, -0.0433, -0.0320,  0.0691, -0.0332, -0.1329,\n",
       "          0.0645,  0.0212,  0.1300, -0.5202, -0.0358, -0.0271, -0.1429, -0.0258,\n",
       "         -0.3023, -0.1886, -0.2283, -0.1752, -0.1945, -0.1025,  0.0980,  0.1421,\n",
       "         -0.3726,  0.1828, -0.1780,  0.0704, -0.3181,  0.1272, -0.1619,  0.0012],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.feed_forward.encoder_0.bias_hh_l0': tensor([ 0.0337,  0.1503,  0.2310, -0.1822, -0.0812, -0.1219,  0.0967,  0.1640,\n",
       "          0.1540, -0.3695, -0.0290, -0.1383,  0.1630, -0.0851,  0.1948,  0.0831,\n",
       "          0.0317,  0.0185, -0.0186, -0.0434,  0.0777, -0.1534, -0.2362, -0.0621,\n",
       "         -0.1560, -0.2627, -0.0119, -0.1911, -0.0385, -0.2065, -0.1649, -0.1282,\n",
       "         -0.1374,  0.2130,  0.2391,  0.0746, -0.3869, -0.1888, -0.4299,  0.0441,\n",
       "         -0.1229, -0.1160, -0.4539, -0.0749,  0.1717,  0.2023, -0.1887,  0.2924,\n",
       "         -0.0530, -0.0916, -0.1217,  0.2310, -0.0028, -0.1756, -0.3656, -0.2015,\n",
       "          0.0321,  0.3672, -0.0218, -0.1895,  0.0537, -0.0697,  0.2545, -0.0887,\n",
       "         -0.1243, -0.0857, -0.2807, -0.0477, -0.3112, -0.0274,  0.1073, -0.0928,\n",
       "         -0.1644, -0.2173, -0.2358, -0.1355, -0.0431, -0.0285, -0.1604, -0.2829,\n",
       "         -0.1636,  0.0227, -0.3234, -0.1213,  0.0723, -0.2931, -0.2775, -0.0657,\n",
       "         -0.4278, -0.1814, -0.0954, -0.0575, -0.3629,  0.2057, -0.1107,  0.2609,\n",
       "         -0.0720, -0.0632, -0.3894, -0.1423,  0.0058,  0.0333, -0.0321, -0.0225,\n",
       "         -0.0412,  0.0123,  0.0654,  0.0582, -0.0514,  0.0354,  0.1566,  0.2372,\n",
       "          0.0997,  0.1741,  0.1023, -0.0143,  0.1321,  0.1039,  0.1865,  0.0440,\n",
       "         -0.0438,  0.0185, -0.0406,  0.1505, -0.0946, -0.0578,  0.0018,  0.1045,\n",
       "         -0.1612,  0.0168, -0.1763,  0.1434,  0.0334, -0.1462, -0.2827, -0.1468,\n",
       "          0.0098, -0.0363, -0.0704, -0.1335,  0.1210, -0.0504, -0.0495,  0.0332,\n",
       "          0.1559,  0.0136, -0.1621, -0.1877,  0.0721,  0.1520, -0.1533, -0.1770,\n",
       "          0.1219,  0.0343, -0.1350, -0.2354,  0.2960, -0.0492,  0.1521, -0.1518,\n",
       "         -0.2163, -0.1456, -0.0957, -0.0932,  0.0447, -0.0539, -0.1389, -0.1617,\n",
       "         -0.0921, -0.1439, -0.0651, -0.0312, -0.2217, -0.1270, -0.1133, -0.2123,\n",
       "          0.1093, -0.1442,  0.1885, -0.2704, -0.0881, -0.0310, -0.1751, -0.2361,\n",
       "         -0.2930, -0.0307, -0.1517, -0.1985, -0.2480,  0.0991,  0.2212,  0.0439,\n",
       "         -0.4440,  0.0243, -0.1527, -0.0480, -0.2047,  0.0929, -0.0294,  0.0096],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.feed_forward.encoder_1.weight_ih_l0': tensor([[-0.1588, -0.0733, -0.3157,  ..., -0.1659,  0.0582, -0.1764],\n",
       "         [-0.0389,  0.1413, -0.0108,  ..., -0.1899, -0.1419, -0.0469],\n",
       "         [ 0.3618, -0.0026,  0.1036,  ..., -0.0181, -0.2344, -0.0890],\n",
       "         ...,\n",
       "         [ 0.0795,  0.1861,  0.1998,  ..., -0.0275, -0.3479, -0.0876],\n",
       "         [ 0.0555, -0.1301, -0.1090,  ...,  0.0703,  0.2699, -0.4606],\n",
       "         [-0.0374,  0.0350, -0.3209,  ..., -0.2127, -0.0767, -0.0353]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.feed_forward.encoder_1.weight_hh_l0': tensor([[-0.0625,  0.0727, -0.1455,  ..., -0.4373, -0.0233,  0.0332],\n",
       "         [ 0.1311, -0.0008, -0.0909,  ..., -0.1493,  0.0079, -0.1695],\n",
       "         [-0.0121,  0.0324, -0.2452,  ...,  0.2034,  0.2620, -0.1240],\n",
       "         ...,\n",
       "         [ 0.0008,  0.0756, -0.1741,  ...,  0.0283,  0.2091, -0.1619],\n",
       "         [ 0.0639, -0.1002, -0.2176,  ...,  0.1565,  0.1929,  0.0080],\n",
       "         [ 0.0274,  0.2966, -0.1159,  ...,  0.0631, -0.1064, -0.4218]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.feed_forward.encoder_1.bias_ih_l0': tensor([ 0.0810, -0.1228, -0.1367,  0.2198,  0.0743,  0.1107,  0.0553, -0.2085,\n",
       "         -0.0522,  0.0381, -0.0579, -0.1741, -0.2135, -0.2490, -0.0978, -0.0782,\n",
       "         -0.1791,  0.1048,  0.0997, -0.2491, -0.0276,  0.0901, -0.0130, -0.0713,\n",
       "         -0.1122, -0.2539,  0.0108, -0.3454, -0.3855,  0.0848, -0.3854,  0.0813,\n",
       "         -0.2744, -0.2973, -0.1667,  0.0476, -0.1638, -0.0138, -0.0599, -0.1960,\n",
       "         -0.0327,  0.0911, -0.6697,  0.0164, -0.0647, -0.1823,  0.0885, -0.2798,\n",
       "         -0.0534, -0.1789,  0.1379, -0.3840, -0.1594,  0.2241, -0.1380,  0.1879,\n",
       "          0.0867,  0.0013,  0.1430,  0.1443, -0.0411,  0.0216, -0.1288, -0.4152,\n",
       "          0.0875,  0.1916, -0.1539, -0.0921, -0.1832, -0.2551,  0.0683,  0.0264,\n",
       "         -0.0109, -0.1143, -0.0428, -0.1671,  0.0607, -0.2964, -0.4344,  0.0211,\n",
       "         -0.2864,  0.1133, -0.3970, -0.4521, -0.1948, -0.2090,  0.1435, -0.0117,\n",
       "         -0.0685, -0.0993, -0.1381, -0.1990, -0.4238, -0.2327, -0.1455, -0.2345,\n",
       "          0.1170, -0.2242, -0.2309, -0.1066, -0.0772, -0.0396,  0.0982,  0.0479,\n",
       "          0.1039,  0.0094, -0.0658,  0.2493,  0.2938,  0.2546, -0.2531, -0.0666,\n",
       "         -0.0998, -0.1502,  0.0831,  0.0743, -0.1750, -0.0811,  0.1811, -0.1923,\n",
       "         -0.0123,  0.0416, -0.1360,  0.1226,  0.1017,  0.0038,  0.2071, -0.1732,\n",
       "         -0.1095, -0.0164,  0.0135,  0.1020, -0.1141, -0.0084, -0.1060,  0.1422,\n",
       "          0.0306, -0.0063, -0.0329,  0.0787,  0.0543, -0.1911, -0.2853, -0.0250,\n",
       "          0.0187, -0.1454,  0.1280,  0.0806,  0.1176,  0.0500, -0.0172, -0.2850,\n",
       "         -0.1265,  0.0727,  0.0333,  0.0047, -0.0336, -0.1794,  0.0430,  0.0658,\n",
       "         -0.1127, -0.1530, -0.4305, -0.1511, -0.0765, -0.0022, -0.3008, -0.0738,\n",
       "         -0.0635, -0.1960, -0.1770,  0.1149, -0.0397,  0.2132, -0.1964, -0.1917,\n",
       "         -0.1250, -0.4489, -0.3042,  0.1448, -0.4181,  0.1465, -0.4297, -0.1427,\n",
       "         -0.2679, -0.2909,  0.0721, -0.2112, -0.2294,  0.0567,  0.1081,  0.0825,\n",
       "         -0.6457, -0.2486, -0.1456, -0.3294,  0.1188, -0.2482, -0.3461, -0.1221],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.feed_forward.encoder_1.bias_hh_l0': tensor([-1.5352e-01, -3.0873e-01, -2.3970e-01,  4.8614e-02,  1.2812e-01,\n",
       "          1.2810e-01,  8.4022e-02, -2.8643e-01,  6.0665e-02,  1.5212e-01,\n",
       "         -2.7936e-01, -2.3748e-01, -1.9916e-01, -1.8167e-01, -4.1681e-03,\n",
       "         -5.1321e-02, -2.2591e-01, -1.1218e-01,  1.7625e-01, -1.7999e-01,\n",
       "         -2.0455e-01, -4.5449e-02, -1.2201e-02, -5.8592e-02, -2.0147e-01,\n",
       "         -1.4016e-01, -1.1166e-01, -2.8167e-01, -2.2721e-01,  1.5198e-01,\n",
       "         -3.2136e-01, -1.2545e-01, -3.8930e-01, -1.0054e-01, -1.8469e-01,\n",
       "          9.4043e-03, -1.1484e-01, -1.0242e-01,  7.6671e-02, -2.5707e-01,\n",
       "         -1.9629e-01,  6.9049e-02, -4.5159e-01, -1.0996e-01,  3.8931e-02,\n",
       "         -9.0896e-02,  1.6290e-01, -2.9387e-01, -2.1538e-01, -1.4848e-01,\n",
       "          1.6578e-01, -2.7174e-01, -1.7769e-01,  5.3307e-02, -1.1650e-01,\n",
       "          2.4195e-01,  6.0912e-02,  1.2310e-01, -1.6801e-02, -5.8888e-02,\n",
       "         -5.6663e-02,  1.0446e-01, -3.7944e-02, -4.7462e-01,  1.4147e-01,\n",
       "          2.3707e-01, -2.5517e-01, -2.7207e-02, -2.5727e-01, -1.2916e-01,\n",
       "         -6.8351e-02,  1.2567e-01, -1.2495e-01, -1.7499e-01, -1.2371e-01,\n",
       "         -8.0970e-02, -9.1083e-02, -2.8271e-01, -4.2767e-01,  1.2215e-01,\n",
       "         -4.0206e-01, -5.0326e-02, -2.4268e-01, -5.9830e-01, -1.1981e-01,\n",
       "         -2.7693e-01,  7.0860e-02, -7.1888e-02, -1.8006e-01, -8.4307e-02,\n",
       "         -2.0158e-01, -1.8902e-01, -4.8190e-01, -8.3846e-02, -2.4454e-01,\n",
       "         -1.3985e-01,  1.2187e-01, -3.3050e-01, -1.8032e-01,  4.2174e-03,\n",
       "          1.6019e-01,  7.3509e-02,  2.6344e-01, -1.9556e-02,  1.0569e-01,\n",
       "          1.4136e-01,  1.1233e-01,  1.1207e-01,  2.3630e-01,  2.7357e-01,\n",
       "         -1.7057e-01, -1.7950e-02, -1.2082e-01, -2.3488e-02,  7.6726e-02,\n",
       "         -1.2426e-02, -1.6491e-01, -3.9166e-02,  2.3237e-01, -8.6068e-04,\n",
       "          3.4327e-02, -1.2896e-01,  8.9208e-03,  1.7505e-01,  1.9916e-02,\n",
       "          8.2963e-02,  2.2982e-01, -2.0910e-01, -1.8026e-01, -7.4117e-02,\n",
       "         -5.0987e-02,  5.8648e-02,  7.3862e-02, -2.9933e-02, -4.5912e-02,\n",
       "          1.1830e-01,  1.7340e-01,  1.6612e-01, -1.2635e-01,  3.1600e-03,\n",
       "          4.8727e-04, -2.1662e-01, -1.0325e-01,  4.2136e-03, -1.2018e-01,\n",
       "         -1.7698e-01,  2.1371e-01,  1.1364e-01,  9.9392e-02,  2.1239e-01,\n",
       "          1.1640e-01, -3.8057e-01, -5.1942e-02,  2.3833e-01, -1.8101e-01,\n",
       "          9.9108e-02, -1.0095e-01, -1.0463e-01, -3.7024e-02, -5.4978e-03,\n",
       "         -2.9691e-01, -1.3944e-01, -3.7328e-01, -1.0622e-01, -1.4806e-01,\n",
       "          6.4229e-02, -2.4439e-01, -3.1092e-01, -1.3878e-01, -1.8761e-01,\n",
       "         -1.4638e-01,  6.4634e-02,  1.4572e-01,  6.2955e-02, -1.2543e-01,\n",
       "         -2.0311e-01, -1.7846e-01, -2.6798e-01, -3.2392e-01, -4.2817e-02,\n",
       "         -3.1008e-01,  1.4372e-01, -5.4076e-01, -1.9896e-01, -2.4979e-01,\n",
       "         -2.9924e-01, -5.7686e-02, -2.3356e-01, -7.0877e-02,  1.1064e-01,\n",
       "          8.1190e-02,  2.0070e-01, -6.2809e-01, -3.5395e-01,  7.5573e-02,\n",
       "         -4.3437e-01,  4.1720e-02, -2.3949e-01, -1.8563e-01,  6.8538e-03],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.feed_forward.encoder_2.weight_ih_l0': tensor([[ 0.1428, -0.2163,  0.0175,  ..., -0.2580,  0.0818,  0.1078],\n",
       "         [ 0.4422,  0.1384,  0.0893,  ...,  0.0053,  0.0990, -0.1361],\n",
       "         [ 0.1859,  0.3742, -0.0493,  ...,  0.0156, -0.1570,  0.0707],\n",
       "         ...,\n",
       "         [-0.3547, -0.2699, -0.1141,  ...,  0.2517,  0.0846, -0.1266],\n",
       "         [-0.2934, -0.1971,  0.0594,  ...,  0.0539,  0.2641,  0.1422],\n",
       "         [-0.0320,  0.0688, -0.1238,  ..., -0.0515,  0.1668,  0.0516]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.feed_forward.encoder_2.weight_hh_l0': tensor([[ 0.3075, -0.0598,  0.2239,  ..., -0.4322,  0.3954,  0.2779],\n",
       "         [-0.0195, -0.0464,  0.2405,  ..., -0.0039, -0.1625,  0.0528],\n",
       "         [-0.1948, -0.0106,  0.0387,  ..., -0.1894,  0.0939,  0.1239],\n",
       "         ...,\n",
       "         [-0.2880,  0.0762, -0.1080,  ...,  0.2525,  0.0952, -0.1169],\n",
       "         [ 0.1339, -0.3366, -0.0692,  ...,  0.1022,  0.0042,  0.1123],\n",
       "         [-0.1007,  0.2227, -0.0430,  ...,  0.0609,  0.0523, -0.2076]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.feed_forward.encoder_2.bias_ih_l0': tensor([ 0.2240, -0.1902, -0.2160, -0.0691,  0.0474, -0.0736, -0.1869,  0.0795,\n",
       "         -0.1565,  0.1787, -0.1367, -0.1289, -0.1764, -0.0687, -0.0961, -0.2827,\n",
       "         -0.2364, -0.0977,  0.0075, -0.2128,  0.1165, -0.0113,  0.0214,  0.0242,\n",
       "         -0.2387, -0.0149, -0.0403,  0.0475, -0.3923, -0.1571,  0.0164, -0.0781,\n",
       "          0.0888,  0.0965,  0.0226, -0.2639,  0.0464, -0.2263, -0.2152, -0.0893,\n",
       "         -0.1096, -0.2987, -0.0080, -0.3600,  0.0629,  0.2230,  0.0580,  0.1537,\n",
       "          0.0103,  0.4012,  0.2030, -0.0052, -0.1717, -0.3545, -0.0330,  0.0704,\n",
       "         -0.1458,  0.1253, -0.1437, -0.1203, -0.5915,  0.1506, -0.2406,  0.1823,\n",
       "         -0.0957, -0.1668,  0.0167, -0.1228, -0.2096, -0.2463, -0.1089,  0.1706,\n",
       "         -0.1384,  0.2241, -0.2081,  0.1757, -0.0448,  0.0678, -0.1296, -0.2513,\n",
       "         -0.1262, -0.1072,  0.0188, -0.1810, -0.1544, -0.2049,  0.0730, -0.0485,\n",
       "         -0.1622, -0.1828,  0.0587, -0.0538, -0.1500, -0.2044, -0.2390, -0.1602,\n",
       "          0.1436,  0.1424, -0.1063,  0.3581,  0.0827, -0.0720,  0.0299,  0.0151,\n",
       "          0.2339,  0.2249, -0.2119, -0.1595,  0.1317, -0.2545, -0.0103,  0.0670,\n",
       "         -0.0091,  0.0892,  0.0568, -0.0090, -0.0046, -0.0684,  0.0133, -0.0958,\n",
       "          0.0237,  0.0468,  0.0927, -0.0574, -0.0545,  0.0326, -0.2090,  0.1499,\n",
       "          0.1300,  0.0654,  0.1143,  0.0746, -0.0286, -0.0056, -0.1230,  0.0112,\n",
       "          0.1450, -0.1974, -0.0264, -0.1514, -0.1063, -0.2739, -0.0522,  0.2084,\n",
       "         -0.0075,  0.0749, -0.1163, -0.1333,  0.1209,  0.0490,  0.1328,  0.0248,\n",
       "         -0.2153, -0.5408,  0.0024, -0.1206, -0.1883, -0.1980, -0.1112, -0.1274,\n",
       "         -0.1362, -0.0274,  0.0155,  0.1667, -0.2760, -0.1534, -0.2066, -0.2448,\n",
       "          0.1496, -0.2816,  0.1467, -0.0654,  0.0610,  0.0302, -0.2595, -0.2151,\n",
       "         -0.1174,  0.0059, -0.3053, -0.0767,  0.0639, -0.3195, -0.1625, -0.1074,\n",
       "         -0.2736, -0.3220,  0.1623, -0.3216, -0.0050, -0.1156, -0.2836, -0.1581,\n",
       "         -0.0916, -0.2154, -0.3020,  0.1646,  0.1693,  0.0788,  0.0699,  0.2169],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.feed_forward.encoder_2.bias_hh_l0': tensor([ 0.1100,  0.0454, -0.2339, -0.0448,  0.0833, -0.0983, -0.0834, -0.1161,\n",
       "         -0.1256, -0.0118, -0.2140, -0.2492, -0.1565, -0.0256, -0.1574, -0.1985,\n",
       "         -0.2521, -0.1636, -0.1469, -0.1541,  0.1211, -0.0471, -0.0946, -0.0368,\n",
       "         -0.1292, -0.1038,  0.0232, -0.0360, -0.3193,  0.0379, -0.0482, -0.1874,\n",
       "          0.0963, -0.1628, -0.0281, -0.2461,  0.0161, -0.4112, -0.2177, -0.0325,\n",
       "          0.0035, -0.3227, -0.0678, -0.1732, -0.1603,  0.2121,  0.2205,  0.1153,\n",
       "         -0.0774,  0.2603, -0.0167, -0.2306, -0.3842, -0.2153, -0.1005, -0.0141,\n",
       "         -0.1713,  0.1326, -0.1495, -0.1548, -0.5880,  0.1724, -0.2019, -0.0316,\n",
       "          0.1154, -0.2721,  0.0071, -0.0414, -0.0881, -0.2449, -0.1718, -0.0509,\n",
       "         -0.0802,  0.0875, -0.1960,  0.0704, -0.1383, -0.1074,  0.0501, -0.1142,\n",
       "         -0.0489, -0.2714,  0.1148, -0.1708, -0.0246, -0.3147,  0.2474, -0.1213,\n",
       "         -0.0762, -0.3593, -0.0955, -0.1430,  0.0225, -0.2697, -0.3867, -0.0897,\n",
       "          0.0783,  0.1957, -0.1349,  0.3973,  0.0516, -0.0611, -0.1808,  0.1029,\n",
       "          0.0601, -0.0419, -0.0040,  0.0212,  0.2374,  0.0101, -0.0299,  0.0849,\n",
       "          0.1493,  0.0058,  0.2711,  0.0542,  0.1476,  0.0076, -0.1375,  0.0859,\n",
       "          0.1278,  0.1138,  0.0599,  0.1708, -0.0097,  0.1851, -0.2354,  0.2229,\n",
       "         -0.0584,  0.0017,  0.0772, -0.0937,  0.2041,  0.0454, -0.2893,  0.2124,\n",
       "          0.2056, -0.1298, -0.0086, -0.0714, -0.1205, -0.1491,  0.1114,  0.0426,\n",
       "         -0.0102,  0.0745, -0.1220, -0.2052, -0.0481, -0.0466,  0.1914,  0.0614,\n",
       "         -0.2576, -0.4204, -0.0232,  0.0033, -0.0530, -0.0488, -0.2375, -0.0825,\n",
       "         -0.2238,  0.0141,  0.0166,  0.0871, -0.3072, -0.0225, -0.0455, -0.1110,\n",
       "          0.1506, -0.2893,  0.0131, -0.1286,  0.0793,  0.1051, -0.1609, -0.0613,\n",
       "         -0.1697, -0.2363, -0.2040,  0.0291, -0.0892, -0.4050, -0.1136, -0.0873,\n",
       "         -0.4571, -0.4555,  0.2072, -0.2158,  0.0544, -0.0264, -0.1927, -0.2780,\n",
       "         -0.0229, -0.0199, -0.2065,  0.0934, -0.0286,  0.1097,  0.2919, -0.0192],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.sublayer.0.norm.a_2': tensor([0.2490, 0.5496, 0.3628, 0.4900, 0.4431, 0.7266, 0.6189, 0.5512, 0.5089,\n",
       "         0.5579, 0.5845, 0.7491, 0.6684, 0.5178, 0.4645, 0.7136, 0.5535, 0.4109,\n",
       "         0.4353, 0.2544, 0.3468, 0.4029, 0.6143, 0.3907, 0.3481, 0.3223, 0.4770,\n",
       "         0.6865, 0.5605, 0.4433, 0.3355, 0.6339, 0.4408, 0.2412, 0.3434, 0.6037,\n",
       "         0.2546, 0.6067, 0.5408, 0.2640, 0.7673, 0.4102, 0.4276, 0.4456, 0.3614,\n",
       "         0.4944, 0.4851, 0.5883, 0.2975, 0.4963], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.sublayer.0.norm.b_2': tensor([-0.0524,  0.3262, -0.1062,  0.1158, -0.2056, -0.0135, -0.2671,  0.0293,\n",
       "          0.0365, -0.1127, -0.0143,  0.1029,  0.1657,  0.1852, -0.0185,  0.1364,\n",
       "          0.0160,  0.0524, -0.0690, -0.0990, -0.1396,  0.1751,  0.0629,  0.0654,\n",
       "         -0.0859, -0.1301, -0.2830,  0.1926,  0.0963, -0.1247, -0.1336,  0.1700,\n",
       "          0.4325,  0.1657, -0.0087, -0.0971,  0.0201,  0.1171, -0.0842, -0.1249,\n",
       "         -0.0014,  0.2017, -0.0475,  0.0220, -0.1076,  0.0720,  0.0382,  0.1565,\n",
       "         -0.2809, -0.1989], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.sublayer.1.norm.a_2': tensor([1.0718, 1.0729, 1.2806, 1.0912, 0.9630, 1.0300, 0.8413, 0.8990, 0.9248,\n",
       "         1.1149, 0.7264, 1.2411, 0.7969, 0.7508, 1.0554, 1.2042, 0.8193, 1.0177,\n",
       "         1.0564, 0.4548, 0.9421, 0.8461, 0.9510, 0.5569, 0.8302, 1.0649, 0.9844,\n",
       "         1.1727, 1.2644, 1.0676, 0.7274, 1.1229, 0.9550, 1.1641, 0.9499, 0.6366,\n",
       "         0.8561, 1.2252, 1.1645, 0.8010, 0.8932, 0.9766, 0.8575, 0.9027, 0.8946,\n",
       "         1.2059, 0.6473, 1.1296, 0.5754, 0.9583], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.7.sublayer.1.norm.b_2': tensor([ 9.5401e-02,  8.1871e-02,  1.0097e-01,  1.3083e-01,  4.5671e-02,\n",
       "          4.6745e-02, -1.5129e-01,  1.2520e-02, -8.2530e-05,  3.4154e-02,\n",
       "          7.3606e-02,  7.8475e-02, -2.6090e-03,  1.8752e-01, -1.1495e-01,\n",
       "          4.2131e-02,  7.1963e-02,  1.1992e-01, -2.3245e-02,  3.5225e-02,\n",
       "         -7.2078e-02,  1.2587e-01,  4.8081e-02, -5.2414e-02,  8.7033e-02,\n",
       "          1.8125e-02, -1.0234e-01,  9.1837e-02, -4.2457e-02,  3.9631e-02,\n",
       "          4.1875e-02, -1.4654e-01,  3.0867e-01,  4.8300e-02,  2.6568e-02,\n",
       "         -6.7833e-02,  4.3884e-02, -9.0634e-02, -2.5412e-01, -2.2942e-01,\n",
       "          1.0116e-01,  8.4555e-02, -7.6137e-03,  4.3059e-04,  3.4616e-02,\n",
       "         -1.0814e-01,  6.5337e-02,  9.9693e-02, -2.2350e-01,  1.1971e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.self_attn.linears.0.weight': tensor([[-0.1052, -0.1422, -0.0253,  ..., -0.1922, -0.1948,  0.1367],\n",
       "         [ 0.1286,  0.3639, -0.1294,  ..., -0.1934, -0.1809,  0.0461],\n",
       "         [-0.1409,  0.0010, -0.1133,  ..., -0.0700, -0.0061,  0.2048],\n",
       "         ...,\n",
       "         [-0.2043, -0.2800,  0.0458,  ..., -0.0535,  0.5261,  0.2381],\n",
       "         [ 0.3585,  0.1710, -0.0657,  ...,  0.1666, -0.3705, -0.1846],\n",
       "         [ 0.0862,  0.0243,  0.0310,  ..., -0.0018, -0.2343, -0.0576]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.self_attn.linears.0.bias': tensor([-0.2447, -0.6136, -0.0467, -0.4425, -0.3156,  0.2084, -0.0537, -0.4288,\n",
       "          0.1231,  0.2942, -0.3337,  0.2490,  0.3369,  0.0122, -0.0682, -0.2645,\n",
       "         -0.0145, -0.1326, -0.3162,  0.3016,  0.2239, -0.2226,  0.0819, -0.5548,\n",
       "         -0.1137, -0.3320,  0.9062,  0.4424,  0.2052,  0.7857, -0.2812,  0.5280,\n",
       "         -0.5629,  0.4185, -0.4307,  0.7357, -0.4177, -0.3308, -0.0479, -0.1113,\n",
       "          0.6765, -0.5543, -0.1326,  0.5686,  0.4948, -0.0339,  0.2711,  0.6106,\n",
       "         -0.3080,  0.0380], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.self_attn.linears.1.weight': tensor([[-0.0986, -0.0526,  0.0912,  ..., -0.2420, -0.2732,  0.0048],\n",
       "         [-0.1215,  0.1300,  0.1382,  ..., -0.0255,  0.1031, -0.2917],\n",
       "         [-0.1009, -0.0389,  0.0693,  ..., -0.0118, -0.0748,  0.0783],\n",
       "         ...,\n",
       "         [-0.2525,  0.0657, -0.0572,  ..., -0.0488,  0.3072, -0.0566],\n",
       "         [ 0.2618, -0.0047,  0.0092,  ..., -0.0375, -0.1687,  0.1428],\n",
       "         [-0.2756,  0.0042, -0.0838,  ...,  0.0403, -0.0379,  0.0301]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.self_attn.linears.1.bias': tensor([-0.0789, -0.1411, -0.0460, -0.0866,  0.0874, -0.0903,  0.0955, -0.1204,\n",
       "         -0.0193, -0.1312,  0.1102, -0.1048,  0.0410, -0.1079,  0.0975, -0.0970,\n",
       "          0.1302,  0.0401, -0.0026,  0.1350,  0.0527, -0.0560,  0.1290, -0.1341,\n",
       "          0.1307,  0.1356,  0.1026, -0.0706, -0.0911,  0.0842,  0.0821,  0.1341,\n",
       "         -0.1218, -0.0806, -0.1367,  0.1334,  0.0300,  0.1203, -0.0412, -0.1075,\n",
       "          0.1184,  0.0117, -0.0881,  0.0003,  0.1279, -0.0429, -0.0396,  0.0975,\n",
       "         -0.0364,  0.0842], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.self_attn.linears.2.weight': tensor([[-0.0398, -0.1774,  0.0140,  ..., -0.0208, -0.0640,  0.0493],\n",
       "         [-0.0069,  0.0635,  0.1019,  ..., -0.0142,  0.1615,  0.0314],\n",
       "         [-0.0268, -0.0540,  0.0289,  ..., -0.0345, -0.0795,  0.0450],\n",
       "         ...,\n",
       "         [ 0.1232,  0.1051,  0.0119,  ...,  0.0326, -0.0722,  0.0960],\n",
       "         [ 0.0950, -0.1333,  0.0937,  ...,  0.0081,  0.1019, -0.0752],\n",
       "         [-0.0330,  0.1000,  0.0349,  ..., -0.1471, -0.0165, -0.0573]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.self_attn.linears.2.bias': tensor([-5.6298e-02, -6.4720e-02, -1.3025e-01, -7.3233e-02,  7.4765e-02,\n",
       "         -1.0027e-01,  1.0830e-01, -1.0716e-01,  9.2209e-03, -4.0298e-02,\n",
       "          1.0320e-01, -1.3790e-01,  2.6515e-02, -9.0755e-02,  1.6235e-02,\n",
       "         -1.8282e-01,  1.5150e-01,  1.6322e-02, -3.7522e-02,  5.4044e-02,\n",
       "          7.5660e-02, -4.0039e-02,  1.5144e-01, -1.4751e-01,  1.4507e-01,\n",
       "          8.4557e-02,  1.8374e-01, -6.1983e-03,  3.1371e-03, -1.5192e-04,\n",
       "          1.0829e-01,  1.6888e-01, -1.1951e-01, -2.6208e-02, -3.5571e-02,\n",
       "          1.0411e-01,  5.1942e-02,  5.8112e-02, -3.1229e-02, -8.6183e-02,\n",
       "          1.8628e-02, -2.1899e-02, -2.8423e-02,  5.6610e-02,  1.1639e-01,\n",
       "         -2.4047e-04, -3.4300e-02,  7.6006e-02, -3.9307e-02,  4.6334e-02],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.self_attn.linears.3.weight': tensor([[ 0.0573, -0.1304,  0.1869,  ..., -0.0981, -0.0409, -0.0528],\n",
       "         [ 0.0098, -0.0205,  0.1978,  ..., -0.0613,  0.0916,  0.0110],\n",
       "         [-0.0058, -0.0243, -0.0751,  ..., -0.0457, -0.0474, -0.0134],\n",
       "         ...,\n",
       "         [ 0.0039,  0.0902,  0.0523,  ..., -0.0083, -0.0718,  0.0559],\n",
       "         [ 0.0358, -0.1904,  0.1220,  ..., -0.0706,  0.1548,  0.0381],\n",
       "         [-0.1131,  0.1369, -0.1047,  ..., -0.1154, -0.0847, -0.0503]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.self_attn.linears.3.bias': tensor([-0.2017, -0.2183, -0.0563, -0.1000,  0.1726, -0.2537,  0.5698, -0.2277,\n",
       "          0.0234, -0.0264, -0.1479,  0.2914, -0.1899, -0.1347,  0.2233, -0.1542,\n",
       "         -0.0353,  0.0821,  0.0917,  0.0417,  0.1079, -0.2112,  0.1117, -0.1601,\n",
       "          0.1317,  0.1080,  0.2964, -0.3476, -0.1484,  0.1955,  0.1028, -0.2060,\n",
       "         -0.7883,  0.1907, -0.1244,  0.1226, -0.0092, -0.0418, -0.0665,  0.1109,\n",
       "          0.1023,  0.0061, -0.0712, -0.1731,  0.3516,  0.0146,  0.0311, -0.0804,\n",
       "          0.5793,  0.1208], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.feed_forward.bn.weight': tensor([0.8658, 1.0800, 1.1037, 1.2838, 1.1709, 0.8833, 0.9647, 0.6533, 0.6809,\n",
       "         0.9342, 0.8785, 1.0844, 0.8058, 0.6168, 1.0242, 1.1296, 0.9230, 1.0755,\n",
       "         0.7661, 0.9933, 0.9878, 0.8940, 0.7199, 0.7851, 1.2945, 1.0725, 1.0586,\n",
       "         0.7761, 1.0417, 0.7773, 1.0153, 0.5749, 0.4746, 1.3298, 0.9455, 0.8679,\n",
       "         0.5536, 0.8431, 1.1868, 1.0155, 0.7617, 1.1017, 0.7424, 0.6670, 1.1878,\n",
       "         1.2211, 0.7424, 0.8477, 1.5971, 1.0485], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.feed_forward.bn.bias': tensor([-0.3986, -0.1283, -0.2191,  0.1293, -0.0232, -0.2555,  0.0108, -0.2701,\n",
       "         -0.1560, -0.1434, -0.0913,  0.0617, -0.1487, -0.3102,  0.0025, -0.0286,\n",
       "         -0.0263,  0.0284, -0.1835, -0.1051, -0.0017, -0.1899, -0.2542, -0.2344,\n",
       "         -0.0680, -0.0559, -0.0412, -0.2402, -0.2179, -0.2670, -0.0764, -0.4725,\n",
       "         -0.5767,  0.1459, -0.1153, -0.2039, -0.3730, -0.2241,  0.0415, -0.0652,\n",
       "         -0.3026, -0.0091, -0.2497, -0.2422,  0.0765, -0.0362, -0.2452, -0.2113,\n",
       "          0.6528, -0.0834], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.feed_forward.bn.running_mean': tensor([-0.0389, -0.0498, -0.0322,  0.0033,  0.0433,  0.0461,  0.0851, -0.0520,\n",
       "          0.0208,  0.0706,  0.1396,  0.0521,  0.0407, -0.0952,  0.0682,  0.0687,\n",
       "          0.0364,  0.0572,  0.1805,  0.0585, -0.0207, -0.0487,  0.1604,  0.2049,\n",
       "         -0.0248,  0.0004, -0.1152,  0.0930,  0.0613,  0.1304,  0.0322, -0.1950,\n",
       "         -0.0297,  0.1245,  0.1777,  0.0865, -0.0102,  0.0325,  0.0621,  0.0486,\n",
       "          0.1409, -0.1885,  0.1711,  0.0107, -0.1684, -0.0632,  0.0949,  0.0820,\n",
       "         -0.0394, -0.0203], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.feed_forward.bn.running_var': tensor([0.1161, 0.1071, 0.0606, 0.0475, 0.0921, 0.1587, 0.1983, 0.1717, 0.0875,\n",
       "         0.1787, 0.0425, 0.1102, 0.1479, 0.1474, 0.0358, 0.0703, 0.1091, 0.0317,\n",
       "         0.2664, 0.1610, 0.0651, 0.0377, 0.1300, 0.1046, 0.1085, 0.0704, 0.1378,\n",
       "         0.0778, 0.0347, 0.1362, 0.1017, 0.0957, 0.0182, 0.0491, 0.1089, 0.0481,\n",
       "         0.0878, 0.0268, 0.0530, 0.0497, 0.1745, 0.0989, 0.0790, 0.0520, 0.0972,\n",
       "         0.0917, 0.2016, 0.0934, 0.0828, 0.0626], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.feed_forward.bn.num_batches_tracked': tensor(213030),\n",
       " 'transformer_pre.model.layers.8.feed_forward.encoder_0.weight_ih_l0': tensor([[-0.0695,  0.0604, -0.0055,  ...,  0.0803, -0.2045,  0.1306],\n",
       "         [-0.4806, -0.0743, -0.3123,  ...,  0.1574,  0.0254,  0.1692],\n",
       "         [-0.1653,  0.1205, -0.3701,  ...,  0.0062,  0.0361, -0.0583],\n",
       "         ...,\n",
       "         [ 0.1197,  0.1456,  0.1535,  ...,  0.0413, -0.1317, -0.2608],\n",
       "         [-0.0439,  0.0712, -0.2357,  ...,  0.1471,  0.0259, -0.2177],\n",
       "         [ 0.0137,  0.1396,  0.0697,  ..., -0.1844,  0.1015, -0.0486]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.feed_forward.encoder_0.weight_hh_l0': tensor([[ 0.0946, -0.1209,  0.0956,  ...,  0.1199, -0.2737,  0.1412],\n",
       "         [-0.1943,  0.1384,  0.1182,  ...,  0.0369,  0.0429, -0.0641],\n",
       "         [ 0.2711, -0.3522,  0.0223,  ...,  0.3169,  0.1956,  0.1187],\n",
       "         ...,\n",
       "         [-0.1599,  0.1819,  0.0670,  ..., -0.2359,  0.1803, -0.2997],\n",
       "         [ 0.0926,  0.0384,  0.0870,  ...,  0.2397,  0.0236, -0.2195],\n",
       "         [ 0.2081,  0.0558,  0.0984,  ...,  0.1743,  0.0411, -0.1307]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.feed_forward.encoder_0.bias_ih_l0': tensor([-0.2111,  0.2158, -0.0540, -0.1449,  0.0840, -0.3232, -0.0373,  0.1576,\n",
       "          0.0366, -0.0577, -0.0206,  0.0028,  0.1040, -0.0831,  0.0349, -0.2475,\n",
       "          0.0692, -0.1892, -0.0047, -0.0104, -0.1747, -0.2600, -0.1886, -0.1652,\n",
       "         -0.2160, -0.3874, -0.0846, -0.2566,  0.1366, -0.0006,  0.0502, -0.1812,\n",
       "         -0.2716, -0.0872, -0.1479, -0.0966, -0.0986, -0.0401,  0.0910, -0.0435,\n",
       "         -0.0162, -0.1724, -0.2044, -0.2069,  0.0432,  0.0458, -0.0777, -0.2391,\n",
       "         -0.3539, -0.2184, -0.0987,  0.1176, -0.0454,  0.0232, -0.2395, -0.1723,\n",
       "         -0.0361,  0.0151,  0.2782, -0.2377, -0.1493, -0.1717,  0.2545, -0.0212,\n",
       "         -0.1023, -0.1447, -0.0050, -0.0818, -0.2234, -0.1672, -0.3472, -0.1337,\n",
       "          0.1636,  0.0104, -0.1762, -0.1642,  0.0681, -0.2486,  0.1032,  0.0099,\n",
       "         -0.2127, -0.3140,  0.0461,  0.0712, -0.0160, -0.0821,  0.0192, -0.0121,\n",
       "          0.2632, -0.1849, -0.1067, -0.1472, -0.0238, -0.1263, -0.1556, -0.3710,\n",
       "          0.0485, -0.1878, -0.4782, -0.1795,  0.0360,  0.1644,  0.0730,  0.0476,\n",
       "         -0.0166, -0.0548,  0.2235,  0.0734,  0.0978,  0.0488,  0.2191,  0.1552,\n",
       "          0.1763, -0.1685,  0.2325,  0.0462,  0.1068,  0.0642, -0.0830,  0.0016,\n",
       "          0.0054,  0.0256, -0.0878, -0.0855,  0.0190,  0.0575, -0.1752,  0.0814,\n",
       "         -0.0817, -0.2334, -0.0644,  0.0387, -0.2108,  0.3497,  0.0605, -0.0785,\n",
       "          0.2096,  0.0793, -0.0503, -0.0365, -0.0454, -0.2014,  0.0294, -0.0434,\n",
       "          0.0340, -0.0267,  0.1086,  0.1645,  0.1501,  0.0449, -0.4409,  0.0820,\n",
       "         -0.0337, -0.0754, -0.0731, -0.2171,  0.0577,  0.2480, -0.0442, -0.2374,\n",
       "         -0.1989,  0.1479,  0.0658, -0.1047,  0.1611, -0.0805,  0.1252, -0.2174,\n",
       "          0.1563,  0.1451, -0.1351, -0.1239, -0.0031, -0.0214, -0.3656, -0.0381,\n",
       "          0.1385, -0.1258, -0.1282, -0.1642, -0.0272, -0.1644, -0.2819, -0.2200,\n",
       "         -0.3783, -0.1481, -0.0680, -0.1003,  0.1464, -0.2391,  0.0080, -0.1789,\n",
       "         -0.1460,  0.2003, -0.0905, -0.0815, -0.0599,  0.0192, -0.5251, -0.1599],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.feed_forward.encoder_0.bias_hh_l0': tensor([-0.0556,  0.2290,  0.0706, -0.2494, -0.0604, -0.2003, -0.0407,  0.0370,\n",
       "          0.0801, -0.1354, -0.1324, -0.0770,  0.1708, -0.2619,  0.0498, -0.0317,\n",
       "          0.0583, -0.1451, -0.0515,  0.1141, -0.1601, -0.2786, -0.0315, -0.2024,\n",
       "         -0.3202, -0.4745,  0.1458, -0.2236, -0.0796,  0.0759,  0.0307, -0.2088,\n",
       "         -0.1464,  0.0570, -0.0224,  0.0910, -0.0690, -0.1107, -0.0738, -0.1288,\n",
       "         -0.0744, -0.3301, -0.2450, -0.1294,  0.1720,  0.1375,  0.0266, -0.0234,\n",
       "         -0.4487, -0.1692, -0.2233,  0.1661, -0.0244, -0.1414, -0.1602, -0.0306,\n",
       "         -0.0896,  0.2039,  0.1284, -0.1761, -0.1062, -0.0071,  0.2167, -0.0838,\n",
       "         -0.1788, -0.2806, -0.1093, -0.0776, -0.2234, -0.0531, -0.2538, -0.2391,\n",
       "         -0.0160, -0.2050, -0.2218, -0.3190, -0.0899, -0.0524, -0.0622, -0.0221,\n",
       "         -0.1296, -0.1271, -0.2107, -0.0859, -0.1751, -0.1544, -0.1889,  0.1086,\n",
       "          0.1060, -0.2826, -0.0983, -0.1145, -0.0625,  0.0285, -0.0979, -0.1684,\n",
       "          0.0410, -0.2370, -0.5823, -0.2512, -0.2269,  0.2123, -0.0485,  0.0186,\n",
       "         -0.0775, -0.0270,  0.2848,  0.0999, -0.0843, -0.0868,  0.2075,  0.1934,\n",
       "          0.1962, -0.0010,  0.2245, -0.1139,  0.2057,  0.1187,  0.1839,  0.0169,\n",
       "         -0.1982,  0.0335,  0.0333,  0.0315, -0.1668, -0.1005, -0.0591,  0.0618,\n",
       "         -0.1027, -0.0364, -0.0258, -0.0535, -0.1232,  0.0825,  0.0601,  0.0062,\n",
       "          0.2006,  0.0758, -0.0485, -0.0929, -0.0177, -0.0724, -0.0245, -0.1329,\n",
       "          0.0829,  0.0705, -0.1500,  0.0309,  0.0278,  0.0635, -0.4290, -0.0319,\n",
       "          0.0368,  0.0092, -0.1769, -0.3703,  0.0485,  0.1199,  0.1379, -0.0793,\n",
       "         -0.1472, -0.0420, -0.0378, -0.1837,  0.2539, -0.1682,  0.0955, -0.3089,\n",
       "         -0.0530,  0.0186, -0.2596, -0.1119, -0.1928, -0.2175, -0.4457, -0.1174,\n",
       "          0.1833, -0.2912, -0.0696,  0.0857, -0.0795, -0.1683, -0.3141, -0.4302,\n",
       "         -0.3690,  0.0098,  0.0086, -0.1236,  0.0928, -0.0376,  0.1312, -0.2771,\n",
       "         -0.2174,  0.0418, -0.0653, -0.1998,  0.0535, -0.0151, -0.3926, -0.1515],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.feed_forward.encoder_1.weight_ih_l0': tensor([[-1.2207e-01,  4.6189e-02, -3.6509e-01,  ..., -2.4928e-01,\n",
       "           6.0985e-02, -1.6619e-02],\n",
       "         [ 1.5798e-04,  2.2444e-01, -1.0616e-01,  ..., -2.3906e-01,\n",
       "          -1.9407e-01,  8.7723e-02],\n",
       "         [ 3.1840e-01, -1.4986e-01,  8.4937e-02,  ...,  7.7213e-03,\n",
       "          -2.4469e-01, -1.1013e-01],\n",
       "         ...,\n",
       "         [ 2.6026e-02,  1.0114e-01,  1.1376e-01,  ..., -6.4085e-02,\n",
       "          -3.0236e-01, -3.8386e-01],\n",
       "         [-1.2787e-01, -8.9071e-02, -8.2326e-02,  ...,  1.3763e-01,\n",
       "           2.6137e-01, -4.9784e-01],\n",
       "         [-1.9080e-01,  8.1874e-02, -2.5085e-01,  ..., -2.0416e-01,\n",
       "          -3.1830e-02,  5.7892e-02]], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.feed_forward.encoder_1.weight_hh_l0': tensor([[-0.0720,  0.0672, -0.1485,  ..., -0.1978, -0.1504, -0.1184],\n",
       "         [-0.1147, -0.0110, -0.2213,  ..., -0.0971, -0.2566,  0.1861],\n",
       "         [ 0.1009, -0.0244, -0.2132,  ...,  0.1226,  0.4056, -0.0768],\n",
       "         ...,\n",
       "         [ 0.1178,  0.1784, -0.0887,  ...,  0.0350,  0.1728, -0.1001],\n",
       "         [ 0.1818, -0.0254, -0.1204,  ...,  0.1461,  0.0469,  0.1772],\n",
       "         [-0.2759,  0.3314, -0.1491,  ..., -0.2314,  0.1509,  0.2635]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.feed_forward.encoder_1.bias_ih_l0': tensor([ 0.0236, -0.0071, -0.1641,  0.1761, -0.0163,  0.0484,  0.0227, -0.1436,\n",
       "         -0.2656, -0.0978,  0.0992, -0.0493, -0.2289,  0.0640, -0.3077, -0.1481,\n",
       "         -0.1694,  0.0126,  0.2061, -0.0567, -0.0606,  0.0007,  0.1092, -0.1422,\n",
       "         -0.0870, -0.1485,  0.0220, -0.1184, -0.4620,  0.0749,  0.2249, -0.2050,\n",
       "          0.0674, -0.2664, -0.0121,  0.0780, -0.1406, -0.0852, -0.1189,  0.0869,\n",
       "          0.2215,  0.0064, -0.5744,  0.2856, -0.1323,  0.1231,  0.2733, -0.3148,\n",
       "         -0.0803, -0.2979, -0.0369, -0.1017, -0.2329,  0.0525, -0.2022,  0.0908,\n",
       "          0.0664, -0.0896,  0.0996, -0.0600, -0.0059, -0.0309, -0.2262,  0.0696,\n",
       "          0.0085, -0.1355, -0.0206, -0.2412,  0.2281, -0.4044, -0.1607, -0.2156,\n",
       "          0.2121, -0.1275,  0.1838, -0.1899,  0.0508,  0.0999, -0.4045, -0.0469,\n",
       "          0.0915, -0.0900, -0.0687, -0.2545,  0.0867, -0.0994, -0.0375, -0.1073,\n",
       "         -0.1648, -0.2626,  0.1405, -0.1894, -0.2618, -0.2392, -0.0350,  0.1759,\n",
       "          0.1609, -0.0754, -0.2888, -0.0805, -0.1419, -0.2337, -0.1001,  0.0393,\n",
       "          0.0820, -0.0071, -0.2474, -0.2210, -0.0133,  0.1750,  0.0606, -0.1982,\n",
       "         -0.2524,  0.0361,  0.1732,  0.0955, -0.1314,  0.0816,  0.0935, -0.1788,\n",
       "         -0.1345, -0.0248,  0.0866,  0.0491,  0.0076,  0.0397,  0.1305, -0.0861,\n",
       "         -0.1179, -0.0156, -0.1226, -0.1417, -0.2948, -0.0465,  0.1539,  0.0882,\n",
       "         -0.1654, -0.0483, -0.0126,  0.0466,  0.0630, -0.3836, -0.2081, -0.0492,\n",
       "         -0.1038, -0.0599,  0.2093,  0.1253,  0.1546, -0.2443, -0.0367, -0.2630,\n",
       "         -0.2488,  0.0886, -0.0785,  0.0511, -0.0115, -0.0906, -0.1219, -0.0058,\n",
       "          0.0202,  0.0769, -0.1468,  0.1959, -0.2841,  0.1223, -0.1581, -0.1579,\n",
       "          0.0927, -0.1100, -0.1266,  0.1195,  0.0645,  0.2657, -0.2041, -0.0261,\n",
       "         -0.1009, -0.2639, -0.2600,  0.1429, -0.1673, -0.2922, -0.2163, -0.1783,\n",
       "         -0.0367, -0.2906,  0.0032, -0.3295, -0.3237,  0.1080,  0.3610,  0.0325,\n",
       "         -0.3019,  0.0471, -0.3666, -0.0386,  0.2765, -0.2617, -0.2820, -0.1922],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.feed_forward.encoder_1.bias_hh_l0': tensor([-0.2109, -0.1930, -0.2671,  0.0049,  0.0375,  0.0659,  0.0514, -0.2215,\n",
       "         -0.1528,  0.0162, -0.1222, -0.1127, -0.2146,  0.1313, -0.2141, -0.1212,\n",
       "         -0.2163, -0.2043,  0.2826,  0.0124, -0.2376, -0.1349,  0.1100, -0.1295,\n",
       "         -0.1763, -0.0348, -0.1005, -0.0546, -0.3036,  0.1420,  0.2890, -0.4118,\n",
       "         -0.0475, -0.0697, -0.0300,  0.0398, -0.0916, -0.1739,  0.0177,  0.0258,\n",
       "          0.0579, -0.0157, -0.3563,  0.1592, -0.0286,  0.2145,  0.3477, -0.3289,\n",
       "         -0.2423, -0.2676, -0.0091,  0.0105, -0.2513, -0.1183, -0.1807,  0.1448,\n",
       "          0.0406,  0.0322, -0.0602, -0.2632, -0.0215,  0.0520, -0.1353,  0.0102,\n",
       "          0.0625, -0.0900, -0.1219, -0.1763,  0.1540, -0.2785, -0.2974, -0.1163,\n",
       "          0.0981, -0.1882,  0.1029, -0.1038, -0.1009,  0.1136, -0.3977,  0.0542,\n",
       "         -0.0242, -0.2536,  0.0855, -0.4006,  0.1617, -0.1673, -0.1101, -0.1675,\n",
       "         -0.2764, -0.2476,  0.0770, -0.1794, -0.3199, -0.0904, -0.1340,  0.2706,\n",
       "          0.1657, -0.1816, -0.2382,  0.0303,  0.0955, -0.1206,  0.0651, -0.0282,\n",
       "          0.0838,  0.1248, -0.0692, -0.3582, -0.0707,  0.1940,  0.1432, -0.1496,\n",
       "         -0.2734,  0.1628,  0.1668,  0.0088, -0.1213,  0.1235,  0.1448,  0.0126,\n",
       "         -0.0879, -0.1954,  0.2316,  0.1015, -0.0742,  0.1189,  0.1532, -0.1220,\n",
       "         -0.1887, -0.0733, -0.1871, -0.1851, -0.1068, -0.0681,  0.2140,  0.0643,\n",
       "         -0.0226,  0.1241, -0.1061, -0.0290,  0.0092, -0.4091, -0.0261, -0.0200,\n",
       "         -0.2427, -0.0915,  0.2951,  0.1583,  0.1364, -0.0819,  0.0970, -0.3587,\n",
       "         -0.1743,  0.2543, -0.2928,  0.1455, -0.0789, -0.0159, -0.2019, -0.0771,\n",
       "         -0.1640,  0.0905, -0.0896,  0.2408, -0.3557,  0.1887, -0.1017, -0.3951,\n",
       "          0.0174, -0.1016, -0.0959,  0.0692,  0.2500,  0.1155, -0.1331, -0.0375,\n",
       "         -0.1543, -0.0830, -0.2797, -0.0448, -0.0594, -0.2951, -0.3274, -0.2345,\n",
       "         -0.0186, -0.2989, -0.1266, -0.3519, -0.1652,  0.1619,  0.3341,  0.1507,\n",
       "         -0.2843, -0.0582, -0.1455, -0.1436,  0.1994, -0.2529, -0.1216, -0.0633],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.feed_forward.encoder_2.weight_ih_l0': tensor([[ 0.3948, -0.2200,  0.0183,  ..., -0.3105, -0.0946, -0.0854],\n",
       "         [ 0.1786,  0.4059,  0.3096,  ...,  0.1101,  0.2884, -0.1695],\n",
       "         [ 0.1562,  0.3591, -0.0608,  ..., -0.0384, -0.0017,  0.1814],\n",
       "         ...,\n",
       "         [-0.0226, -0.1232, -0.1623,  ...,  0.1504,  0.0703, -0.1263],\n",
       "         [-0.1684, -0.2156,  0.0425,  ...,  0.0871,  0.0710, -0.1342],\n",
       "         [ 0.1653,  0.2391, -0.0985,  ..., -0.0508, -0.3322, -0.1138]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.feed_forward.encoder_2.weight_hh_l0': tensor([[ 0.0400, -0.0062,  0.0875,  ..., -0.2463,  0.0625,  0.1575],\n",
       "         [ 0.0209,  0.0832, -0.3254,  ..., -0.4450, -0.1263,  0.1222],\n",
       "         [-0.2198,  0.1386,  0.0847,  ..., -0.4559,  0.0276,  0.2699],\n",
       "         ...,\n",
       "         [-0.2452, -0.0709, -0.0020,  ...,  0.1711,  0.0394,  0.1985],\n",
       "         [ 0.2464, -0.0748, -0.3312,  ..., -0.0300, -0.0562,  0.1310],\n",
       "         [ 0.1609,  0.1007, -0.3175,  ...,  0.0902, -0.0238,  0.2623]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.feed_forward.encoder_2.bias_ih_l0': tensor([ 0.1143, -0.1847, -0.1782, -0.1372, -0.0017, -0.3027, -0.0499,  0.2930,\n",
       "         -0.3705,  0.3058, -0.0814, -0.1619, -0.0880, -0.3174, -0.1783, -0.1426,\n",
       "         -0.2560,  0.0024,  0.0354, -0.1929, -0.1697,  0.1143,  0.0189,  0.2939,\n",
       "         -0.0133, -0.0060, -0.0331,  0.0065, -0.2550, -0.2961, -0.0962,  0.0390,\n",
       "         -0.2144,  0.1273,  0.0763, -0.3179, -0.3392, -0.1752, -0.2265, -0.1105,\n",
       "         -0.1361, -0.1962,  0.0045, -0.4113,  0.2733,  0.0220,  0.0371,  0.1497,\n",
       "          0.1204, -0.0512,  0.0546,  0.2258,  0.0334, -0.3352, -0.0049, -0.0544,\n",
       "         -0.1050,  0.1799, -0.3776,  0.1678, -0.0504,  0.0359, -0.1646, -0.0139,\n",
       "         -0.4727, -0.0908, -0.0896,  0.0052, -0.1831, -0.0800, -0.0563, -0.0520,\n",
       "          0.0785,  0.2672,  0.0029,  0.2807,  0.0462,  0.1112, -0.1771, -0.4516,\n",
       "         -0.1646,  0.0160, -0.1753, -0.1549, -0.1743, -0.1313, -0.3415,  0.0198,\n",
       "         -0.0382, -0.1120, -0.0425,  0.0246, -0.2051, -0.2291,  0.0322, -0.2683,\n",
       "          0.1161, -0.0405,  0.1206, -0.2017,  0.1605, -0.1719, -0.0047, -0.0813,\n",
       "         -0.0155,  0.2959, -0.1324, -0.0739,  0.0249, -0.2195,  0.1647,  0.0524,\n",
       "         -0.1472, -0.1323, -0.1600, -0.1292, -0.0673,  0.0049,  0.0528, -0.0297,\n",
       "         -0.2517, -0.0953, -0.1344,  0.0740, -0.0876,  0.1416,  0.0479,  0.0427,\n",
       "          0.0630, -0.0496,  0.0705,  0.0025, -0.2205,  0.0333,  0.0700, -0.1704,\n",
       "         -0.1095, -0.0895,  0.0008, -0.1259, -0.0346, -0.0558,  0.0586,  0.1377,\n",
       "         -0.1144,  0.0430, -0.1134, -0.0763,  0.1348, -0.1247,  0.0914,  0.0618,\n",
       "         -0.0984, -0.5764, -0.0563, -0.4389, -0.0381, -0.0999, -0.0207, -0.0532,\n",
       "         -0.2955, -0.2155,  0.1749, -0.0992, -0.2431, -0.1453, -0.2101, -0.1068,\n",
       "          0.2197, -0.1708, -0.0982,  0.0443, -0.0299,  0.2438, -0.0276, -0.0021,\n",
       "         -0.0566,  0.2113, -0.2254, -0.1680, -0.0795, -0.1790, -0.2614, -0.2053,\n",
       "          0.0307, -0.3285, -0.2139, -0.0979, -0.1141, -0.3074, -0.3126, -0.0725,\n",
       "          0.0011, -0.1241, -0.0218,  0.0762,  0.0216, -0.0172, -0.0274, -0.0269],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.feed_forward.encoder_2.bias_hh_l0': tensor([ 2.6284e-04,  5.0822e-02, -1.9609e-01, -1.1292e-01,  3.4142e-02,\n",
       "         -3.2743e-01,  5.3579e-02,  9.7442e-02, -3.3967e-01,  1.1527e-01,\n",
       "         -1.5872e-01, -2.8221e-01, -6.8055e-02, -2.7428e-01, -2.3962e-01,\n",
       "         -5.8351e-02, -2.7173e-01, -6.3523e-02, -1.1901e-01, -1.3423e-01,\n",
       "         -1.6519e-01,  7.8493e-02, -9.7054e-02,  2.3289e-01,  9.6205e-02,\n",
       "         -9.4892e-02,  3.0448e-02, -7.6994e-02, -1.8195e-01, -1.0107e-01,\n",
       "         -1.6077e-01, -7.0296e-02, -2.0688e-01, -1.3201e-01,  2.5545e-02,\n",
       "         -3.0006e-01, -3.6942e-01, -3.6009e-01, -2.2907e-01, -5.3682e-02,\n",
       "         -2.3025e-02, -2.2019e-01, -5.5282e-02, -2.2445e-01,  4.9995e-02,\n",
       "          1.1067e-02,  1.9962e-01,  1.1143e-01,  3.2747e-02, -1.9205e-01,\n",
       "         -1.6507e-01,  4.1069e-04, -1.7914e-01, -1.9602e-01, -7.2418e-02,\n",
       "         -1.3889e-01, -1.3052e-01,  1.8717e-01, -3.8340e-01,  1.3324e-01,\n",
       "         -4.6952e-02,  5.7661e-02, -1.2586e-01, -2.2772e-01, -2.6157e-01,\n",
       "         -1.9612e-01, -9.9142e-02,  8.6551e-02, -6.1714e-02, -7.8608e-02,\n",
       "         -1.1919e-01, -2.7355e-01,  1.3672e-01,  1.3051e-01,  1.5060e-02,\n",
       "          1.7533e-01, -4.7300e-02, -6.4046e-02,  2.5484e-03, -3.1450e-01,\n",
       "         -8.7290e-02, -1.4816e-01, -7.9359e-02, -1.4481e-01, -4.4493e-02,\n",
       "         -2.4110e-01, -1.6716e-01, -5.2971e-02,  4.7774e-02, -2.8847e-01,\n",
       "         -1.9657e-01, -6.4624e-02, -3.2685e-02, -2.9427e-01, -1.1546e-01,\n",
       "         -1.9775e-01,  5.0834e-02,  1.2775e-02,  9.1936e-02, -1.6254e-01,\n",
       "          1.2946e-01, -1.6100e-01, -2.1541e-01,  6.4800e-03, -1.8920e-01,\n",
       "          2.9162e-02,  7.5526e-02,  1.0683e-01,  1.3052e-01,  4.5074e-02,\n",
       "          1.4514e-01,  7.0255e-02,  1.1220e-02, -2.1572e-01,  5.4410e-02,\n",
       "         -6.6055e-02,  8.4933e-02,  8.0896e-02, -9.8012e-02,  1.5197e-01,\n",
       "         -1.4762e-01, -2.8192e-02, -1.6718e-01,  3.0221e-01, -4.2889e-02,\n",
       "          2.9408e-01,  2.1510e-02,  1.1566e-01, -1.2539e-01, -1.1317e-01,\n",
       "          3.3462e-02, -1.6584e-01,  1.2254e-02,  8.4314e-02, -9.6255e-02,\n",
       "          3.0832e-02, -4.8843e-02, -2.1878e-02,  1.8528e-02, -4.5920e-02,\n",
       "         -4.8764e-02,  6.9045e-02,  2.2225e-01, -2.8153e-02, -1.1709e-01,\n",
       "          4.2528e-02, -1.1906e-01, -1.4818e-01, -3.4215e-02, -2.2034e-01,\n",
       "          1.5002e-01,  9.8365e-02, -1.4063e-01, -4.5598e-01, -8.1922e-02,\n",
       "         -3.1501e-01,  9.7140e-02,  4.9287e-02, -1.4690e-01, -8.2938e-03,\n",
       "         -3.8301e-01, -1.7400e-01,  1.7596e-01, -1.7878e-01, -2.7438e-01,\n",
       "         -1.4326e-02, -4.8976e-02,  2.6879e-02,  2.2069e-01, -1.7852e-01,\n",
       "         -2.3175e-01, -1.8830e-02, -1.1566e-02,  3.1863e-01,  7.0991e-02,\n",
       "          1.5172e-01, -1.0892e-01, -3.0938e-02, -1.2416e-01, -6.2231e-02,\n",
       "         -2.3257e-01, -2.6442e-01, -2.1255e-01, -1.8524e-01, -1.5283e-01,\n",
       "         -4.6196e-01, -1.6899e-01,  7.9222e-03, -5.4710e-02, -2.1818e-01,\n",
       "         -2.2168e-01, -1.9246e-01,  6.9858e-02,  7.1362e-02,  7.3799e-02,\n",
       "          5.0083e-03, -1.7634e-01,  1.3674e-02,  1.9464e-01, -2.6295e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.sublayer.0.norm.a_2': tensor([0.4301, 0.6514, 0.3139, 0.6191, 0.5139, 0.6667, 0.6446, 0.5381, 0.5251,\n",
       "         0.5631, 0.6039, 0.7201, 0.6501, 0.4138, 0.3534, 0.5057, 0.5093, 0.4630,\n",
       "         0.3526, 0.2604, 0.3021, 0.4294, 0.6567, 0.4349, 0.2137, 0.4350, 0.5086,\n",
       "         0.5811, 0.5922, 0.4288, 0.4043, 0.7912, 0.4153, 0.3069, 0.3707, 0.6610,\n",
       "         0.3524, 0.5201, 0.5878, 0.2025, 0.7067, 0.3210, 0.2545, 0.2373, 0.2992,\n",
       "         0.5030, 0.5473, 0.6184, 0.3813, 0.3704], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.sublayer.0.norm.b_2': tensor([-0.0118,  0.2754, -0.0953,  0.0841, -0.1931,  0.0108, -0.2905,  0.0426,\n",
       "          0.0607, -0.1387,  0.0751,  0.1038,  0.1465,  0.1904,  0.0028,  0.0941,\n",
       "          0.0204,  0.0495, -0.0590, -0.1315, -0.1265,  0.2138,  0.0716,  0.0587,\n",
       "         -0.0747, -0.1297, -0.2613,  0.2721,  0.1089, -0.0871, -0.1184,  0.2050,\n",
       "          0.4076,  0.0826, -0.0024, -0.0646,  0.0502,  0.1013, -0.0171, -0.1122,\n",
       "          0.0138,  0.1553, -0.0293,  0.0129, -0.1105,  0.0743,  0.0448,  0.1488,\n",
       "         -0.3047, -0.1629], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.sublayer.1.norm.a_2': tensor([1.1025, 0.7526, 1.1516, 0.9914, 0.9390, 0.9515, 0.8014, 0.7352, 1.0544,\n",
       "         0.9480, 0.7471, 1.3295, 0.7632, 0.8808, 0.9070, 1.1366, 0.9734, 1.0069,\n",
       "         0.8374, 0.8093, 0.9328, 0.6957, 1.0488, 0.6193, 1.0634, 0.9150, 0.9807,\n",
       "         1.2378, 1.1528, 0.8512, 0.7418, 1.0335, 0.9505, 0.9618, 1.0911, 0.6910,\n",
       "         0.9248, 1.2746, 1.0552, 1.0073, 0.9672, 1.1314, 0.8913, 1.1184, 0.8871,\n",
       "         1.0400, 0.8565, 0.9789, 0.7420, 0.9534], dtype=torch.float64),\n",
       " 'transformer_pre.model.layers.8.sublayer.1.norm.b_2': tensor([-0.0011,  0.2516, -0.0202, -0.0177, -0.0648,  0.0577, -0.2006,  0.1256,\n",
       "         -0.1125, -0.1283,  0.1144,  0.0972,  0.2686, -0.0171, -0.1371, -0.2093,\n",
       "          0.0872,  0.0912, -0.1790,  0.1848, -0.2839,  0.2357,  0.0174,  0.0491,\n",
       "         -0.0478, -0.1513, -0.1763,  0.0628, -0.0005, -0.0151,  0.1316, -0.0511,\n",
       "          0.3294,  0.1072,  0.0082, -0.1213,  0.1075, -0.1056, -0.2600, -0.2977,\n",
       "          0.1295,  0.1387,  0.1532,  0.0544,  0.1159, -0.0083, -0.1300,  0.1366,\n",
       "         -0.2477, -0.0887], dtype=torch.float64),\n",
       " 'transformer_pre.model.norm.a_2': tensor([0.9817, 0.9739, 0.9851, 0.9828, 1.0933, 1.0278, 1.2692, 1.1095, 1.1471,\n",
       "         1.0821, 1.0039, 1.1099, 1.2220, 1.2013, 1.1912, 1.1456, 1.1053, 0.9652,\n",
       "         1.1044, 0.9908, 1.0028, 1.0246, 1.1832, 1.0965, 1.1386, 1.2069, 0.9767,\n",
       "         0.9956, 1.3057, 1.0592, 1.1773, 1.1117, 1.4196, 1.1521, 1.2315, 1.1081,\n",
       "         1.2010, 1.1902, 1.1237, 1.1547, 1.0493, 1.4394, 1.2548, 1.0053, 1.0060,\n",
       "         0.9803, 1.1895, 1.1582, 1.7418, 1.0165], dtype=torch.float64),\n",
       " 'transformer_pre.model.norm.b_2': tensor([-0.2231,  0.0116, -0.1623,  0.1064, -0.1160, -0.0703,  0.2480, -0.0533,\n",
       "         -0.0627, -0.0342, -0.1139,  0.1815, -0.1216,  0.0029,  0.1071,  0.0091,\n",
       "         -0.0672,  0.1017, -0.0738,  0.0275, -0.0063,  0.0376,  0.0325,  0.0251,\n",
       "          0.0064,  0.0166,  0.0501, -0.0363, -0.0135,  0.0177, -0.0186, -0.2504,\n",
       "         -0.7507,  0.3183, -0.0671, -0.1293,  0.1061,  0.0303,  0.0434,  0.1600,\n",
       "         -0.0226, -0.0816,  0.0953, -0.1535,  0.0732,  0.1864,  0.0638, -0.0126,\n",
       "          0.7865, -0.0291], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.rotary_pos_emb.inv_freq': tensor([1.0000e+00, 5.6234e-01, 3.1623e-01, 1.7783e-01, 1.0000e-01, 5.6234e-02,\n",
       "         3.1623e-02, 1.7783e-02, 1.0000e-02, 5.6234e-03, 3.1623e-03, 1.7783e-03,\n",
       "         1.0000e-03, 5.6234e-04, 3.1623e-04, 1.7783e-04], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.input_self_attn.norm.g': tensor([ 0.2206,  0.1113,  0.0744,  0.1171,  0.1126,  0.0953,  0.0428,  0.0389,\n",
       "          0.0827,  0.1903,  0.0833,  0.0979,  0.0182,  0.0921,  0.0125,  0.0509,\n",
       "          0.1119,  0.0753,  0.1090,  0.0682,  0.1171,  0.0423,  0.1607,  0.0390,\n",
       "          0.0584,  0.0514,  0.0781,  0.0460,  0.0090,  0.0506,  0.0576,  0.0685,\n",
       "          0.0170,  0.0519,  0.0276,  0.0762,  0.1159,  0.0461,  0.0851,  0.0122,\n",
       "          0.0840,  0.0123,  0.0743,  0.0152,  0.0403,  0.0384,  0.1870,  0.0284,\n",
       "         -0.0141,  0.0523], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.input_self_attn.to_q.weight': tensor([[-0.1783, -0.0148, -0.1121,  ...,  0.1478, -0.1795, -0.1782],\n",
       "         [-0.1502,  0.0704,  0.0754,  ..., -0.0297,  0.1501, -0.2122],\n",
       "         [ 0.0709, -0.0223, -0.1441,  ..., -0.0174, -0.1789, -0.2338],\n",
       "         ...,\n",
       "         [-0.1860,  0.1003,  0.0280,  ..., -0.0956,  0.1074,  0.2269],\n",
       "         [-0.0889,  0.0730, -0.0755,  ..., -0.1636, -0.0526,  0.0893],\n",
       "         [ 0.0582, -0.1144,  0.0563,  ..., -0.1174, -0.0365,  0.0616]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.input_self_attn.to_kv.weight': tensor([[-0.1090, -0.0710,  0.1986,  ..., -0.0963,  0.2984,  0.2614],\n",
       "         [ 0.0682, -0.1023,  0.0216,  ..., -0.2644, -0.1656,  0.2066],\n",
       "         [ 0.1330,  0.1698,  0.1474,  ..., -0.0838,  0.1447,  0.3990],\n",
       "         ...,\n",
       "         [ 0.0028,  0.0297,  0.0146,  ...,  0.0186,  0.0145,  0.0619],\n",
       "         [-0.0644, -0.0210, -0.0453,  ...,  0.0151,  0.0570, -0.0747],\n",
       "         [ 0.0412,  0.0049,  0.0313,  ...,  0.0101, -0.0610,  0.0571]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.input_self_attn.to_out.weight': tensor([[-9.9161e-03,  1.2994e-02, -5.1284e-04,  ...,  2.7639e-02,\n",
       "           1.5203e-02,  2.1851e-02],\n",
       "         [ 4.8278e-03,  9.5415e-03,  1.8774e-05,  ..., -1.3490e-04,\n",
       "           2.0142e-04, -6.7653e-04],\n",
       "         [-1.0107e-02,  2.0610e-03, -1.4659e-02,  ..., -6.3043e-03,\n",
       "          -2.0159e-03, -1.1846e-02],\n",
       "         ...,\n",
       "         [-3.6256e-03,  2.1777e-03,  2.1481e-02,  ..., -8.5395e-03,\n",
       "          -1.5023e-02, -1.2759e-03],\n",
       "         [ 9.3228e-03,  3.1484e-03,  6.9421e-03,  ..., -5.1356e-05,\n",
       "           1.4465e-02, -5.4043e-03],\n",
       "         [-1.3723e-03,  2.4750e-03, -1.2923e-02,  ...,  1.6534e-02,\n",
       "           3.0322e-02,  1.3745e-02]], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.input_self_attn.to_out.bias': tensor([ 3.6475e-04, -5.9323e-03,  3.1904e-03,  3.3459e-03,  1.4766e-02,\n",
       "          3.6943e-03, -1.1950e-02,  7.8629e-04, -1.2182e-03, -8.5758e-03,\n",
       "         -1.4337e-04,  9.0775e-05,  1.5388e-02,  5.9336e-03, -4.0590e-03,\n",
       "         -1.1773e-02,  5.8967e-03, -6.2903e-03, -1.5426e-02, -1.1625e-03,\n",
       "          8.3949e-03, -1.0303e-02, -2.9652e-03, -2.1248e-02, -8.8823e-03,\n",
       "         -8.9273e-04,  1.3614e-03, -9.9418e-04,  6.3774e-03,  9.8393e-03,\n",
       "         -8.1589e-03, -4.7030e-04, -5.6498e-04,  2.6808e-03,  2.6636e-03,\n",
       "          5.0215e-03, -3.0297e-03, -2.3325e-03, -5.5887e-03, -6.9674e-03,\n",
       "          2.3270e-03, -1.4305e-02,  9.9827e-03,  5.6285e-04,  1.1665e-03,\n",
       "          1.0586e-03, -1.1882e-02,  4.0285e-03, -3.6174e-03, -6.7145e-03],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.state_self_attn.norm.g': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.state_self_attn.to_q.weight': tensor([[ 0.0509,  0.1051,  0.1339,  ..., -0.0057,  0.1401,  0.1123],\n",
       "         [-0.0997, -0.0710,  0.0539,  ...,  0.1172, -0.0910,  0.0137],\n",
       "         [ 0.0143,  0.0289,  0.0607,  ..., -0.0912,  0.1207, -0.0338],\n",
       "         ...,\n",
       "         [-0.1269, -0.0251,  0.0079,  ...,  0.0447, -0.0435,  0.0826],\n",
       "         [ 0.0194, -0.1375, -0.0310,  ..., -0.0759,  0.0080, -0.0620],\n",
       "         [ 0.1200,  0.1217,  0.0238,  ..., -0.0383,  0.0391, -0.0288]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.state_self_attn.to_kv.weight': tensor([[ 0.0159, -0.1189,  0.0352,  ...,  0.1066,  0.0038,  0.0432],\n",
       "         [ 0.0161,  0.0502, -0.1263,  ...,  0.0663,  0.0298,  0.1339],\n",
       "         [ 0.1116, -0.0466, -0.0785,  ..., -0.1009, -0.1156, -0.0061],\n",
       "         ...,\n",
       "         [ 0.1197,  0.0012,  0.0970,  ...,  0.1360,  0.1074,  0.0569],\n",
       "         [-0.1398, -0.1302,  0.0654,  ...,  0.0568,  0.0875, -0.1215],\n",
       "         [ 0.0388,  0.0879,  0.1348,  ...,  0.0440, -0.1142, -0.0557]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.state_self_attn.to_out.weight': tensor([[-0.0281,  0.0153,  0.0278,  ..., -0.0355,  0.0362, -0.0236],\n",
       "         [-0.0184,  0.0442, -0.0260,  ..., -0.0136,  0.0306,  0.0413],\n",
       "         [-0.0041, -0.0260,  0.0176,  ..., -0.0016, -0.0053,  0.0014],\n",
       "         ...,\n",
       "         [-0.0279,  0.0147, -0.0167,  ...,  0.0432, -0.0430,  0.0179],\n",
       "         [-0.0221,  0.0242, -0.0205,  ...,  0.0112,  0.0004, -0.0342],\n",
       "         [ 0.0278,  0.0143, -0.0407,  ...,  0.0176,  0.0441,  0.0110]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.state_self_attn.to_out.bias': tensor([ 0.0369, -0.0088,  0.0279, -0.0188,  0.0360,  0.0348, -0.0282, -0.0353,\n",
       "         -0.0363, -0.0024,  0.0027,  0.0196, -0.0149,  0.0156,  0.0262,  0.0401,\n",
       "          0.0147, -0.0343, -0.0119,  0.0244,  0.0215, -0.0033, -0.0040,  0.0135,\n",
       "          0.0164,  0.0384, -0.0336, -0.0065,  0.0313,  0.0385,  0.0231,  0.0160,\n",
       "          0.0238,  0.0068,  0.0316,  0.0283, -0.0387, -0.0271,  0.0220, -0.0016,\n",
       "         -0.0175, -0.0270,  0.0171,  0.0041,  0.0245, -0.0104,  0.0235, -0.0105,\n",
       "         -0.0142,  0.0223], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.input_state_cross_attn.norm.g': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.input_state_cross_attn.to_q.weight': tensor([[ 0.0476,  0.1114, -0.1199,  ...,  0.1261,  0.0922, -0.0414],\n",
       "         [-0.0171, -0.0760,  0.1127,  ...,  0.0624, -0.1394, -0.0828],\n",
       "         [-0.1052,  0.0991, -0.0830,  ...,  0.0477,  0.0635, -0.1289],\n",
       "         ...,\n",
       "         [ 0.0592, -0.0628, -0.0765,  ...,  0.0360, -0.0651,  0.1248],\n",
       "         [-0.0747,  0.0906, -0.0040,  ...,  0.0744, -0.0202,  0.0776],\n",
       "         [ 0.0507, -0.0641,  0.1310,  ..., -0.1384,  0.0817, -0.0456]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.input_state_cross_attn.to_kv.weight': tensor([[-1.3650e-01, -4.8742e-02, -8.2434e-02,  ..., -6.5501e-02,\n",
       "          -3.1865e-02, -3.8758e-02],\n",
       "         [-4.0367e-02,  2.3892e-03,  6.5167e-02,  ..., -1.2878e-01,\n",
       "          -1.2535e-01,  6.5947e-02],\n",
       "         [ 6.8275e-02, -2.6133e-02, -9.3549e-05,  ..., -8.6920e-02,\n",
       "           5.4597e-02,  1.0974e-01],\n",
       "         ...,\n",
       "         [ 1.0805e-01, -1.0999e-01, -1.0442e-01,  ..., -6.6457e-02,\n",
       "          -1.1350e-02, -1.1312e-02],\n",
       "         [-8.3168e-02, -4.5475e-02, -1.4002e-01,  ..., -1.9852e-02,\n",
       "           2.2722e-02, -1.7258e-02],\n",
       "         [-7.2751e-02,  3.5793e-02, -1.4097e-01,  ...,  1.2685e-01,\n",
       "          -1.2113e-01, -5.0748e-02]], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.input_state_cross_attn.to_out.weight': tensor([[ 0.0367, -0.0037,  0.0062,  ..., -0.0015, -0.0114,  0.0432],\n",
       "         [ 0.0143,  0.0274, -0.0353,  ...,  0.0120, -0.0330, -0.0303],\n",
       "         [ 0.0281, -0.0357, -0.0432,  ..., -0.0383,  0.0379, -0.0135],\n",
       "         ...,\n",
       "         [ 0.0256, -0.0042,  0.0199,  ...,  0.0224,  0.0023, -0.0441],\n",
       "         [-0.0338,  0.0178,  0.0167,  ..., -0.0391,  0.0012,  0.0426],\n",
       "         [ 0.0093, -0.0001, -0.0214,  ..., -0.0223,  0.0287,  0.0160]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.input_state_cross_attn.to_out.bias': tensor([-5.0511e-03,  3.8857e-03,  1.9464e-03, -5.6035e-02,  4.0771e-03,\n",
       "         -6.7451e-03,  1.4963e-02,  4.0910e-03,  9.0590e-03,  4.8617e-03,\n",
       "          2.6550e-03, -7.1349e-05, -7.4785e-03, -5.5936e-03,  5.1270e-03,\n",
       "         -1.6805e-03,  9.8455e-03,  1.0281e-02,  7.2544e-03, -3.6446e-03,\n",
       "          5.4466e-03,  5.1314e-03,  3.7322e-03, -8.3755e-03,  1.2475e-03,\n",
       "          2.7726e-02,  4.0266e-04,  5.1121e-03,  8.8868e-03,  3.8948e-03,\n",
       "         -9.8367e-04, -7.9075e-03,  7.8044e-03, -7.3885e-03,  4.9261e-03,\n",
       "         -1.0468e-02, -5.8210e-03, -4.3291e-04, -2.4097e-03, -8.2032e-03,\n",
       "          1.1373e-03,  1.0551e-03, -4.3285e-04,  2.6408e-03,  7.2293e-03,\n",
       "         -7.0286e-03,  7.9196e-03,  4.9219e-03, -7.5982e-03, -3.9782e-03],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.state_input_cross_attn.norm.g': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.state_input_cross_attn.to_q.weight': tensor([[-0.0236,  0.0505, -0.0191,  ...,  0.0829,  0.0553, -0.0072],\n",
       "         [ 0.0141, -0.1268, -0.0145,  ..., -0.0120,  0.0464,  0.0248],\n",
       "         [ 0.0194,  0.1312, -0.0522,  ..., -0.0575,  0.0604, -0.1185],\n",
       "         ...,\n",
       "         [ 0.1363,  0.0607, -0.0392,  ..., -0.0145, -0.0285,  0.1302],\n",
       "         [ 0.0429, -0.0992,  0.0927,  ...,  0.0474,  0.0347,  0.1030],\n",
       "         [ 0.0039, -0.0128, -0.1217,  ...,  0.1321, -0.0446,  0.1321]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.state_input_cross_attn.to_kv.weight': tensor([[ 0.1237, -0.1369, -0.1042,  ...,  0.1033,  0.0462, -0.0021],\n",
       "         [-0.0899, -0.0094,  0.1074,  ...,  0.0752, -0.0245,  0.0885],\n",
       "         [-0.0558,  0.0508,  0.1231,  ...,  0.1373,  0.0208,  0.0523],\n",
       "         ...,\n",
       "         [ 0.0038, -0.0978,  0.0962,  ...,  0.0282, -0.0587, -0.0342],\n",
       "         [ 0.0831,  0.0712,  0.0255,  ...,  0.1032,  0.0058, -0.0245],\n",
       "         [-0.0424,  0.0337,  0.1219,  ...,  0.0236,  0.0346,  0.1033]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.state_input_cross_attn.to_out.weight': tensor([[ 0.0096, -0.0005,  0.0224,  ...,  0.0086, -0.0038, -0.0391],\n",
       "         [ 0.0030,  0.0309,  0.0349,  ...,  0.0310, -0.0341, -0.0130],\n",
       "         [ 0.0294, -0.0156, -0.0183,  ..., -0.0287,  0.0016, -0.0387],\n",
       "         ...,\n",
       "         [ 0.0105,  0.0011,  0.0086,  ..., -0.0365,  0.0274,  0.0362],\n",
       "         [-0.0218, -0.0281,  0.0238,  ...,  0.0386, -0.0403,  0.0146],\n",
       "         [-0.0256,  0.0159, -0.0096,  ...,  0.0261,  0.0096, -0.0092]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.state_input_cross_attn.to_out.bias': tensor([ 0.0037,  0.0317, -0.0398,  0.0095, -0.0289, -0.0327, -0.0312,  0.0306,\n",
       "         -0.0060,  0.0318,  0.0341,  0.0363,  0.0402,  0.0008,  0.0131,  0.0120,\n",
       "          0.0247,  0.0182,  0.0188,  0.0082,  0.0148,  0.0433, -0.0224,  0.0103,\n",
       "          0.0437, -0.0195, -0.0304, -0.0072,  0.0107, -0.0063, -0.0386,  0.0093,\n",
       "         -0.0053,  0.0397, -0.0300,  0.0215, -0.0288,  0.0057, -0.0306, -0.0079,\n",
       "          0.0042, -0.0307,  0.0421,  0.0404, -0.0300,  0.0105,  0.0059, -0.0355,\n",
       "         -0.0129,  0.0079], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.proj_gate.main_proj.weight': tensor([[-0.0377, -0.0089, -0.0446,  ..., -0.1366,  0.0901, -0.0584],\n",
       "         [ 0.0002,  0.1255, -0.1217,  ...,  0.0886,  0.0859, -0.1284],\n",
       "         [ 0.0179, -0.0880,  0.1071,  ...,  0.1382,  0.1186, -0.0836],\n",
       "         ...,\n",
       "         [ 0.0675, -0.1061, -0.0088,  ..., -0.1211,  0.0489,  0.0861],\n",
       "         [-0.1279,  0.0178,  0.0354,  ...,  0.0213,  0.0699,  0.0187],\n",
       "         [-0.0759, -0.0368, -0.1318,  ...,  0.0769, -0.1199,  0.0568]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.proj_gate.main_proj.bias': tensor([-0.0692, -0.0079,  0.1028,  0.1297, -0.0431, -0.0091,  0.1096,  0.0975,\n",
       "         -0.1341, -0.1136,  0.1076, -0.0644,  0.1077, -0.0819,  0.1013,  0.0294,\n",
       "          0.0535, -0.0382, -0.0002, -0.0533, -0.1378, -0.0212, -0.0599,  0.1395,\n",
       "          0.0773, -0.0906,  0.0643,  0.0151, -0.0965,  0.0604,  0.0049, -0.1087,\n",
       "         -0.0331, -0.0317,  0.0222, -0.0550, -0.0495, -0.0730, -0.1108,  0.0591,\n",
       "         -0.1288,  0.0345,  0.1263, -0.0853, -0.1084, -0.0569,  0.1243,  0.1035,\n",
       "         -0.0299, -0.1305], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.proj_gate.input_proj.weight': tensor([[-0.0735, -0.0290,  0.0323,  ..., -0.0160, -0.0283,  0.0575],\n",
       "         [ 0.0353, -0.0407, -0.0064,  ...,  0.0765,  0.0410, -0.0762],\n",
       "         [ 0.0967,  0.0009,  0.1210,  ...,  0.1108, -0.1008,  0.0091],\n",
       "         ...,\n",
       "         [ 0.0291,  0.1077, -0.0344,  ..., -0.0525, -0.0297,  0.1378],\n",
       "         [-0.0541,  0.1331, -0.0970,  ...,  0.0471, -0.0987,  0.1057],\n",
       "         [-0.1079, -0.0684, -0.0768,  ...,  0.1326,  0.0422,  0.0692]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.proj_gate.input_proj.bias': tensor([-0.0839, -0.0289,  0.1026,  0.0661, -0.0167,  0.0185, -0.1032, -0.0126,\n",
       "          0.1089, -0.1308, -0.0023, -0.1005, -0.0223, -0.1357, -0.0731, -0.1174,\n",
       "         -0.0979,  0.1359, -0.0511, -0.0380, -0.0605,  0.0456,  0.0519, -0.0807,\n",
       "         -0.0165,  0.0366, -0.0283,  0.0878,  0.0972, -0.0867,  0.1221, -0.0781,\n",
       "         -0.0824,  0.1367, -0.0250,  0.0551,  0.1104, -0.1287, -0.1104,  0.0401,\n",
       "         -0.0445, -0.1199,  0.1231,  0.0975,  0.0180, -0.0067, -0.1271, -0.0846,\n",
       "         -0.0026,  0.0717], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.proj_gate.forget_proj.weight': tensor([[-0.0123,  0.0263, -0.1301,  ...,  0.0584, -0.1026, -0.0809],\n",
       "         [-0.1008, -0.0960,  0.0178,  ..., -0.0397,  0.0182,  0.0518],\n",
       "         [-0.0722, -0.0527, -0.0688,  ..., -0.0315,  0.0030, -0.0084],\n",
       "         ...,\n",
       "         [-0.0008, -0.0277, -0.1346,  ..., -0.0211,  0.1403, -0.0485],\n",
       "         [-0.1277,  0.0168, -0.1314,  ..., -0.0505,  0.0447,  0.1215],\n",
       "         [-0.0744, -0.1387,  0.0698,  ...,  0.1201, -0.0234,  0.0655]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.proj_gate.forget_proj.bias': tensor([-0.0878,  0.0854,  0.0494,  0.0275,  0.0178,  0.0459,  0.0074, -0.0316,\n",
       "         -0.1354,  0.0101, -0.0389, -0.0908, -0.0868, -0.0126,  0.1370, -0.1196,\n",
       "          0.0064, -0.0949,  0.1402,  0.1023, -0.1083, -0.1368,  0.1372, -0.1388,\n",
       "         -0.0400, -0.1054,  0.0919, -0.1001,  0.0115,  0.1034,  0.0555, -0.1408,\n",
       "         -0.0515,  0.0850, -0.0640,  0.0039, -0.0157,  0.0008,  0.1243,  0.0858,\n",
       "          0.0200, -0.0439,  0.1176,  0.1055,  0.1232,  0.0861, -0.0580,  0.0846,\n",
       "          0.0878,  0.0611], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.ff_gate.main_proj.weight': tensor([[ 0.0931, -0.1367, -0.0617,  ...,  0.0449, -0.0614,  0.0381],\n",
       "         [ 0.0405,  0.0848,  0.1278,  ...,  0.0710, -0.0803, -0.0099],\n",
       "         [ 0.0042, -0.0863,  0.0122,  ..., -0.1181, -0.0495,  0.1213],\n",
       "         ...,\n",
       "         [ 0.0951, -0.1112,  0.0369,  ...,  0.0452, -0.0764, -0.0719],\n",
       "         [-0.0677,  0.1364,  0.1147,  ...,  0.1133,  0.0219, -0.1003],\n",
       "         [ 0.0350, -0.1038,  0.0003,  ..., -0.1080, -0.1376, -0.1167]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.ff_gate.main_proj.bias': tensor([ 0.1051, -0.1185,  0.0255,  0.0267,  0.0876, -0.0282, -0.0684, -0.0343,\n",
       "          0.0115, -0.1363, -0.1172,  0.0239, -0.1074, -0.0027, -0.0717,  0.0859,\n",
       "         -0.0663,  0.0960,  0.0567,  0.0694, -0.1062, -0.1039,  0.0954, -0.0448,\n",
       "          0.0123,  0.0348,  0.0435,  0.0857,  0.1185,  0.1130, -0.0744,  0.0564,\n",
       "         -0.0954,  0.0577,  0.0961, -0.0367, -0.0364,  0.0911, -0.1067,  0.0674,\n",
       "          0.0766,  0.1244, -0.0322,  0.1075,  0.1106, -0.0660,  0.0548,  0.1398,\n",
       "         -0.1289, -0.0776], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.ff_gate.input_proj.weight': tensor([[-0.0009,  0.0602, -0.0103,  ...,  0.0156,  0.0714, -0.0990],\n",
       "         [ 0.0559, -0.0503,  0.0872,  ..., -0.0842, -0.0852,  0.0267],\n",
       "         [-0.1067,  0.0843, -0.0153,  ...,  0.1169, -0.1071,  0.0378],\n",
       "         ...,\n",
       "         [ 0.1285,  0.0478,  0.0564,  ..., -0.1212,  0.0987, -0.0060],\n",
       "         [ 0.0131,  0.0325, -0.1095,  ...,  0.0101,  0.1390, -0.1058],\n",
       "         [ 0.1048,  0.0633,  0.0037,  ...,  0.1177,  0.0280, -0.0490]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.ff_gate.input_proj.bias': tensor([-0.0523, -0.1287, -0.0300, -0.0683,  0.1105, -0.1228,  0.0184,  0.1354,\n",
       "         -0.1225, -0.0649,  0.0060, -0.0915,  0.0199, -0.0121, -0.1298,  0.1014,\n",
       "          0.0515,  0.0287, -0.0102, -0.0150,  0.0294,  0.1336,  0.0431, -0.0603,\n",
       "         -0.0280,  0.0766, -0.1390, -0.1030, -0.0415, -0.0269,  0.1384,  0.0363,\n",
       "          0.0940,  0.0830, -0.0212,  0.0065, -0.0437, -0.1367, -0.0903, -0.1129,\n",
       "         -0.0232,  0.0272, -0.0163, -0.1204,  0.1402, -0.0086, -0.0263, -0.0120,\n",
       "          0.0725,  0.0344], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.ff_gate.forget_proj.weight': tensor([[-0.0887, -0.0020, -0.0656,  ..., -0.0189,  0.0335,  0.0461],\n",
       "         [-0.0935, -0.1009, -0.0715,  ...,  0.0653, -0.0475,  0.0176],\n",
       "         [ 0.0156, -0.1285, -0.0587,  ...,  0.0062,  0.0825,  0.0121],\n",
       "         ...,\n",
       "         [ 0.0823, -0.1311, -0.0218,  ..., -0.0957, -0.1197, -0.0372],\n",
       "         [-0.1033,  0.1076, -0.0761,  ..., -0.1270, -0.0385,  0.0565],\n",
       "         [ 0.0255, -0.1242,  0.0509,  ..., -0.0227, -0.0755, -0.1408]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.ff_gate.forget_proj.bias': tensor([-0.0276, -0.0539, -0.0893, -0.0253,  0.0935,  0.1031, -0.0227,  0.0177,\n",
       "          0.0168, -0.0983, -0.0214,  0.0856, -0.0171, -0.0240,  0.0592, -0.0440,\n",
       "         -0.0809, -0.0201, -0.0507,  0.0685,  0.0345, -0.1017, -0.1169,  0.0170,\n",
       "         -0.0338, -0.1210,  0.0842,  0.0910,  0.0328,  0.0648,  0.0791,  0.1023,\n",
       "          0.0961,  0.1223, -0.1234,  0.0276, -0.0477, -0.0466, -0.1372, -0.1412,\n",
       "          0.0769,  0.1016,  0.1237,  0.0004,  0.0885,  0.0433,  0.0787,  0.1089,\n",
       "          0.0983, -0.0048], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.input_proj.weight': tensor([[-0.0309,  0.0340,  0.0141,  ...,  0.0281,  0.0431, -0.0302],\n",
       "         [-0.1029, -0.0201, -0.0197,  ..., -0.0202,  0.0370, -0.0308],\n",
       "         [-0.0204,  0.0507, -0.0516,  ...,  0.0689,  0.0274,  0.0431],\n",
       "         ...,\n",
       "         [ 0.0611, -0.0126,  0.0376,  ..., -0.0236,  0.0268, -0.0113],\n",
       "         [-0.0256, -0.0485,  0.0067,  ..., -0.0989,  0.0522, -0.0328],\n",
       "         [ 0.0074, -0.0042,  0.0716,  ..., -0.0149, -0.0059,  0.0360]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.state_proj.weight': tensor([[ 0.0245, -0.0048, -0.0315,  ...,  0.0751, -0.0810, -0.0098],\n",
       "         [ 0.0853, -0.0296, -0.0291,  ...,  0.0457, -0.0160,  0.0044],\n",
       "         [-0.0433, -0.0626,  0.0152,  ..., -0.0771, -0.0640, -0.0035],\n",
       "         ...,\n",
       "         [-0.0689,  0.0649,  0.0046,  ...,  0.0905, -0.0199, -0.0047],\n",
       "         [ 0.0748,  0.0748, -0.0585,  ..., -0.0937, -0.0088, -0.0584],\n",
       "         [-0.0280, -0.0241, -0.0753,  ..., -0.0158,  0.0744, -0.0101]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.input_ff.ff.0.0.weight': tensor([[ 0.1472,  0.3022,  0.0608,  ...,  0.0103, -0.2884,  0.0631],\n",
       "         [ 0.4894,  0.0567, -0.0976,  ..., -0.0138, -0.0345, -0.1226],\n",
       "         [ 0.1466,  0.3502, -0.0128,  ...,  0.0718, -0.0826, -0.0926],\n",
       "         ...,\n",
       "         [ 0.2035,  0.0583, -0.1133,  ..., -0.1159, -0.1540, -0.1773],\n",
       "         [ 0.0487,  0.0213,  0.0566,  ..., -0.1452, -0.3963, -0.1095],\n",
       "         [ 0.1825,  0.1281,  0.0837,  ...,  0.0319, -0.3126, -0.0156]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.input_ff.ff.0.0.bias': tensor([-0.6066, -0.3816, -0.1855, -0.2886, -0.2218, -0.1853, -0.1755, -0.2109,\n",
       "         -0.3247, -0.2341, -0.4232, -0.3827, -0.4360, -0.4918, -0.2795, -0.3203,\n",
       "         -0.0653,  0.0418, -0.2728, -0.1696, -0.1893, -0.3621, -0.2699, -0.1721,\n",
       "         -0.5187, -0.1688, -0.3045, -0.4986, -0.0925, -0.2448, -0.2384, -0.1917,\n",
       "         -0.4009, -0.1947, -0.3494, -0.3357, -0.1643, -0.1191, -0.2017, -0.2212,\n",
       "         -0.4212, -0.2969, -0.4201, -0.3017, -0.1506, -0.1274, -0.1509, -0.3468,\n",
       "         -0.5024, -0.3513, -0.3896, -0.5861, -0.3416, -0.3881, -0.3077, -0.4000,\n",
       "         -0.5847, -0.3493, -0.3057, -0.3594, -0.1946, -0.4844, -0.3694, -0.1640,\n",
       "         -0.5172, -0.1495, -0.4047, -0.0979, -0.2383, -0.4039, -0.3273, -0.1056,\n",
       "         -0.4992, -0.3648, -0.4601, -0.3024, -0.2965, -0.4076, -0.3371, -0.1140,\n",
       "         -0.4827, -0.2818, -0.5379, -0.3943, -0.2209, -0.2925, -0.3346, -0.3727,\n",
       "         -0.3916, -0.2057, -0.1182, -0.2797, -0.2452, -0.1659, -0.2954, -0.1634,\n",
       "         -0.3211, -0.3323, -0.6009, -0.2148, -0.2479, -0.3795, -0.2027, -0.4088,\n",
       "         -0.3105, -0.4979, -0.3726, -0.2206, -0.2962, -0.4051, -0.1437, -0.4795,\n",
       "         -0.4121, -0.2761, -0.2794, -0.3523, -0.1051, -0.2815, -0.2920, -0.0726,\n",
       "         -0.2626, -0.1068, -0.3382, -0.1569, -0.2691, -0.4520, -0.5899, -0.1625,\n",
       "         -0.2138, -0.3735, -0.1142, -0.2442, -0.0839, -0.0951, -0.1851, -0.3088,\n",
       "         -0.1226, -0.4080, -0.3668, -0.1330, -0.3812, -0.3432, -0.1997, -0.3254,\n",
       "         -0.2879, -0.4237, -0.5762, -0.2494, -0.5222, -0.5479, -0.2334, -0.1961,\n",
       "         -0.2899, -0.3023, -0.1086, -0.2683, -0.2037, -0.2127, -0.3315, -0.3321,\n",
       "         -0.3261, -0.0877, -0.1761, -0.2145, -0.2673, -0.2439, -0.2040, -0.1526,\n",
       "         -0.4406, -0.5491, -0.3473, -0.1805, -0.2866, -0.3405, -0.1734, -0.0946,\n",
       "         -0.1196, -0.1794, -0.0753, -0.4964, -0.3908, -0.2198, -0.1526, -0.3597,\n",
       "         -0.4445, -0.2755, -0.3079, -0.1729, -0.4252,  0.0250, -0.1282, -0.2993,\n",
       "         -0.2044, -0.2801, -0.3803, -0.1189, -0.3312, -0.4330, -0.5199, -0.5143],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.input_ff.ff.2.weight': tensor([[ 0.0304,  0.0754, -0.0627,  ..., -0.0288, -0.0088,  0.0192],\n",
       "         [ 0.0892,  0.0094, -0.0667,  ..., -0.0517,  0.0044, -0.0599],\n",
       "         [ 0.0142, -0.0410,  0.0211,  ...,  0.1040,  0.0346,  0.0590],\n",
       "         ...,\n",
       "         [ 0.0480, -0.0868,  0.0070,  ...,  0.0450, -0.0598, -0.0667],\n",
       "         [-0.1576, -0.3944, -0.1613,  ..., -0.0215,  0.0039, -0.1168],\n",
       "         [-0.0931,  0.0011,  0.1018,  ..., -0.1266,  0.0384,  0.0378]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.input_ff.ff.2.bias': tensor([-0.0587,  0.1595, -0.3178, -0.0136, -0.2010, -0.0456, -0.2571,  0.0248,\n",
       "          0.0049, -0.1502,  0.1208, -0.0105,  0.1782,  0.0833,  0.0238,  0.1953,\n",
       "         -0.0569,  0.0400, -0.1466, -0.1418, -0.1320,  0.1938,  0.0498,  0.1451,\n",
       "         -0.0586, -0.1631, -0.2570,  0.1185,  0.1870,  0.0032, -0.0106,  0.0832,\n",
       "         -0.2525,  0.2607,  0.0285, -0.1103,  0.0197,  0.1529,  0.0969, -0.0132,\n",
       "          0.0343,  0.0652,  0.1224, -0.0624, -0.1510,  0.0378, -0.1126,  0.1230,\n",
       "          0.2684, -0.1862], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.state_ff.ff.0.0.weight': tensor([[ 0.0863,  0.0297, -0.0625,  ...,  0.0270,  0.1018,  0.1289],\n",
       "         [ 0.0795, -0.1214, -0.0775,  ...,  0.1254, -0.0202, -0.0754],\n",
       "         [ 0.0246, -0.1341,  0.0832,  ...,  0.0311, -0.1354,  0.0036],\n",
       "         ...,\n",
       "         [-0.1380, -0.0018,  0.0298,  ...,  0.0517, -0.0983,  0.0314],\n",
       "         [-0.0831, -0.0212,  0.1142,  ..., -0.0412, -0.0196,  0.0728],\n",
       "         [ 0.0961,  0.0912,  0.0530,  ..., -0.1368,  0.0419, -0.0907]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.state_ff.ff.0.0.bias': tensor([ 0.0279,  0.1219,  0.0024,  0.0039, -0.0574, -0.1399, -0.0931, -0.0534,\n",
       "         -0.0889, -0.0535, -0.0684, -0.1341,  0.0741,  0.0451,  0.0635,  0.0520,\n",
       "         -0.1098, -0.0821,  0.0696, -0.0590, -0.0177,  0.0151, -0.1041, -0.0842,\n",
       "         -0.0291,  0.0930,  0.1204,  0.1071, -0.1106,  0.1315,  0.0913,  0.0829,\n",
       "          0.0966, -0.0090, -0.0509, -0.0464,  0.0229,  0.0087,  0.0956, -0.0927,\n",
       "          0.0384, -0.1333,  0.0321,  0.1206, -0.0473,  0.1161, -0.1365,  0.0986,\n",
       "          0.0249, -0.0915,  0.0588,  0.1333,  0.1347, -0.1260,  0.0948, -0.1174,\n",
       "         -0.1334, -0.1123,  0.0088,  0.1103, -0.1275,  0.0434,  0.1228,  0.1175,\n",
       "         -0.0453,  0.0798,  0.0309, -0.0746,  0.1120, -0.0471, -0.1345, -0.0304,\n",
       "         -0.1177,  0.0812,  0.0267,  0.0096,  0.0566,  0.0639, -0.0779, -0.1253,\n",
       "         -0.1279,  0.0482,  0.1145,  0.0889,  0.0576,  0.1379,  0.0174, -0.0148,\n",
       "          0.0370,  0.0460,  0.0639, -0.1373,  0.1150, -0.0159, -0.0074, -0.1309,\n",
       "         -0.0966,  0.0227,  0.0849,  0.1355,  0.0601, -0.1400,  0.1023,  0.0727,\n",
       "         -0.0554,  0.0676,  0.0710,  0.0912, -0.0928, -0.0625, -0.0953, -0.0404,\n",
       "         -0.0250, -0.1088, -0.0737, -0.0440,  0.0680, -0.0753,  0.0020,  0.1349,\n",
       "          0.0720,  0.1049,  0.0855,  0.0330, -0.1000, -0.0161, -0.0914, -0.0910,\n",
       "         -0.1292,  0.0181, -0.0483,  0.1165, -0.0926, -0.1368,  0.0298,  0.1064,\n",
       "         -0.0346,  0.1068,  0.1076, -0.1301, -0.0562,  0.0081,  0.0199,  0.0736,\n",
       "          0.0171, -0.0946,  0.0591, -0.0787, -0.0323,  0.0008, -0.1134, -0.0137,\n",
       "         -0.0911, -0.0902, -0.0464,  0.1160, -0.1352,  0.0660,  0.0125, -0.0043,\n",
       "         -0.0439, -0.0211, -0.0783,  0.0566,  0.0904, -0.1229, -0.1148,  0.0963,\n",
       "          0.0498,  0.0012,  0.0273, -0.1125,  0.0624,  0.0231, -0.0193, -0.1155,\n",
       "         -0.0502,  0.0770, -0.0182,  0.1012,  0.0839, -0.0762, -0.0696,  0.0832,\n",
       "         -0.0110, -0.0415,  0.0683, -0.0664,  0.0129,  0.0089,  0.0184,  0.0665,\n",
       "          0.0459,  0.0725,  0.0712,  0.0341, -0.0537,  0.1193,  0.0932, -0.0136],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.state_ff.ff.2.weight': tensor([[-0.0284,  0.0465, -0.0102,  ..., -0.0604,  0.0147, -0.0653],\n",
       "         [ 0.0135,  0.0275,  0.0478,  ..., -0.0218, -0.0404,  0.0019],\n",
       "         [ 0.0047,  0.0140, -0.0563,  ...,  0.0068,  0.0099,  0.0343],\n",
       "         ...,\n",
       "         [-0.0071, -0.0274, -0.0270,  ...,  0.0200, -0.0172, -0.0193],\n",
       "         [ 0.0302,  0.0586, -0.0162,  ...,  0.0619, -0.0204, -0.0029],\n",
       "         [-0.0525,  0.0265,  0.0401,  ...,  0.0276,  0.0152,  0.0521]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.self_attn.state_ff.ff.2.bias': tensor([ 0.0399, -0.0665, -0.0058,  0.0680,  0.0194,  0.0278,  0.0011,  0.0100,\n",
       "          0.0627, -0.0381, -0.0687,  0.0146, -0.0145, -0.0096, -0.0537, -0.0288,\n",
       "         -0.0531,  0.0326, -0.0414,  0.0179,  0.0437, -0.0431,  0.0302, -0.0663,\n",
       "          0.0434,  0.0586, -0.0355,  0.0640,  0.0126,  0.0509,  0.0287, -0.0337,\n",
       "         -0.0013, -0.0315,  0.0045,  0.0693, -0.0093,  0.0477, -0.0478,  0.0343,\n",
       "          0.0602,  0.0359,  0.0552, -0.0192,  0.0511, -0.0077,  0.0520, -0.0286,\n",
       "          0.0431, -0.0404], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.feed_forward.bn.weight': tensor([0.7081, 0.9654, 0.7323, 0.9244, 0.7044, 1.0808, 0.8080, 0.6978, 0.7679,\n",
       "         0.7153, 0.8890, 0.9423, 0.6693, 0.6315, 0.7880, 0.7656, 0.7275, 1.0842,\n",
       "         0.6520, 0.7511, 0.7281, 0.7923, 0.7122, 0.7161, 0.8388, 0.8062, 0.7539,\n",
       "         0.8874, 0.6900, 0.8246, 0.7362, 0.7526, 1.0559, 1.2523, 0.5499, 0.8170,\n",
       "         0.6002, 0.8889, 0.8447, 0.9147, 0.6801, 1.3412, 0.7498, 0.7914, 0.8683,\n",
       "         0.8090, 0.8384, 0.8378, 1.2502, 0.7163], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.feed_forward.bn.bias': tensor([-5.9209e-02, -1.5887e-02, -2.2844e-01,  4.7808e-02, -2.9864e-02,\n",
       "          2.7296e-02,  3.2984e-01, -2.7722e-02, -3.0427e-02, -2.7137e-02,\n",
       "         -8.1517e-02,  4.9807e-02, -1.1517e-01, -3.7157e-02, -3.1170e-02,\n",
       "         -6.0684e-03, -9.3122e-02,  1.4158e-01,  6.8747e-02,  4.3105e-02,\n",
       "          8.5874e-03, -3.4463e-02, -2.8797e-02,  3.6339e-02,  1.1154e-01,\n",
       "         -2.9145e-02,  5.5568e-02, -8.8648e-02,  1.6354e-01,  2.1914e-02,\n",
       "          1.5454e-01, -2.5077e-01, -9.4310e-01,  3.5087e-01,  4.7960e-02,\n",
       "         -8.4377e-02,  5.9226e-03,  2.6210e-02,  9.1318e-02,  2.2983e-01,\n",
       "         -4.2733e-02, -4.7012e-02,  1.3498e-01, -2.9107e-01,  8.3756e-02,\n",
       "          7.2495e-02,  8.4451e-04, -3.6822e-02,  1.1113e+00, -5.5193e-02],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.feed_forward.bn.running_mean': tensor([ 1.3127, -0.1381,  0.9257,  0.8759,  1.0497,  0.5509,  0.4384,  1.1876,\n",
       "          0.7018,  2.2777,  1.4523,  0.5235,  1.2317,  0.7381,  0.7159,  1.0134,\n",
       "          1.6205,  0.6130,  1.0032,  1.2005,  1.2969,  0.8384,  0.7534,  0.9709,\n",
       "          1.3587,  0.6220,  0.4227,  0.4191,  1.5239,  1.6728,  2.0787,  1.0676,\n",
       "          0.7216,  1.0670,  0.7841,  1.2320,  1.0570,  0.2058,  0.5732,  0.7638,\n",
       "          0.8812,  0.4234,  2.4502,  0.5776,  0.9802,  0.7616,  0.9717,  1.4046,\n",
       "          0.3735,  1.1923], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.feed_forward.bn.running_var': tensor([ 9.0425,  1.8795,  8.1074,  5.5376,  6.7752,  6.0371,  2.8891,  7.1964,\n",
       "          6.7694, 12.7527, 10.8970,  6.8542,  6.8162,  6.1546,  5.3866, 11.7950,\n",
       "         11.6584,  5.5999,  7.6379,  6.1262,  6.9977,  9.3523,  5.6860,  9.3561,\n",
       "         10.4933,  6.2718,  5.3967,  5.3317, 11.6677, 10.4175, 14.1537,  6.5940,\n",
       "          4.3613,  7.8046,  5.9478, 10.0614,  7.6403,  4.2236,  6.3704,  6.4115,\n",
       "          7.5005,  5.5602, 12.9511,  5.6866,  6.7509,  7.5806,  7.2660, 13.9719,\n",
       "          2.0276, 10.7222], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.feed_forward.bn.num_batches_tracked': tensor(213030),\n",
       " 'transformer_rec.model.layers.0.feed_forward.encoder_0.weight': tensor([[[-0.0674],\n",
       "          [ 0.1513],\n",
       "          [-0.2011],\n",
       "          ...,\n",
       "          [-0.3035],\n",
       "          [ 0.1258],\n",
       "          [ 0.0656]],\n",
       " \n",
       "         [[-0.0673],\n",
       "          [ 0.4086],\n",
       "          [ 0.1896],\n",
       "          ...,\n",
       "          [ 0.0873],\n",
       "          [-0.1557],\n",
       "          [ 0.0840]],\n",
       " \n",
       "         [[ 0.2485],\n",
       "          [ 0.0952],\n",
       "          [ 0.2413],\n",
       "          ...,\n",
       "          [-0.2725],\n",
       "          [-0.0008],\n",
       "          [ 0.0686]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.1143],\n",
       "          [ 0.1888],\n",
       "          [ 0.0490],\n",
       "          ...,\n",
       "          [-0.0588],\n",
       "          [-0.0933],\n",
       "          [-0.2483]],\n",
       " \n",
       "         [[-0.0936],\n",
       "          [ 0.1699],\n",
       "          [ 0.1374],\n",
       "          ...,\n",
       "          [-0.1831],\n",
       "          [-0.2355],\n",
       "          [-0.1011]],\n",
       " \n",
       "         [[ 0.1921],\n",
       "          [ 0.1368],\n",
       "          [ 0.0686],\n",
       "          ...,\n",
       "          [-0.3514],\n",
       "          [ 0.0453],\n",
       "          [ 0.4520]]], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.feed_forward.encoder_0.bias': tensor([-0.1423, -0.3792, -0.2182, -0.1545, -0.1706, -0.2395,  0.0470,  0.0363,\n",
       "         -0.0591, -0.0322, -0.1554, -0.0300, -0.0307, -0.0776,  0.0132,  0.1679,\n",
       "         -0.0719, -0.0854, -0.0248, -0.0403,  0.1192, -0.0569, -0.1308, -0.1829,\n",
       "         -0.1241, -0.1993, -0.1542, -0.1533,  0.0881, -0.0007, -0.0298, -0.2649,\n",
       "         -0.0512, -0.3833, -0.1545, -0.0796, -0.0060,  0.0018, -0.0853, -0.0826,\n",
       "         -0.1516, -0.0120,  0.0911,  0.0935, -0.0381,  0.1123,  0.0766, -0.2154,\n",
       "         -0.0817, -0.0857], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.feed_forward.encoder_1.weight': tensor([[[ 0.2401,  0.2617,  0.3555],\n",
       "          [-0.0395, -0.0072, -0.0362],\n",
       "          [ 0.0712,  0.1203,  0.0847],\n",
       "          ...,\n",
       "          [-0.3888, -0.2568, -0.2779],\n",
       "          [ 0.1593,  0.1257,  0.0910],\n",
       "          [-0.0476, -0.0752, -0.0570]],\n",
       " \n",
       "         [[-0.0073, -0.1202,  0.0431],\n",
       "          [ 0.4014,  0.5239,  0.3099],\n",
       "          [ 0.0870, -0.0166,  0.1389],\n",
       "          ...,\n",
       "          [ 0.1473,  0.2060,  0.1584],\n",
       "          [ 0.0290, -0.0977, -0.0347],\n",
       "          [ 0.0182,  0.0600,  0.0216]],\n",
       " \n",
       "         [[ 0.3045,  0.2516,  0.2230],\n",
       "          [-0.0786, -0.0873, -0.0291],\n",
       "          [ 0.0193,  0.1006,  0.1242],\n",
       "          ...,\n",
       "          [-0.1889, -0.2928, -0.2787],\n",
       "          [ 0.1225,  0.1653,  0.0655],\n",
       "          [-0.2118, -0.0693, -0.0191]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.0697,  0.0700,  0.1279],\n",
       "          [ 0.0425,  0.0355,  0.1182],\n",
       "          [ 0.0310, -0.0026,  0.0121],\n",
       "          ...,\n",
       "          [ 0.0826,  0.0411,  0.0749],\n",
       "          [-0.1215, -0.1864, -0.1974],\n",
       "          [-0.1982, -0.2958, -0.2672]],\n",
       " \n",
       "         [[ 0.0712,  0.0507, -0.0206],\n",
       "          [ 0.0671,  0.1605,  0.0546],\n",
       "          [ 0.0250,  0.0222, -0.0290],\n",
       "          ...,\n",
       "          [-0.0045, -0.0944, -0.0594],\n",
       "          [-0.1514, -0.3676,  0.3073],\n",
       "          [ 0.0738, -0.1062, -0.0496]],\n",
       " \n",
       "         [[-0.0077, -0.1064, -0.0442],\n",
       "          [-0.1291, -0.0527, -0.1743],\n",
       "          [-0.0829,  0.0216, -0.0693],\n",
       "          ...,\n",
       "          [-0.4185, -0.4855, -0.4372],\n",
       "          [ 0.0604,  0.0953,  0.0175],\n",
       "          [ 0.2975,  0.3991,  0.4324]]], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.feed_forward.encoder_1.bias': tensor([-0.0974, -0.3931,  0.0051, -0.0982, -0.2474, -0.1320, -0.2051, -0.0614,\n",
       "          0.0059,  0.1149, -0.1717,  0.0744, -0.0869, -0.0402,  0.0035, -0.1804,\n",
       "          0.1585, -0.1112, -0.1149,  0.1236,  0.0403, -0.0556, -0.1081, -0.0829,\n",
       "          0.0073, -0.1556, -0.2690, -0.2693, -0.0061, -0.0809, -0.0051, -0.0613,\n",
       "          0.0706, -0.1372, -0.0346, -0.0608, -0.1511, -0.1554, -0.2059, -0.1093,\n",
       "         -0.1884, -0.0894, -0.0456, -0.0690, -0.0856,  0.0055,  0.0480, -0.1436,\n",
       "         -0.2088,  0.0720], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.feed_forward.encoder_2.weight': tensor([[[ 0.2965,  0.3249,  0.2018,  0.2086,  0.2087],\n",
       "          [-0.0588,  0.0119,  0.0416,  0.1154,  0.0559],\n",
       "          [ 0.0886,  0.0456,  0.1387,  0.0022,  0.0491],\n",
       "          ...,\n",
       "          [-0.3463, -0.3784, -0.2460, -0.3057, -0.2426],\n",
       "          [ 0.1752,  0.0848,  0.1292,  0.1417,  0.1313],\n",
       "          [-0.0612, -0.0077, -0.0437,  0.0317, -0.0013]],\n",
       " \n",
       "         [[-0.0171,  0.0145, -0.0605, -0.0561, -0.0921],\n",
       "          [ 0.4995,  0.4114,  0.4031,  0.4433,  0.3599],\n",
       "          [-0.0577,  0.0514, -0.0323,  0.0401,  0.0250],\n",
       "          ...,\n",
       "          [ 0.0624,  0.1011,  0.2194,  0.2482,  0.0955],\n",
       "          [-0.0241,  0.0733, -0.1379,  0.0363,  0.1218],\n",
       "          [-0.1112,  0.0118,  0.0604,  0.0555,  0.0081]],\n",
       " \n",
       "         [[ 0.4048,  0.3717,  0.2671,  0.4012,  0.1999],\n",
       "          [ 0.0379, -0.0121, -0.0414, -0.0270,  0.0151],\n",
       "          [ 0.2506,  0.0556,  0.2174,  0.2800,  0.2964],\n",
       "          ...,\n",
       "          [-0.3405, -0.2037, -0.2340, -0.3200, -0.2702],\n",
       "          [ 0.0195,  0.0363,  0.0292,  0.1034, -0.0118],\n",
       "          [-0.0348, -0.0056, -0.0557, -0.0123, -0.0310]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.0409,  0.0448,  0.0961,  0.1033,  0.0347],\n",
       "          [-0.1439, -0.0366,  0.0163,  0.0639,  0.1184],\n",
       "          [ 0.0739, -0.0275,  0.0055,  0.0702, -0.0458],\n",
       "          ...,\n",
       "          [ 0.0292,  0.0336,  0.0828,  0.0756,  0.1462],\n",
       "          [ 0.1281, -0.0463, -0.0177, -0.0924, -0.1485],\n",
       "          [-0.1141, -0.1248, -0.1569, -0.0192, -0.0759]],\n",
       " \n",
       "         [[ 0.0457, -0.0605, -0.0426, -0.0334, -0.0590],\n",
       "          [ 0.1841, -0.0304,  0.0310,  0.0249, -0.1011],\n",
       "          [ 0.0722, -0.0346,  0.0516,  0.0422,  0.0735],\n",
       "          ...,\n",
       "          [ 0.0288, -0.0135, -0.0557,  0.0500,  0.0229],\n",
       "          [-0.1183, -0.0113, -0.4499,  0.1793,  0.1497],\n",
       "          [ 0.0552,  0.0424, -0.0439, -0.0238, -0.0120]],\n",
       " \n",
       "         [[-0.1038, -0.0019, -0.0208, -0.0538,  0.0313],\n",
       "          [-0.0235,  0.0358,  0.0268,  0.0438,  0.1629],\n",
       "          [-0.1063, -0.1830, -0.1370, -0.1549, -0.0416],\n",
       "          ...,\n",
       "          [-0.2111, -0.1731, -0.2248, -0.1452, -0.0624],\n",
       "          [-0.0675, -0.1304, -0.1009, -0.1940, -0.1298],\n",
       "          [ 0.1322,  0.1178,  0.0676,  0.1177,  0.0601]]], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.feed_forward.encoder_2.bias': tensor([-0.0244, -0.3571,  0.0362, -0.0370,  0.0220, -0.2335, -0.2832,  0.0160,\n",
       "         -0.1280,  0.1347, -0.0750, -0.1750, -0.0627, -0.0890, -0.0675, -0.1193,\n",
       "          0.1307, -0.1010, -0.1441, -0.2355, -0.1861,  0.0237, -0.2817, -0.1286,\n",
       "         -0.0687, -0.1551, -0.1856, -0.1553, -0.0955,  0.1472, -0.0110,  0.0841,\n",
       "         -0.0413, -0.0924, -0.0893, -0.0313, -0.2892, -0.1432, -0.1011, -0.0625,\n",
       "          0.1781,  0.0008,  0.1928, -0.1429, -0.2300, -0.1925, -0.1155,  0.0567,\n",
       "         -0.0163, -0.1821], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.sublayer.0.norm.a_2': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.sublayer.0.norm.b_2': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.sublayer.1.norm.a_2': tensor([0.9405, 0.8829, 0.4898, 0.8343, 1.0158, 0.9622, 0.8343, 0.9424, 1.1200,\n",
       "         1.0827, 0.7271, 1.0306, 1.0450, 1.1368, 0.9225, 1.0524, 1.1128, 1.1771,\n",
       "         1.0050, 0.9373, 1.0101, 0.8397, 1.1436, 1.1338, 1.1678, 1.0497, 0.6383,\n",
       "         0.8227, 1.2288, 0.9504, 1.1100, 1.0434, 0.4578, 0.6348, 1.0928, 1.0295,\n",
       "         1.2897, 1.1564, 1.0012, 0.8528, 1.0185, 0.7988, 1.0926, 0.8459, 0.8756,\n",
       "         0.9008, 1.2236, 1.1901, 0.3869, 0.9605], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.0.sublayer.1.norm.b_2': tensor([ 0.1382,  0.0026, -0.0831,  0.2120, -0.0163, -0.0200, -0.4260, -0.1009,\n",
       "         -0.0030, -0.0761,  0.2569, -0.0299,  0.1472,  0.0038,  0.0929,  0.0492,\n",
       "         -0.1050,  0.0442, -0.1190, -0.0317, -0.1354,  0.3230,  0.0327,  0.1510,\n",
       "         -0.1400, -0.0617, -0.2262,  0.1821,  0.1885,  0.0786, -0.0781,  0.2525,\n",
       "          0.4345,  0.1277, -0.0517, -0.0670,  0.0332,  0.2197,  0.0651, -0.0804,\n",
       "          0.0990,  0.1712,  0.1424,  0.1665,  0.0551,  0.0483, -0.0557,  0.1190,\n",
       "         -0.3886, -0.1665], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.rotary_pos_emb.inv_freq': tensor([1.0000e+00, 5.6234e-01, 3.1623e-01, 1.7783e-01, 1.0000e-01, 5.6234e-02,\n",
       "         3.1623e-02, 1.7783e-02, 1.0000e-02, 5.6234e-03, 3.1623e-03, 1.7783e-03,\n",
       "         1.0000e-03, 5.6234e-04, 3.1623e-04, 1.7783e-04], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.input_self_attn.norm.g': tensor([0.1670, 0.1060, 0.1032, 0.0807, 0.1591, 0.0582, 0.0341, 0.0510, 0.2503,\n",
       "         0.1428, 0.1111, 0.2597, 0.0506, 0.1464, 0.0169, 0.0659, 0.1060, 0.1333,\n",
       "         0.1135, 0.0585, 0.1189, 0.1510, 0.1895, 0.1614, 0.0436, 0.0715, 0.1546,\n",
       "         0.1237, 0.1365, 0.0308, 0.1350, 0.1439, 0.0225, 0.0553, 0.0975, 0.1564,\n",
       "         0.0917, 0.1623, 0.0997, 0.1279, 0.1724, 0.0359, 0.1650, 0.1890, 0.2012,\n",
       "         0.0711, 0.1353, 0.0332, 0.0127, 0.0520], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.input_self_attn.to_q.weight': tensor([[-9.9605e-02, -9.5126e-02, -8.1304e-02,  ..., -4.4981e-02,\n",
       "          -9.9586e-02,  9.7320e-02],\n",
       "         [-1.0981e-01,  1.9129e-01,  1.7854e-01,  ...,  1.8642e-02,\n",
       "           1.3450e-01, -1.4737e-01],\n",
       "         [ 7.7869e-02, -1.5828e-01, -2.7947e-01,  ..., -1.4669e-01,\n",
       "          -2.3983e-01,  1.8063e-02],\n",
       "         ...,\n",
       "         [-3.1382e-05,  7.0416e-02,  9.8246e-02,  ...,  1.5688e-02,\n",
       "           1.4584e-01,  5.9870e-03],\n",
       "         [ 1.2328e-02,  7.2794e-02,  2.5430e-02,  ..., -1.7766e-01,\n",
       "          -1.2720e-01,  1.4233e-01],\n",
       "         [ 1.2978e-01, -1.1501e-01,  7.0924e-02,  ..., -2.6889e-02,\n",
       "          -1.6167e-01, -9.0559e-02]], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.input_self_attn.to_kv.weight': tensor([[-0.1159, -0.1076,  0.1196,  ...,  0.1810,  0.0854, -0.0752],\n",
       "         [ 0.1423, -0.0229,  0.0976,  ..., -0.3322, -0.1140,  0.3200],\n",
       "         [ 0.1550,  0.1883,  0.0686,  ...,  0.2797, -0.0546, -0.0113],\n",
       "         ...,\n",
       "         [-0.0420,  0.0590,  0.0210,  ...,  0.0564,  0.0811,  0.0652],\n",
       "         [-0.0548, -0.0734, -0.0307,  ..., -0.0506,  0.1146, -0.1447],\n",
       "         [ 0.0290, -0.0162, -0.0126,  ..., -0.0385, -0.0200,  0.0348]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.input_self_attn.to_out.weight': tensor([[ 0.0052, -0.0007,  0.0107,  ...,  0.0234, -0.0314,  0.0027],\n",
       "         [ 0.0167,  0.0112, -0.0041,  ..., -0.0074, -0.0232, -0.0365],\n",
       "         [ 0.0041,  0.0067, -0.0013,  ...,  0.0179, -0.0162,  0.0187],\n",
       "         ...,\n",
       "         [-0.0091, -0.0244, -0.0028,  ...,  0.0009, -0.0112,  0.0049],\n",
       "         [ 0.0019, -0.0205, -0.0056,  ..., -0.0284,  0.0038, -0.0093],\n",
       "         [-0.0086,  0.0002, -0.0054,  ...,  0.0100,  0.0094, -0.0007]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.input_self_attn.to_out.bias': tensor([-7.8995e-03, -2.5505e-03,  2.2334e-03,  8.8242e-03, -5.0351e-03,\n",
       "          8.6266e-05, -3.0466e-03,  1.6838e-03,  7.0235e-03, -7.0041e-03,\n",
       "          1.6420e-02, -5.5444e-03,  1.1005e-02,  7.1273e-03,  7.1504e-04,\n",
       "         -4.7301e-04,  1.5041e-03,  3.9193e-04,  3.3940e-03,  2.1613e-03,\n",
       "         -2.4654e-03,  2.6097e-03,  5.7391e-03, -8.3459e-04, -1.6011e-04,\n",
       "          4.3323e-03,  8.0218e-03, -4.1543e-03, -1.5651e-03,  7.4589e-03,\n",
       "         -2.0831e-03, -2.2802e-03, -2.9268e-03, -8.8753e-03,  4.1169e-04,\n",
       "         -4.9599e-03,  2.9705e-03,  6.9931e-03, -5.9865e-03, -2.8137e-03,\n",
       "         -1.4363e-02,  5.4681e-03, -5.2262e-03, -1.7822e-03, -6.5558e-03,\n",
       "          2.0464e-03,  3.1439e-04, -1.4382e-03, -5.4370e-03, -1.3522e-03],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.state_self_attn.norm.g': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.state_self_attn.to_q.weight': tensor([[ 0.0509,  0.1051,  0.1339,  ..., -0.0057,  0.1401,  0.1123],\n",
       "         [-0.0997, -0.0710,  0.0539,  ...,  0.1172, -0.0910,  0.0137],\n",
       "         [ 0.0143,  0.0289,  0.0607,  ..., -0.0912,  0.1207, -0.0338],\n",
       "         ...,\n",
       "         [-0.1269, -0.0251,  0.0079,  ...,  0.0447, -0.0435,  0.0826],\n",
       "         [ 0.0194, -0.1375, -0.0310,  ..., -0.0759,  0.0080, -0.0620],\n",
       "         [ 0.1200,  0.1217,  0.0238,  ..., -0.0383,  0.0391, -0.0288]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.state_self_attn.to_kv.weight': tensor([[ 0.0159, -0.1189,  0.0352,  ...,  0.1066,  0.0038,  0.0432],\n",
       "         [ 0.0161,  0.0502, -0.1263,  ...,  0.0663,  0.0298,  0.1339],\n",
       "         [ 0.1116, -0.0466, -0.0785,  ..., -0.1009, -0.1156, -0.0061],\n",
       "         ...,\n",
       "         [ 0.1197,  0.0012,  0.0970,  ...,  0.1360,  0.1074,  0.0569],\n",
       "         [-0.1398, -0.1302,  0.0654,  ...,  0.0568,  0.0875, -0.1215],\n",
       "         [ 0.0388,  0.0879,  0.1348,  ...,  0.0440, -0.1142, -0.0557]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.state_self_attn.to_out.weight': tensor([[-0.0281,  0.0153,  0.0278,  ..., -0.0355,  0.0362, -0.0236],\n",
       "         [-0.0184,  0.0442, -0.0260,  ..., -0.0136,  0.0306,  0.0413],\n",
       "         [-0.0041, -0.0260,  0.0176,  ..., -0.0016, -0.0053,  0.0014],\n",
       "         ...,\n",
       "         [-0.0279,  0.0147, -0.0167,  ...,  0.0432, -0.0430,  0.0179],\n",
       "         [-0.0221,  0.0242, -0.0205,  ...,  0.0112,  0.0004, -0.0342],\n",
       "         [ 0.0278,  0.0143, -0.0407,  ...,  0.0176,  0.0441,  0.0110]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.state_self_attn.to_out.bias': tensor([ 0.0369, -0.0088,  0.0279, -0.0188,  0.0360,  0.0348, -0.0282, -0.0353,\n",
       "         -0.0363, -0.0024,  0.0027,  0.0196, -0.0149,  0.0156,  0.0262,  0.0401,\n",
       "          0.0147, -0.0343, -0.0119,  0.0244,  0.0215, -0.0033, -0.0040,  0.0135,\n",
       "          0.0164,  0.0384, -0.0336, -0.0065,  0.0313,  0.0385,  0.0231,  0.0160,\n",
       "          0.0238,  0.0068,  0.0316,  0.0283, -0.0387, -0.0271,  0.0220, -0.0016,\n",
       "         -0.0175, -0.0270,  0.0171,  0.0041,  0.0245, -0.0104,  0.0235, -0.0105,\n",
       "         -0.0142,  0.0223], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.input_state_cross_attn.norm.g': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.input_state_cross_attn.to_q.weight': tensor([[ 0.0476,  0.1114, -0.1199,  ...,  0.1261,  0.0922, -0.0414],\n",
       "         [-0.0171, -0.0760,  0.1127,  ...,  0.0624, -0.1394, -0.0828],\n",
       "         [-0.1052,  0.0991, -0.0830,  ...,  0.0477,  0.0635, -0.1289],\n",
       "         ...,\n",
       "         [ 0.0592, -0.0628, -0.0765,  ...,  0.0360, -0.0651,  0.1248],\n",
       "         [-0.0747,  0.0906, -0.0040,  ...,  0.0744, -0.0202,  0.0776],\n",
       "         [ 0.0507, -0.0641,  0.1310,  ..., -0.1384,  0.0817, -0.0456]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.input_state_cross_attn.to_kv.weight': tensor([[-1.3650e-01, -4.8742e-02, -8.2434e-02,  ..., -6.5501e-02,\n",
       "          -3.1865e-02, -3.8758e-02],\n",
       "         [-4.0367e-02,  2.3892e-03,  6.5167e-02,  ..., -1.2878e-01,\n",
       "          -1.2535e-01,  6.5947e-02],\n",
       "         [ 6.8275e-02, -2.6133e-02, -9.3549e-05,  ..., -8.6920e-02,\n",
       "           5.4597e-02,  1.0974e-01],\n",
       "         ...,\n",
       "         [ 1.0805e-01, -1.0999e-01, -1.0442e-01,  ..., -6.6457e-02,\n",
       "          -1.1350e-02, -1.1312e-02],\n",
       "         [-8.3168e-02, -4.5475e-02, -1.4002e-01,  ..., -1.9852e-02,\n",
       "           2.2722e-02, -1.7258e-02],\n",
       "         [-7.2751e-02,  3.5793e-02, -1.4097e-01,  ...,  1.2685e-01,\n",
       "          -1.2113e-01, -5.0748e-02]], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.input_state_cross_attn.to_out.weight': tensor([[ 0.0367, -0.0037,  0.0062,  ..., -0.0015, -0.0114,  0.0432],\n",
       "         [ 0.0143,  0.0274, -0.0353,  ...,  0.0120, -0.0330, -0.0303],\n",
       "         [ 0.0281, -0.0357, -0.0432,  ..., -0.0383,  0.0379, -0.0135],\n",
       "         ...,\n",
       "         [ 0.0256, -0.0042,  0.0199,  ...,  0.0224,  0.0023, -0.0441],\n",
       "         [-0.0338,  0.0178,  0.0167,  ..., -0.0391,  0.0012,  0.0426],\n",
       "         [ 0.0093, -0.0001, -0.0214,  ..., -0.0223,  0.0287,  0.0160]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.input_state_cross_attn.to_out.bias': tensor([ 3.4704e-03, -4.2829e-03, -3.4043e-02, -2.2868e-01, -1.4587e-02,\n",
       "         -1.4250e-01,  9.0711e-02,  1.2325e-01,  7.0360e-02, -1.1272e-02,\n",
       "          1.7464e-01, -6.1105e-02, -2.2793e-01, -1.4475e-01, -4.0750e-03,\n",
       "          1.7460e-03,  3.3385e-03, -4.2267e-04,  5.7796e-02, -1.8755e-01,\n",
       "          3.2090e-03, -4.0999e-02,  1.1849e-01, -1.6974e-01,  8.1259e-02,\n",
       "          2.4297e-01, -6.2029e-02,  2.3162e-01,  1.0981e-01, -1.1441e-01,\n",
       "          2.4641e-01,  1.9183e-01,  1.9219e-02, -1.0377e-01,  1.7264e-01,\n",
       "          1.5936e-01, -1.3871e-01,  1.8455e-01,  7.6663e-02, -2.3528e-04,\n",
       "         -5.4097e-03, -4.0795e-03,  7.2892e-03, -5.7344e-03,  1.7795e-01,\n",
       "          5.4601e-04, -6.4439e-02, -6.1453e-03, -2.9292e-03,  1.3219e-03],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.state_input_cross_attn.norm.g': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.state_input_cross_attn.to_q.weight': tensor([[-0.0236,  0.0505, -0.0191,  ...,  0.0829,  0.0553, -0.0072],\n",
       "         [ 0.0141, -0.1268, -0.0145,  ..., -0.0120,  0.0464,  0.0248],\n",
       "         [ 0.0194,  0.1312, -0.0522,  ..., -0.0575,  0.0604, -0.1185],\n",
       "         ...,\n",
       "         [ 0.1363,  0.0607, -0.0392,  ..., -0.0145, -0.0285,  0.1302],\n",
       "         [ 0.0429, -0.0992,  0.0927,  ...,  0.0474,  0.0347,  0.1030],\n",
       "         [ 0.0039, -0.0128, -0.1217,  ...,  0.1321, -0.0446,  0.1321]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.state_input_cross_attn.to_kv.weight': tensor([[ 0.1237, -0.1369, -0.1042,  ...,  0.1033,  0.0462, -0.0021],\n",
       "         [-0.0899, -0.0094,  0.1074,  ...,  0.0752, -0.0245,  0.0885],\n",
       "         [-0.0558,  0.0508,  0.1231,  ...,  0.1373,  0.0208,  0.0523],\n",
       "         ...,\n",
       "         [ 0.0038, -0.0978,  0.0962,  ...,  0.0282, -0.0587, -0.0342],\n",
       "         [ 0.0831,  0.0712,  0.0255,  ...,  0.1032,  0.0058, -0.0245],\n",
       "         [-0.0424,  0.0337,  0.1219,  ...,  0.0236,  0.0346,  0.1033]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.state_input_cross_attn.to_out.weight': tensor([[ 0.0096, -0.0005,  0.0224,  ...,  0.0086, -0.0038, -0.0391],\n",
       "         [ 0.0030,  0.0309,  0.0349,  ...,  0.0310, -0.0341, -0.0130],\n",
       "         [ 0.0294, -0.0156, -0.0183,  ..., -0.0287,  0.0016, -0.0387],\n",
       "         ...,\n",
       "         [ 0.0105,  0.0011,  0.0086,  ..., -0.0365,  0.0274,  0.0362],\n",
       "         [-0.0218, -0.0281,  0.0238,  ...,  0.0386, -0.0403,  0.0146],\n",
       "         [-0.0256,  0.0159, -0.0096,  ...,  0.0261,  0.0096, -0.0092]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.state_input_cross_attn.to_out.bias': tensor([ 0.0037,  0.0317, -0.0398,  0.0095, -0.0289, -0.0327, -0.0312,  0.0306,\n",
       "         -0.0060,  0.0318,  0.0341,  0.0363,  0.0402,  0.0008,  0.0131,  0.0120,\n",
       "          0.0247,  0.0182,  0.0188,  0.0082,  0.0148,  0.0433, -0.0224,  0.0103,\n",
       "          0.0437, -0.0195, -0.0304, -0.0072,  0.0107, -0.0063, -0.0386,  0.0093,\n",
       "         -0.0053,  0.0397, -0.0300,  0.0215, -0.0288,  0.0057, -0.0306, -0.0079,\n",
       "          0.0042, -0.0307,  0.0421,  0.0404, -0.0300,  0.0105,  0.0059, -0.0355,\n",
       "         -0.0129,  0.0079], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.proj_gate.main_proj.weight': tensor([[-0.0377, -0.0089, -0.0446,  ..., -0.1366,  0.0901, -0.0584],\n",
       "         [ 0.0002,  0.1255, -0.1217,  ...,  0.0886,  0.0859, -0.1284],\n",
       "         [ 0.0179, -0.0880,  0.1071,  ...,  0.1382,  0.1186, -0.0836],\n",
       "         ...,\n",
       "         [ 0.0675, -0.1061, -0.0088,  ..., -0.1211,  0.0489,  0.0861],\n",
       "         [-0.1279,  0.0178,  0.0354,  ...,  0.0213,  0.0699,  0.0187],\n",
       "         [-0.0759, -0.0368, -0.1318,  ...,  0.0769, -0.1199,  0.0568]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.proj_gate.main_proj.bias': tensor([-0.0692, -0.0079,  0.1028,  0.1297, -0.0431, -0.0091,  0.1096,  0.0975,\n",
       "         -0.1341, -0.1136,  0.1076, -0.0644,  0.1077, -0.0819,  0.1013,  0.0294,\n",
       "          0.0535, -0.0382, -0.0002, -0.0533, -0.1378, -0.0212, -0.0599,  0.1395,\n",
       "          0.0773, -0.0906,  0.0643,  0.0151, -0.0965,  0.0604,  0.0049, -0.1087,\n",
       "         -0.0331, -0.0317,  0.0222, -0.0550, -0.0495, -0.0730, -0.1108,  0.0591,\n",
       "         -0.1288,  0.0345,  0.1263, -0.0853, -0.1084, -0.0569,  0.1243,  0.1035,\n",
       "         -0.0299, -0.1305], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.proj_gate.input_proj.weight': tensor([[-0.0735, -0.0290,  0.0323,  ..., -0.0160, -0.0283,  0.0575],\n",
       "         [ 0.0353, -0.0407, -0.0064,  ...,  0.0765,  0.0410, -0.0762],\n",
       "         [ 0.0967,  0.0009,  0.1210,  ...,  0.1108, -0.1008,  0.0091],\n",
       "         ...,\n",
       "         [ 0.0291,  0.1077, -0.0344,  ..., -0.0525, -0.0297,  0.1378],\n",
       "         [-0.0541,  0.1331, -0.0970,  ...,  0.0471, -0.0987,  0.1057],\n",
       "         [-0.1079, -0.0684, -0.0768,  ...,  0.1326,  0.0422,  0.0692]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.proj_gate.input_proj.bias': tensor([-0.0839, -0.0289,  0.1026,  0.0661, -0.0167,  0.0185, -0.1032, -0.0126,\n",
       "          0.1089, -0.1308, -0.0023, -0.1005, -0.0223, -0.1357, -0.0731, -0.1174,\n",
       "         -0.0979,  0.1359, -0.0511, -0.0380, -0.0605,  0.0456,  0.0519, -0.0807,\n",
       "         -0.0165,  0.0366, -0.0283,  0.0878,  0.0972, -0.0867,  0.1221, -0.0781,\n",
       "         -0.0824,  0.1367, -0.0250,  0.0551,  0.1104, -0.1287, -0.1104,  0.0401,\n",
       "         -0.0445, -0.1199,  0.1231,  0.0975,  0.0180, -0.0067, -0.1271, -0.0846,\n",
       "         -0.0026,  0.0717], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.proj_gate.forget_proj.weight': tensor([[-0.0123,  0.0263, -0.1301,  ...,  0.0584, -0.1026, -0.0809],\n",
       "         [-0.1008, -0.0960,  0.0178,  ..., -0.0397,  0.0182,  0.0518],\n",
       "         [-0.0722, -0.0527, -0.0688,  ..., -0.0315,  0.0030, -0.0084],\n",
       "         ...,\n",
       "         [-0.0008, -0.0277, -0.1346,  ..., -0.0211,  0.1403, -0.0485],\n",
       "         [-0.1277,  0.0168, -0.1314,  ..., -0.0505,  0.0447,  0.1215],\n",
       "         [-0.0744, -0.1387,  0.0698,  ...,  0.1201, -0.0234,  0.0655]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.proj_gate.forget_proj.bias': tensor([-0.0878,  0.0854,  0.0494,  0.0275,  0.0178,  0.0459,  0.0074, -0.0316,\n",
       "         -0.1354,  0.0101, -0.0389, -0.0908, -0.0868, -0.0126,  0.1370, -0.1196,\n",
       "          0.0064, -0.0949,  0.1402,  0.1023, -0.1083, -0.1368,  0.1372, -0.1388,\n",
       "         -0.0400, -0.1054,  0.0919, -0.1001,  0.0115,  0.1034,  0.0555, -0.1408,\n",
       "         -0.0515,  0.0850, -0.0640,  0.0039, -0.0157,  0.0008,  0.1243,  0.0858,\n",
       "          0.0200, -0.0439,  0.1176,  0.1055,  0.1232,  0.0861, -0.0580,  0.0846,\n",
       "          0.0878,  0.0611], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.ff_gate.main_proj.weight': tensor([[ 0.0931, -0.1367, -0.0617,  ...,  0.0449, -0.0614,  0.0381],\n",
       "         [ 0.0405,  0.0848,  0.1278,  ...,  0.0710, -0.0803, -0.0099],\n",
       "         [ 0.0042, -0.0863,  0.0122,  ..., -0.1181, -0.0495,  0.1213],\n",
       "         ...,\n",
       "         [ 0.0951, -0.1112,  0.0369,  ...,  0.0452, -0.0764, -0.0719],\n",
       "         [-0.0677,  0.1364,  0.1147,  ...,  0.1133,  0.0219, -0.1003],\n",
       "         [ 0.0350, -0.1038,  0.0003,  ..., -0.1080, -0.1376, -0.1167]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.ff_gate.main_proj.bias': tensor([ 0.1051, -0.1185,  0.0255,  0.0267,  0.0876, -0.0282, -0.0684, -0.0343,\n",
       "          0.0115, -0.1363, -0.1172,  0.0239, -0.1074, -0.0027, -0.0717,  0.0859,\n",
       "         -0.0663,  0.0960,  0.0567,  0.0694, -0.1062, -0.1039,  0.0954, -0.0448,\n",
       "          0.0123,  0.0348,  0.0435,  0.0857,  0.1185,  0.1130, -0.0744,  0.0564,\n",
       "         -0.0954,  0.0577,  0.0961, -0.0367, -0.0364,  0.0911, -0.1067,  0.0674,\n",
       "          0.0766,  0.1244, -0.0322,  0.1075,  0.1106, -0.0660,  0.0548,  0.1398,\n",
       "         -0.1289, -0.0776], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.ff_gate.input_proj.weight': tensor([[-0.0009,  0.0602, -0.0103,  ...,  0.0156,  0.0714, -0.0990],\n",
       "         [ 0.0559, -0.0503,  0.0872,  ..., -0.0842, -0.0852,  0.0267],\n",
       "         [-0.1067,  0.0843, -0.0153,  ...,  0.1169, -0.1071,  0.0378],\n",
       "         ...,\n",
       "         [ 0.1285,  0.0478,  0.0564,  ..., -0.1212,  0.0987, -0.0060],\n",
       "         [ 0.0131,  0.0325, -0.1095,  ...,  0.0101,  0.1390, -0.1058],\n",
       "         [ 0.1048,  0.0633,  0.0037,  ...,  0.1177,  0.0280, -0.0490]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.ff_gate.input_proj.bias': tensor([-0.0523, -0.1287, -0.0300, -0.0683,  0.1105, -0.1228,  0.0184,  0.1354,\n",
       "         -0.1225, -0.0649,  0.0060, -0.0915,  0.0199, -0.0121, -0.1298,  0.1014,\n",
       "          0.0515,  0.0287, -0.0102, -0.0150,  0.0294,  0.1336,  0.0431, -0.0603,\n",
       "         -0.0280,  0.0766, -0.1390, -0.1030, -0.0415, -0.0269,  0.1384,  0.0363,\n",
       "          0.0940,  0.0830, -0.0212,  0.0065, -0.0437, -0.1367, -0.0903, -0.1129,\n",
       "         -0.0232,  0.0272, -0.0163, -0.1204,  0.1402, -0.0086, -0.0263, -0.0120,\n",
       "          0.0725,  0.0344], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.ff_gate.forget_proj.weight': tensor([[-0.0887, -0.0020, -0.0656,  ..., -0.0189,  0.0335,  0.0461],\n",
       "         [-0.0935, -0.1009, -0.0715,  ...,  0.0653, -0.0475,  0.0176],\n",
       "         [ 0.0156, -0.1285, -0.0587,  ...,  0.0062,  0.0825,  0.0121],\n",
       "         ...,\n",
       "         [ 0.0823, -0.1311, -0.0218,  ..., -0.0957, -0.1197, -0.0372],\n",
       "         [-0.1033,  0.1076, -0.0761,  ..., -0.1270, -0.0385,  0.0565],\n",
       "         [ 0.0255, -0.1242,  0.0509,  ..., -0.0227, -0.0755, -0.1408]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.ff_gate.forget_proj.bias': tensor([-0.0276, -0.0539, -0.0893, -0.0253,  0.0935,  0.1031, -0.0227,  0.0177,\n",
       "          0.0168, -0.0983, -0.0214,  0.0856, -0.0171, -0.0240,  0.0592, -0.0440,\n",
       "         -0.0809, -0.0201, -0.0507,  0.0685,  0.0345, -0.1017, -0.1169,  0.0170,\n",
       "         -0.0338, -0.1210,  0.0842,  0.0910,  0.0328,  0.0648,  0.0791,  0.1023,\n",
       "          0.0961,  0.1223, -0.1234,  0.0276, -0.0477, -0.0466, -0.1372, -0.1412,\n",
       "          0.0769,  0.1016,  0.1237,  0.0004,  0.0885,  0.0433,  0.0787,  0.1089,\n",
       "          0.0983, -0.0048], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.input_proj.weight': tensor([[-0.0111, -0.0540,  0.1297,  ..., -0.0348,  0.0329, -0.0589],\n",
       "         [-0.0559, -0.0071,  0.0604,  ..., -0.0647,  0.0635,  0.0039],\n",
       "         [-0.0196,  0.0383,  0.0457,  ...,  0.0381,  0.0334,  0.0429],\n",
       "         ...,\n",
       "         [ 0.0571, -0.0372,  0.1006,  ..., -0.0550,  0.0337, -0.0076],\n",
       "         [ 0.0400, -0.1148, -0.6453,  ..., -0.0271,  0.0228, -0.0125],\n",
       "         [-0.0346,  0.0423,  0.1007,  ..., -0.0185,  0.0297,  0.0373]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.state_proj.weight': tensor([[ 0.0245, -0.0048, -0.0315,  ...,  0.0751, -0.0810, -0.0098],\n",
       "         [ 0.0853, -0.0296, -0.0291,  ...,  0.0457, -0.0160,  0.0044],\n",
       "         [-0.0433, -0.0626,  0.0152,  ..., -0.0771, -0.0640, -0.0035],\n",
       "         ...,\n",
       "         [-0.0689,  0.0649,  0.0046,  ...,  0.0905, -0.0199, -0.0047],\n",
       "         [ 0.0748,  0.0748, -0.0585,  ..., -0.0937, -0.0088, -0.0584],\n",
       "         [-0.0280, -0.0241, -0.0753,  ..., -0.0158,  0.0744, -0.0101]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.input_ff.ff.0.0.weight': tensor([[ 0.0333,  0.0044, -0.1342,  ..., -0.0513, -0.1459,  0.1908],\n",
       "         [ 0.3165, -0.0338, -0.1291,  ..., -0.0563,  0.0328, -0.1626],\n",
       "         [ 0.1715,  0.0484, -0.0402,  ...,  0.0006, -0.0816, -0.1293],\n",
       "         ...,\n",
       "         [ 0.2041,  0.0820, -0.1386,  ..., -0.2586, -0.0718, -0.0559],\n",
       "         [-0.0285, -0.0502,  0.0770,  ..., -0.0899, -0.2890,  0.0398],\n",
       "         [ 0.1636,  0.2238,  0.2211,  ..., -0.0218, -0.1398,  0.0438]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.input_ff.ff.0.0.bias': tensor([-0.3067, -0.3838, -0.1439, -0.0731, -0.3160, -0.1979, -0.3130, -0.1554,\n",
       "         -0.0294, -0.3795, -0.2424, -0.2946, -0.2711, -0.3579, -0.3307, -0.1211,\n",
       "         -0.1159, -0.0876, -0.2435, -0.2288, -0.1808, -0.1759,  0.0006, -0.2594,\n",
       "         -0.2142, -0.0077, -0.2180, -0.3289,  0.0459, -0.3297, -0.2198, -0.2045,\n",
       "         -0.1682, -0.1356, -0.2195, -0.1278, -0.1164, -0.1941, -0.0763, -0.2737,\n",
       "         -0.3678, -0.1026, -0.2210, -0.3177, -0.1638, -0.1154, -0.1177, -0.2064,\n",
       "         -0.1257, -0.1523, -0.2218, -0.3042, -0.2431, -0.1557, -0.3133, -0.2502,\n",
       "         -0.2118, -0.3045, -0.1974, -0.2183, -0.3321, -0.2772, -0.4246, -0.1656,\n",
       "         -0.2809, -0.0328, -0.3158, -0.0149, -0.2893, -0.3026, -0.2886, -0.1325,\n",
       "         -0.2640, -0.3496, -0.2182, -0.4322, -0.3144, -0.3416, -0.4620, -0.1354,\n",
       "         -0.3766, -0.2819, -0.3050, -0.1460, -0.2644, -0.1498, -0.2016, -0.3952,\n",
       "         -0.2148, -0.2777, -0.0304, -0.2358, -0.2267, -0.0556, -0.1487, -0.1074,\n",
       "         -0.1054, -0.0706, -0.3451, -0.1343, -0.1865, -0.1500, -0.1928, -0.1936,\n",
       "         -0.0784, -0.2536, -0.0974, -0.2319, -0.2751, -0.2470, -0.1301, -0.0860,\n",
       "         -0.1939, -0.3159, -0.3326, -0.2302, -0.1014, -0.3948, -0.2511, -0.2618,\n",
       "         -0.2950, -0.1010, -0.0814, -0.2005, -0.1964, -0.0911, -0.2297, -0.1010,\n",
       "         -0.1063, -0.2505, -0.0045, -0.1195, -0.2319, -0.1603, -0.3284, -0.3605,\n",
       "         -0.1039, -0.2544, -0.2263, -0.1252, -0.2105, -0.2275, -0.1559, -0.2510,\n",
       "         -0.1605, -0.2519, -0.3915, -0.3403, -0.2925, -0.2775, -0.2633,  0.0499,\n",
       "          0.0103, -0.2006, -0.0648, -0.0981, -0.2064, -0.3226, -0.3283, -0.1118,\n",
       "         -0.1297, -0.1879, -0.1439, -0.0988, -0.2776, -0.1669, -0.3245, -0.1778,\n",
       "         -0.2197, -0.1652, -0.0640, -0.2509, -0.0071, -0.2776, -0.0920, -0.1238,\n",
       "         -0.0470, -0.1569, -0.0256, -0.3069, -0.2597, -0.2008, -0.0892, -0.3052,\n",
       "         -0.3276, -0.1480, -0.1867, -0.2630, -0.3480,  0.0333, -0.3112, -0.2076,\n",
       "         -0.1220, -0.1390, -0.0248, -0.1193, -0.2882, -0.2641, -0.2962, -0.3801],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.input_ff.ff.2.weight': tensor([[ 0.1227,  0.0559,  0.0339,  ...,  0.0748,  0.0437,  0.0737],\n",
       "         [ 0.0828,  0.0582, -0.0342,  ..., -0.0719, -0.0816, -0.1855],\n",
       "         [-0.0250, -0.0992, -0.0392,  ...,  0.3006, -0.0068,  0.0875],\n",
       "         ...,\n",
       "         [-0.0456, -0.0490,  0.0169,  ...,  0.1907, -0.0065, -0.4050],\n",
       "         [-0.0809, -0.1478,  0.0044,  ...,  0.0296, -0.1540,  0.3631],\n",
       "         [-0.0700,  0.1070, -0.0435,  ..., -0.0380,  0.0208, -0.0198]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.input_ff.ff.2.bias': tensor([ 0.0395,  0.2455, -0.2102, -0.0670, -0.0821, -0.0880, -0.1594,  0.0067,\n",
       "         -0.0143, -0.2002,  0.1323, -0.1445,  0.0939,  0.0746,  0.0015,  0.1527,\n",
       "         -0.0725,  0.1094, -0.1641, -0.1816, -0.0661,  0.1414, -0.0327,  0.0320,\n",
       "         -0.0300, -0.0487, -0.1809,  0.1640,  0.1601, -0.0097, -0.0066,  0.0935,\n",
       "         -0.4065,  0.4227,  0.0260, -0.0475, -0.1554,  0.3875,  0.1064, -0.0320,\n",
       "          0.0436,  0.1341,  0.0930, -0.0992, -0.1046, -0.1118, -0.2340,  0.0707,\n",
       "          0.7940, -0.1507], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.state_ff.ff.0.0.weight': tensor([[ 0.0863,  0.0297, -0.0625,  ...,  0.0270,  0.1018,  0.1289],\n",
       "         [ 0.0795, -0.1214, -0.0775,  ...,  0.1254, -0.0202, -0.0754],\n",
       "         [ 0.0246, -0.1341,  0.0832,  ...,  0.0311, -0.1354,  0.0036],\n",
       "         ...,\n",
       "         [-0.1380, -0.0018,  0.0298,  ...,  0.0517, -0.0983,  0.0314],\n",
       "         [-0.0831, -0.0212,  0.1142,  ..., -0.0412, -0.0196,  0.0728],\n",
       "         [ 0.0961,  0.0912,  0.0530,  ..., -0.1368,  0.0419, -0.0907]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.state_ff.ff.0.0.bias': tensor([ 0.0279,  0.1219,  0.0024,  0.0039, -0.0574, -0.1399, -0.0931, -0.0534,\n",
       "         -0.0889, -0.0535, -0.0684, -0.1341,  0.0741,  0.0451,  0.0635,  0.0520,\n",
       "         -0.1098, -0.0821,  0.0696, -0.0590, -0.0177,  0.0151, -0.1041, -0.0842,\n",
       "         -0.0291,  0.0930,  0.1204,  0.1071, -0.1106,  0.1315,  0.0913,  0.0829,\n",
       "          0.0966, -0.0090, -0.0509, -0.0464,  0.0229,  0.0087,  0.0956, -0.0927,\n",
       "          0.0384, -0.1333,  0.0321,  0.1206, -0.0473,  0.1161, -0.1365,  0.0986,\n",
       "          0.0249, -0.0915,  0.0588,  0.1333,  0.1347, -0.1260,  0.0948, -0.1174,\n",
       "         -0.1334, -0.1123,  0.0088,  0.1103, -0.1275,  0.0434,  0.1228,  0.1175,\n",
       "         -0.0453,  0.0798,  0.0309, -0.0746,  0.1120, -0.0471, -0.1345, -0.0304,\n",
       "         -0.1177,  0.0812,  0.0267,  0.0096,  0.0566,  0.0639, -0.0779, -0.1253,\n",
       "         -0.1279,  0.0482,  0.1145,  0.0889,  0.0576,  0.1379,  0.0174, -0.0148,\n",
       "          0.0370,  0.0460,  0.0639, -0.1373,  0.1150, -0.0159, -0.0074, -0.1309,\n",
       "         -0.0966,  0.0227,  0.0849,  0.1355,  0.0601, -0.1400,  0.1023,  0.0727,\n",
       "         -0.0554,  0.0676,  0.0710,  0.0912, -0.0928, -0.0625, -0.0953, -0.0404,\n",
       "         -0.0250, -0.1088, -0.0737, -0.0440,  0.0680, -0.0753,  0.0020,  0.1349,\n",
       "          0.0720,  0.1049,  0.0855,  0.0330, -0.1000, -0.0161, -0.0914, -0.0910,\n",
       "         -0.1292,  0.0181, -0.0483,  0.1165, -0.0926, -0.1368,  0.0298,  0.1064,\n",
       "         -0.0346,  0.1068,  0.1076, -0.1301, -0.0562,  0.0081,  0.0199,  0.0736,\n",
       "          0.0171, -0.0946,  0.0591, -0.0787, -0.0323,  0.0008, -0.1134, -0.0137,\n",
       "         -0.0911, -0.0902, -0.0464,  0.1160, -0.1352,  0.0660,  0.0125, -0.0043,\n",
       "         -0.0439, -0.0211, -0.0783,  0.0566,  0.0904, -0.1229, -0.1148,  0.0963,\n",
       "          0.0498,  0.0012,  0.0273, -0.1125,  0.0624,  0.0231, -0.0193, -0.1155,\n",
       "         -0.0502,  0.0770, -0.0182,  0.1012,  0.0839, -0.0762, -0.0696,  0.0832,\n",
       "         -0.0110, -0.0415,  0.0683, -0.0664,  0.0129,  0.0089,  0.0184,  0.0665,\n",
       "          0.0459,  0.0725,  0.0712,  0.0341, -0.0537,  0.1193,  0.0932, -0.0136],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.state_ff.ff.2.weight': tensor([[-0.0284,  0.0465, -0.0102,  ..., -0.0604,  0.0147, -0.0653],\n",
       "         [ 0.0135,  0.0275,  0.0478,  ..., -0.0218, -0.0404,  0.0019],\n",
       "         [ 0.0047,  0.0140, -0.0563,  ...,  0.0068,  0.0099,  0.0343],\n",
       "         ...,\n",
       "         [-0.0071, -0.0274, -0.0270,  ...,  0.0200, -0.0172, -0.0193],\n",
       "         [ 0.0302,  0.0586, -0.0162,  ...,  0.0619, -0.0204, -0.0029],\n",
       "         [-0.0525,  0.0265,  0.0401,  ...,  0.0276,  0.0152,  0.0521]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.self_attn.state_ff.ff.2.bias': tensor([ 0.0399, -0.0665, -0.0058,  0.0680,  0.0194,  0.0278,  0.0011,  0.0100,\n",
       "          0.0627, -0.0381, -0.0687,  0.0146, -0.0145, -0.0096, -0.0537, -0.0288,\n",
       "         -0.0531,  0.0326, -0.0414,  0.0179,  0.0437, -0.0431,  0.0302, -0.0663,\n",
       "          0.0434,  0.0586, -0.0355,  0.0640,  0.0126,  0.0509,  0.0287, -0.0337,\n",
       "         -0.0013, -0.0315,  0.0045,  0.0693, -0.0093,  0.0477, -0.0478,  0.0343,\n",
       "          0.0602,  0.0359,  0.0552, -0.0192,  0.0511, -0.0077,  0.0520, -0.0286,\n",
       "          0.0431, -0.0404], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.feed_forward.bn.weight': tensor([0.7962, 0.9576, 1.0551, 0.9754, 0.8701, 1.0280, 0.9505, 0.7773, 0.7324,\n",
       "         0.7765, 0.8742, 1.0015, 0.7965, 0.5887, 0.8790, 1.0013, 0.7199, 0.9508,\n",
       "         0.6551, 0.7549, 0.7474, 0.8316, 0.5840, 0.7197, 0.8520, 0.7959, 0.7360,\n",
       "         0.8510, 0.9188, 0.6734, 0.8686, 0.6649, 1.7361, 1.7083, 0.5312, 0.8503,\n",
       "         0.5571, 1.0185, 0.9740, 0.8201, 0.8660, 1.6706, 0.8125, 0.8108, 0.8886,\n",
       "         1.1160, 0.5156, 0.6759, 2.3206, 0.6929], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.feed_forward.bn.bias': tensor([-0.1012, -0.0529, -0.2256,  0.0394, -0.1129, -0.0914,  0.4904, -0.0625,\n",
       "          0.0251, -0.0703, -0.1996, -0.0592, -0.1854, -0.0618,  0.1269,  0.0517,\n",
       "         -0.1826,  0.0074, -0.0124, -0.0050,  0.0126, -0.0577, -0.1170, -0.1048,\n",
       "          0.0261,  0.0948,  0.1066, -0.0520,  0.1303,  0.1141,  0.0305, -0.1866,\n",
       "         -1.2155,  0.6715,  0.0446, -0.1617, -0.0451,  0.1188,  0.1379,  0.4155,\n",
       "         -0.0332,  0.1092,  0.1447, -0.3520,  0.0911,  0.1800, -0.0481, -0.0851,\n",
       "          1.7264,  0.0956], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.feed_forward.bn.running_mean': tensor([ 1.1865,  0.5555,  0.3706,  1.8302,  1.0669,  0.1632,  0.0198,  1.3408,\n",
       "          0.7751,  1.2272,  0.2091,  0.0822,  0.6517,  1.0441, -0.2579,  0.2390,\n",
       "          2.2870,  0.8976,  1.0473,  2.7170,  1.2608,  0.4965,  1.3179,  0.3588,\n",
       "          1.9416,  0.8120,  0.0443,  0.9470,  0.6514,  0.6098,  3.0201,  1.3396,\n",
       "          0.8961,  0.9917,  0.8540,  1.3210,  0.6841,  0.5869,  0.5387,  0.2279,\n",
       "         -0.1538,  0.0381,  2.0327,  1.1483,  0.8730, -0.4093,  0.8591,  0.3896,\n",
       "         -0.3709,  0.8855], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.feed_forward.bn.running_var': tensor([ 6.8084,  5.3027,  4.3511, 11.3277,  7.3803,  3.9148,  1.9169,  8.7623,\n",
       "          6.5272,  7.6593,  4.8809,  3.2954,  4.5308,  7.6315,  1.8818,  3.9361,\n",
       "         13.0465,  7.3287,  6.3048, 10.2086,  7.1480,  3.8989,  6.0350,  4.9985,\n",
       "         13.8613,  5.5117,  3.0909,  7.6262,  4.6751,  5.6403, 15.9147,  7.8854,\n",
       "          2.7342,  6.5974,  3.6807,  9.7738,  6.4938,  6.0859,  4.7071,  3.2265,\n",
       "          3.0889,  3.7892, 10.4989,  8.9408,  7.6227,  1.3053,  6.0082,  3.7183,\n",
       "          0.4141,  6.9788], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.feed_forward.bn.num_batches_tracked': tensor(213030),\n",
       " 'transformer_rec.model.layers.1.feed_forward.encoder_0.weight': tensor([[[-0.0821],\n",
       "          [-0.0942],\n",
       "          [-0.2317],\n",
       "          ...,\n",
       "          [-0.1022],\n",
       "          [ 0.3213],\n",
       "          [ 0.0135]],\n",
       " \n",
       "         [[-0.0440],\n",
       "          [ 0.3672],\n",
       "          [ 0.2356],\n",
       "          ...,\n",
       "          [ 0.0475],\n",
       "          [-0.2808],\n",
       "          [ 0.0396]],\n",
       " \n",
       "         [[ 0.2126],\n",
       "          [-0.2236],\n",
       "          [ 0.1136],\n",
       "          ...,\n",
       "          [-0.1247],\n",
       "          [ 0.0497],\n",
       "          [ 0.0117]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.0509],\n",
       "          [ 0.2153],\n",
       "          [-0.0767],\n",
       "          ...,\n",
       "          [ 0.0289],\n",
       "          [ 0.1098],\n",
       "          [-0.0976]],\n",
       " \n",
       "         [[-0.1313],\n",
       "          [ 0.0381],\n",
       "          [ 0.1473],\n",
       "          ...,\n",
       "          [-0.1793],\n",
       "          [-0.4988],\n",
       "          [-0.1007]],\n",
       " \n",
       "         [[ 0.0915],\n",
       "          [-0.0944],\n",
       "          [ 0.0039],\n",
       "          ...,\n",
       "          [-0.6296],\n",
       "          [-0.0245],\n",
       "          [ 0.4335]]], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.feed_forward.encoder_0.bias': tensor([-0.0890, -0.4100, -0.0489, -0.1517, -0.1420, -0.1202,  0.2849,  0.0204,\n",
       "         -0.0326,  0.0210, -0.2306,  0.1219,  0.0879, -0.0297, -0.0841,  0.0095,\n",
       "         -0.0441,  0.0266,  0.0637, -0.0541,  0.0014,  0.2237,  0.0217, -0.2577,\n",
       "          0.0056, -0.1956, -0.0384,  0.0337,  0.2819,  0.1164,  0.0183, -0.3236,\n",
       "         -0.3161, -0.2334,  0.1292, -0.2322, -0.1041,  0.1685, -0.0302, -0.1149,\n",
       "         -0.2412,  0.0126,  0.0663, -0.1162,  0.0206,  0.0438, -0.0675, -0.1752,\n",
       "          0.3194, -0.0179], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.feed_forward.encoder_1.weight': tensor([[[ 1.3524e-01,  1.7471e-01,  3.3166e-01],\n",
       "          [-1.1129e-01, -3.2271e-01, -1.6892e-01],\n",
       "          [-1.5345e-02,  1.0875e-01,  6.0156e-02],\n",
       "          ...,\n",
       "          [-2.4533e-01, -2.6087e-01, -1.7975e-01],\n",
       "          [ 2.0304e-01,  1.7558e-01,  1.3935e-01],\n",
       "          [-6.9463e-02, -8.6534e-02, -1.7853e-01]],\n",
       " \n",
       "         [[-1.1507e-01, -1.5677e-01, -9.7511e-02],\n",
       "          [ 3.4546e-01,  4.1117e-01,  3.1197e-01],\n",
       "          [ 1.3864e-01,  8.3698e-02,  2.0108e-01],\n",
       "          ...,\n",
       "          [ 2.8275e-01,  3.0365e-01,  1.8164e-01],\n",
       "          [-5.0917e-03, -1.7452e-01, -7.6806e-02],\n",
       "          [-4.5279e-03,  7.6763e-02,  1.0228e-01]],\n",
       " \n",
       "         [[ 2.4069e-01,  2.1068e-01,  1.4144e-01],\n",
       "          [-3.3587e-01, -2.9163e-01, -2.1606e-01],\n",
       "          [ 8.5212e-02, -1.3903e-02,  1.3095e-01],\n",
       "          ...,\n",
       "          [-9.2719e-02, -9.6464e-02, -1.3058e-01],\n",
       "          [ 1.3277e-01,  8.8724e-02,  5.0104e-02],\n",
       "          [-1.7231e-01, -6.3423e-02, -3.5792e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-2.7310e-03,  1.2898e-01,  1.1476e-01],\n",
       "          [ 1.3356e-01,  3.7378e-02, -3.0405e-02],\n",
       "          [ 1.2894e-01,  9.2336e-02,  3.3257e-02],\n",
       "          ...,\n",
       "          [ 1.2110e-01,  9.0491e-02,  1.3253e-01],\n",
       "          [ 1.2801e-01,  3.4454e-02,  4.4614e-02],\n",
       "          [ 5.1454e-02,  4.0944e-02, -3.8331e-02]],\n",
       " \n",
       "         [[ 5.0035e-02, -3.1432e-04,  1.9833e-02],\n",
       "          [ 2.0695e-02,  7.4186e-02,  6.3689e-02],\n",
       "          [ 5.9922e-02,  6.2179e-02,  5.0447e-03],\n",
       "          ...,\n",
       "          [-8.2531e-02, -1.6689e-01, -4.2446e-02],\n",
       "          [-2.6986e-01, -6.5222e-01, -7.3223e-02],\n",
       "          [-4.2024e-02, -1.4915e-01, -2.3678e-01]],\n",
       " \n",
       "         [[ 1.4903e-01, -5.2360e-02, -2.6036e-02],\n",
       "          [-5.7161e-02, -3.5486e-02, -1.9739e-01],\n",
       "          [-8.4000e-02, -4.5877e-02, -2.4736e-01],\n",
       "          ...,\n",
       "          [-1.9365e-01, -2.5558e-01, -3.0116e-01],\n",
       "          [-1.0243e-01, -1.7643e-01, -1.8400e-01],\n",
       "          [-4.9814e-02,  4.8722e-02,  8.5051e-02]]], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.feed_forward.encoder_1.bias': tensor([-0.2116, -0.0929, -0.1264,  0.0166, -0.2891, -0.1105, -0.1551, -0.1753,\n",
       "         -0.0963, -0.1829, -0.3137,  0.0286,  0.0159, -0.2437,  0.1152, -0.1731,\n",
       "          0.1600, -0.1156, -0.0374,  0.2981,  0.1329, -0.0023,  0.0543, -0.0366,\n",
       "         -0.0853, -0.0809, -0.2735, -0.1261,  0.0393,  0.0091,  0.0162, -0.1662,\n",
       "          0.0265,  0.1038,  0.0811, -0.1574, -0.0540, -0.1565, -0.0678, -0.0554,\n",
       "         -0.2535,  0.0126,  0.0698, -0.2655, -0.0028, -0.0942,  0.0046,  0.0686,\n",
       "          0.0104, -0.1410], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.feed_forward.encoder_2.weight': tensor([[[ 0.2626,  0.2154,  0.1217,  0.2137,  0.2123],\n",
       "          [-0.1615, -0.1493, -0.1922, -0.1046, -0.0550],\n",
       "          [-0.0016,  0.0485,  0.1256, -0.0027,  0.0372],\n",
       "          ...,\n",
       "          [-0.2638, -0.3235, -0.2377, -0.2545, -0.2920],\n",
       "          [ 0.1425,  0.2317,  0.2226,  0.2340,  0.2631],\n",
       "          [-0.0323, -0.0185, -0.1372, -0.1197, -0.0861]],\n",
       " \n",
       "         [[-0.0244, -0.1299, -0.1359, -0.1656, -0.2119],\n",
       "          [ 0.3617,  0.4114,  0.4167,  0.5198,  0.3286],\n",
       "          [ 0.1243,  0.1198,  0.0229,  0.1726,  0.0270],\n",
       "          ...,\n",
       "          [ 0.2734,  0.2519,  0.3227,  0.3042,  0.0909],\n",
       "          [-0.1491, -0.0742, -0.2092, -0.1119,  0.0506],\n",
       "          [-0.1605, -0.0456,  0.0713,  0.0699,  0.0363]],\n",
       " \n",
       "         [[ 0.3993,  0.3329,  0.1847,  0.2160,  0.2016],\n",
       "          [-0.2809, -0.2826, -0.2595, -0.2557, -0.1105],\n",
       "          [ 0.1102,  0.0528,  0.0475,  0.1334,  0.1957],\n",
       "          ...,\n",
       "          [-0.1527, -0.2037, -0.1288, -0.2145, -0.1899],\n",
       "          [-0.0673,  0.0017,  0.0304,  0.1828,  0.0891],\n",
       "          [-0.0416, -0.0160, -0.0749, -0.0716, -0.0970]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.2373,  0.2345,  0.2429,  0.2207,  0.2116],\n",
       "          [-0.0325,  0.0508,  0.0082, -0.1000, -0.0311],\n",
       "          [ 0.1306,  0.1088,  0.0398,  0.1189,  0.0390],\n",
       "          ...,\n",
       "          [ 0.0179,  0.0665,  0.0977,  0.1193,  0.2073],\n",
       "          [-0.0927, -0.0991, -0.0086, -0.1042, -0.1300],\n",
       "          [-0.2533, -0.2754, -0.2608, -0.2195, -0.3029]],\n",
       " \n",
       "         [[ 0.0420, -0.0204, -0.0245, -0.0065,  0.0366],\n",
       "          [ 0.0294, -0.0816, -0.0386,  0.0032,  0.0313],\n",
       "          [ 0.1500,  0.0531,  0.1169,  0.0976,  0.1236],\n",
       "          ...,\n",
       "          [-0.0516, -0.0563, -0.1502,  0.0362, -0.1163],\n",
       "          [-0.0861, -0.1847, -0.7188, -0.1112, -0.0481],\n",
       "          [-0.0299, -0.0885, -0.1168, -0.2160, -0.2304]],\n",
       " \n",
       "         [[-0.1334, -0.0685, -0.1582, -0.1016, -0.0903],\n",
       "          [-0.1666, -0.1408, -0.1941, -0.1997, -0.0816],\n",
       "          [-0.1641, -0.3331, -0.2883, -0.2795, -0.2754],\n",
       "          ...,\n",
       "          [-0.0581, -0.0693, -0.1448, -0.1116, -0.1086],\n",
       "          [-0.0962, -0.0539, -0.1144, -0.0916, -0.0240],\n",
       "          [-0.0499,  0.0471,  0.0293,  0.0532,  0.0909]]], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.feed_forward.encoder_2.bias': tensor([-0.2350, -0.1211, -0.0338,  0.1620, -0.0802, -0.1777,  0.0139,  0.0467,\n",
       "         -0.1656, -0.0220, -0.2607, -0.2350, -0.1685,  0.1578, -0.2611, -0.0041,\n",
       "          0.0365,  0.0350, -0.0253,  0.0130, -0.2852, -0.1360, -0.2569, -0.3004,\n",
       "          0.0799,  0.1453, -0.0761, -0.0569, -0.1720, -0.0604,  0.1930, -0.1298,\n",
       "          0.0113,  0.0057, -0.1365, -0.0162, -0.0427,  0.1855, -0.0491, -0.2119,\n",
       "         -0.1169, -0.0300,  0.0872,  0.0168, -0.1047, -0.2247, -0.1613, -0.1881,\n",
       "          0.0939,  0.0549], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.sublayer.0.norm.a_2': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.sublayer.0.norm.b_2': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.sublayer.1.norm.a_2': tensor([1.2491, 0.9330, 0.8398, 0.8550, 1.0900, 0.9359, 0.8794, 1.1130, 1.2067,\n",
       "         0.8046, 0.8312, 0.7199, 1.1059, 1.0488, 0.7421, 0.8463, 1.0471, 0.9656,\n",
       "         1.1294, 0.9688, 0.9599, 0.6534, 0.9354, 1.2888, 1.2020, 1.0943, 0.9819,\n",
       "         0.8531, 1.2385, 1.0061, 1.0867, 0.9314, 0.7122, 0.8502, 1.0236, 1.1661,\n",
       "         1.3617, 1.1774, 0.8267, 0.8977, 0.9490, 0.9386, 1.1548, 0.8238, 0.8780,\n",
       "         1.0761, 1.2800, 1.0709, 0.8897, 0.8927], dtype=torch.float64),\n",
       " 'transformer_rec.model.layers.1.sublayer.1.norm.b_2': tensor([-0.1118,  0.0675, -0.0689,  0.0827, -0.2115,  0.1707, -0.2516, -0.1159,\n",
       "         -0.1516, -0.1315,  0.0440,  0.0960,  0.0758, -0.0296,  0.0323,  0.0644,\n",
       "          0.0597, -0.2236, -0.0684,  0.0708, -0.0043,  0.0664, -0.0122, -0.0901,\n",
       "          0.0924,  0.1567, -0.1132,  0.1211,  0.0641,  0.0642,  0.1001,  0.0911,\n",
       "          0.8413,  0.3063,  0.1238, -0.0105, -0.0613,  0.3866, -0.0152, -0.0201,\n",
       "          0.0168, -0.0016,  0.1337,  0.0898, -0.0203,  0.2246,  0.0332,  0.1406,\n",
       "         -0.6746, -0.1318], dtype=torch.float64),\n",
       " 'transformer_rec.model.norm.a_2': tensor([0.9105, 0.9424, 1.2186, 0.8961, 0.8989, 0.9112, 1.1806, 0.9495, 0.9640,\n",
       "         0.8618, 0.9366, 0.9036, 0.9064, 0.9304, 0.9616, 0.9901, 0.9049, 0.8919,\n",
       "         0.9576, 0.8493, 0.8976, 0.9239, 0.8805, 0.9018, 0.9753, 0.9286, 0.9219,\n",
       "         0.8668, 0.9938, 0.9490, 1.0814, 0.8120, 2.3881, 2.2261, 0.9526, 1.0692,\n",
       "         0.9730, 0.8856, 0.9387, 1.1298, 0.8737, 2.1119, 1.1045, 0.9615, 0.9102,\n",
       "         1.0002, 0.9709, 0.8839, 2.7849, 0.8914], dtype=torch.float64),\n",
       " 'transformer_rec.model.norm.b_2': tensor([-0.2729,  0.0385, -0.3478,  0.0798, -0.1690, -0.0042,  0.5838, -0.1154,\n",
       "         -0.0771,  0.0132, -0.2083,  0.0510, -0.2457, -0.0908,  0.1247,  0.0558,\n",
       "         -0.1704,  0.1159, -0.0205,  0.0645, -0.0298, -0.1950, -0.0468, -0.0618,\n",
       "          0.0747,  0.0595,  0.0606, -0.1093,  0.2083,  0.1271,  0.0741, -0.2716,\n",
       "         -2.0542,  0.9597,  0.0113, -0.1421,  0.0389, -0.0197,  0.1188,  0.3780,\n",
       "         -0.0644, -0.1407,  0.1405, -0.3647,  0.0309,  0.1650, -0.0396, -0.0278,\n",
       "          2.3962,  0.1226], dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.self_attn.linears.0.weight': tensor([[-0.1206, -0.0599,  0.0369,  ...,  0.2726,  0.2224,  0.0660],\n",
       "         [ 0.1516, -0.0246,  0.1365,  ..., -0.0219, -0.3968,  0.0046],\n",
       "         [ 0.0915,  0.1200,  0.1070,  ..., -0.0933, -0.3195, -0.0442],\n",
       "         ...,\n",
       "         [-0.1628,  0.0594,  0.1496,  ...,  0.0011,  0.4078, -0.0016],\n",
       "         [-0.0004,  0.0905, -0.0091,  ...,  0.1094,  0.1589,  0.0090],\n",
       "         [-0.0455, -0.1137, -0.1345,  ...,  0.0442, -0.1031, -0.1999]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.self_attn.linears.0.bias': tensor([ 1.8145e-01, -3.1963e-01, -4.9657e-01, -4.0526e-01, -4.1714e-01,\n",
       "         -6.6653e-01, -6.4621e-01,  4.7444e-01,  3.8690e-01, -6.1581e-01,\n",
       "         -6.2652e-01, -8.1605e-01, -5.9477e-01, -6.3758e-01,  4.4954e-01,\n",
       "          4.7085e-01, -2.1266e-01,  3.9655e-01,  2.8331e-01, -1.3451e-01,\n",
       "         -9.4432e-02, -2.0283e-01,  6.0380e-02, -1.9953e-01, -3.6587e-01,\n",
       "          2.3166e-01, -3.7030e-01, -9.9645e-02,  2.3318e-01,  2.3563e-01,\n",
       "         -2.5558e-02,  9.1950e-02, -3.1450e-02, -2.8100e-01,  5.4622e-02,\n",
       "         -2.2401e-05, -2.2944e-01, -4.0248e-01, -1.4968e-01, -3.5779e-01,\n",
       "         -3.1863e-01,  4.4687e-02, -3.4508e-02, -7.8450e-02,  1.7010e-01,\n",
       "          8.6701e-02,  5.5614e-01,  3.0536e-01,  1.5589e-01, -2.7448e-02],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.self_attn.linears.1.weight': tensor([[ 0.0980, -0.1345, -0.0954,  ..., -0.1415,  0.1613,  0.2223],\n",
       "         [-0.1359,  0.3073,  0.2048,  ...,  0.2665, -0.4233,  0.0513],\n",
       "         [-0.0172,  0.3364,  0.1954,  ...,  0.2081, -0.3944,  0.0885],\n",
       "         ...,\n",
       "         [ 0.1206, -0.2614,  0.3155,  ..., -0.2414,  0.0272,  0.1239],\n",
       "         [ 0.3668, -0.2186,  0.1689,  ..., -0.0168, -0.0051, -0.1271],\n",
       "         [ 0.0150,  0.2565, -0.1029,  ..., -0.1330,  0.0940,  0.0039]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.self_attn.linears.1.bias': tensor([-0.1382,  0.0977, -0.0890,  0.0642, -0.0799, -0.1224, -0.0750,  0.0794,\n",
       "         -0.0474, -0.1153,  0.0669, -0.0485, -0.0846, -0.0410, -0.1036, -0.0430,\n",
       "          0.0136,  0.1174,  0.1103, -0.0765,  0.0185, -0.1220, -0.0808,  0.0432,\n",
       "         -0.1066, -0.0041, -0.1030, -0.0324, -0.0005,  0.1263, -0.1194, -0.0050,\n",
       "         -0.0200, -0.0711, -0.1271, -0.0429, -0.0581, -0.0961, -0.1360, -0.0358,\n",
       "         -0.0047,  0.0646,  0.0274, -0.0816, -0.0544,  0.0916,  0.1058,  0.0563,\n",
       "         -0.0073,  0.0345], dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.self_attn.linears.2.weight': tensor([[ 0.0242,  0.0160,  0.0015,  ...,  0.1450,  0.0030,  0.1332],\n",
       "         [-0.0553, -0.0399,  0.0821,  ...,  0.1575, -0.0580, -0.0234],\n",
       "         [ 0.0765,  0.0259,  0.0781,  ...,  0.0270,  0.0697,  0.0798],\n",
       "         ...,\n",
       "         [-0.0718, -0.0880,  0.0828,  ...,  0.0158,  0.0522, -0.0003],\n",
       "         [ 0.0592,  0.0489, -0.0189,  ..., -0.0108, -0.0340, -0.0426],\n",
       "         [ 0.0197, -0.0177,  0.0263,  ...,  0.0195,  0.0283, -0.1254]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.self_attn.linears.2.bias': tensor([-0.0123,  0.0529, -0.1167,  0.0155, -0.0028, -0.1395, -0.1725,  0.0791,\n",
       "         -0.1074, -0.0053,  0.0916, -0.1587, -0.0972, -0.0101, -0.0392,  0.1164,\n",
       "         -0.0652,  0.0325, -0.0088, -0.1628, -0.0403, -0.0842, -0.0955,  0.0277,\n",
       "         -0.0819, -0.0448, -0.1247, -0.0067, -0.0222,  0.1230, -0.0461, -0.0907,\n",
       "         -0.0321, -0.0100,  0.0050, -0.0126, -0.0244, -0.1659, -0.0752,  0.0426,\n",
       "         -0.0516,  0.1271,  0.0311, -0.0149,  0.0564,  0.0245,  0.1532,  0.0429,\n",
       "          0.0250, -0.0070], dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.self_attn.linears.3.weight': tensor([[-0.0189, -0.1264, -0.0167,  ...,  0.1269, -0.0566,  0.0217],\n",
       "         [-0.0348,  0.0415,  0.0856,  ...,  0.0829, -0.1040,  0.0355],\n",
       "         [-0.0859,  0.1442, -0.0164,  ...,  0.1138,  0.0416, -0.0089],\n",
       "         ...,\n",
       "         [-0.0424, -0.1195,  0.0805,  ..., -0.0787,  0.1062, -0.0553],\n",
       "         [ 0.1653,  0.2642, -0.7120,  ...,  0.7712,  0.0716, -0.1241],\n",
       "         [-0.0439,  0.0182,  0.0136,  ..., -0.0614,  0.0022, -0.0115]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.self_attn.linears.3.bias': tensor([-1.6083e-01,  1.4687e-01, -1.3517e-01,  1.2788e-01, -1.0085e-01,\n",
       "          1.5672e-02,  2.3395e-01,  3.2573e-03, -2.7748e-02, -6.9408e-02,\n",
       "         -2.0702e-02,  1.3893e-02, -1.4050e-01, -7.1208e-03, -4.5202e-02,\n",
       "         -6.9345e-03, -4.7430e-02,  7.0240e-02,  3.9585e-02, -1.9931e-02,\n",
       "          3.4448e-02, -1.4070e-01, -3.1346e-02,  3.2410e-04, -3.5401e-02,\n",
       "          3.3229e-02, -5.9777e-03, -6.1112e-02,  7.1302e-02,  1.3748e-01,\n",
       "         -1.5200e-02, -8.9972e-02, -1.1142e+00,  3.8257e-01, -6.5381e-02,\n",
       "         -7.8514e-02, -2.2686e-02, -2.7948e-02, -2.0576e-02,  6.6149e-02,\n",
       "         -1.9881e-02, -5.7594e-02,  4.5113e-02, -1.8151e-01, -1.5512e-02,\n",
       "          1.1790e-01,  8.8051e-02, -4.1498e-02,  1.2404e+00,  6.0898e-02],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.feed_forward.bn.weight': tensor([0.4979, 0.9979, 0.6215, 0.6656, 0.4646, 0.6337, 0.7455, 0.4228, 0.4316,\n",
       "         0.5296, 0.4107, 0.6434, 0.5382, 0.4717, 0.5486, 0.6957, 0.4423, 0.5772,\n",
       "         0.5585, 0.5679, 0.5089, 0.3980, 0.5335, 0.5738, 0.5083, 0.5963, 0.7134,\n",
       "         0.4520, 1.1015, 0.4747, 0.4687, 0.6004, 0.5392, 1.7774, 0.4594, 0.5624,\n",
       "         0.6028, 0.4844, 0.6006, 0.6123, 0.4372, 1.5771, 0.4929, 0.3660, 0.4581,\n",
       "         0.9600, 0.6019, 0.4284, 2.5457, 0.5533], dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.feed_forward.bn.bias': tensor([-0.3939, -0.1697, -0.4371, -0.2881, -0.4920, -0.3048, -0.1531, -0.4814,\n",
       "         -0.5110, -0.4095, -0.3649, -0.2560, -0.4097, -0.4377, -0.4035, -0.2734,\n",
       "         -0.3881, -0.2445, -0.4096, -0.3956, -0.3933, -0.4503, -0.4825, -0.3777,\n",
       "         -0.4823, -0.2962, -0.2681, -0.3092, -0.1266, -0.4184, -0.4145, -0.3513,\n",
       "         -0.5247,  0.6171, -0.4190, -0.4648, -0.3450, -0.3578, -0.2861, -0.0834,\n",
       "         -0.4027,  0.2192, -0.3886, -0.5546, -0.4623, -0.2588, -0.2363, -0.4323,\n",
       "          1.1451, -0.2391], dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.feed_forward.bn.running_mean': tensor([-0.0163, -0.1670,  0.0257,  0.0660, -0.0086,  0.0976,  0.0582, -0.0261,\n",
       "          0.0368,  0.0865,  0.1273,  0.0506,  0.0163,  0.0134,  0.0009,  0.0239,\n",
       "         -0.1021, -0.0657,  0.1019,  0.0493,  0.0703,  0.0829,  0.1280,  0.0409,\n",
       "          0.1104,  0.0290,  0.1254,  0.1133, -0.1199,  0.0471,  0.0587, -0.0593,\n",
       "         -0.0166,  0.0236,  0.0854, -0.0106, -0.0144, -0.0561,  0.1042, -0.0176,\n",
       "          0.2240,  0.0310,  0.0146,  0.0476,  0.0271, -0.0356, -0.0684,  0.0390,\n",
       "         -0.1063,  0.0914], dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.feed_forward.bn.running_var': tensor([0.1164, 0.0165, 0.0277, 0.0137, 0.0846, 0.0482, 0.0334, 0.0220, 0.0544,\n",
       "         0.0505, 0.0731, 0.0342, 0.1258, 0.0213, 0.0305, 0.0176, 0.0560, 0.0382,\n",
       "         0.0118, 0.0502, 0.0764, 0.0283, 0.0251, 0.0196, 0.0199, 0.0174, 0.0187,\n",
       "         0.0525, 0.0146, 0.0357, 0.0243, 0.0739, 0.0012, 0.0018, 0.0638, 0.0049,\n",
       "         0.0173, 0.0124, 0.0251, 0.0041, 0.0321, 0.0061, 0.0072, 0.0750, 0.1001,\n",
       "         0.0183, 0.0148, 0.0132, 0.0019, 0.0634], dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.feed_forward.bn.num_batches_tracked': tensor(213030),\n",
       " 'transformer_post.model.layers.0.feed_forward.encoder_0.weight_ih_l0': tensor([[ 0.2057,  0.1050, -0.1986,  ...,  0.1637, -0.1553, -0.1056],\n",
       "         [-0.2591,  0.0708, -0.2047,  ..., -0.0988,  0.0368,  0.2139],\n",
       "         [ 0.4576, -0.1886,  0.0204,  ..., -0.1919, -0.0167,  0.1208],\n",
       "         ...,\n",
       "         [ 0.0517, -0.1591,  0.1590,  ...,  0.2120, -0.2629, -0.0745],\n",
       "         [ 0.1394,  0.4208,  0.1290,  ..., -0.0551, -0.4369, -0.0031],\n",
       "         [ 0.0475, -0.0401,  0.2240,  ...,  0.1154, -0.0366, -0.1618]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.feed_forward.encoder_0.weight_hh_l0': tensor([[-0.1439, -0.0376, -0.1164,  ...,  0.0222,  0.1732, -0.0922],\n",
       "         [-0.0259,  0.2322, -0.2508,  ...,  0.0740,  0.2402,  0.0281],\n",
       "         [ 0.0059,  0.0188, -0.1958,  ...,  0.0247, -0.2601, -0.0488],\n",
       "         ...,\n",
       "         [-0.2281,  0.1186, -0.4028,  ...,  0.0495, -0.0372, -0.0999],\n",
       "         [ 0.0295,  0.2380, -0.0348,  ..., -0.0791,  0.0937, -0.0256],\n",
       "         [-0.3105,  0.0740,  0.0587,  ...,  0.1028, -0.1185, -0.2419]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.feed_forward.encoder_0.bias_ih_l0': tensor([-9.1119e-02, -2.5624e-01, -2.0972e-01, -2.8235e-01, -3.3578e-02,\n",
       "         -3.5701e-01, -1.5988e-01,  1.2968e-02, -7.4586e-02, -2.8415e-02,\n",
       "          6.7460e-02,  8.8925e-02,  1.3680e-01, -2.1868e-01,  1.7436e-01,\n",
       "         -1.7385e-04, -2.1953e-01, -1.2718e-01, -1.8141e-01, -4.5181e-02,\n",
       "          8.3302e-02, -1.6335e-01, -1.4768e-01, -1.0532e-03, -9.4736e-02,\n",
       "         -1.9504e-01, -3.1455e-02,  2.2004e-01, -2.6182e-01,  1.1570e-01,\n",
       "          1.4031e-01,  8.9202e-02, -3.7902e-01, -2.2660e-01,  1.0224e-01,\n",
       "         -2.7571e-01, -1.0879e-01, -1.0377e-01,  1.8094e-02, -3.6041e-01,\n",
       "          1.9871e-01,  7.1919e-03, -2.1879e-01, -6.8224e-02,  1.2670e-01,\n",
       "         -6.8912e-02, -8.1991e-02, -1.8555e-01, -2.3878e-01,  2.6497e-01,\n",
       "          3.5670e-02, -6.0924e-02, -2.8837e-01, -1.9842e-01, -4.8538e-02,\n",
       "          1.9535e-01, -2.1480e-01, -1.2471e-01,  9.2415e-02, -2.1559e-01,\n",
       "          2.3899e-01, -1.4968e-01, -3.0360e-02, -1.8409e-01, -3.1989e-03,\n",
       "          3.8230e-02, -1.2711e-02, -5.8977e-03, -5.4845e-02, -2.0587e-01,\n",
       "         -1.2057e-01, -2.6741e-01, -1.3545e-01, -8.6828e-02, -3.8206e-01,\n",
       "          3.2803e-02,  8.1282e-02, -1.1457e-01, -1.1901e-01, -5.6846e-02,\n",
       "         -4.7775e-02,  3.1459e-02, -1.5032e-02, -2.5179e-01,  6.6260e-02,\n",
       "         -2.1877e-01, -1.1067e-01,  3.9845e-02, -1.3299e-01, -3.0130e-01,\n",
       "          5.2888e-02, -5.0730e-02, -2.4779e-01,  4.4504e-02,  1.0221e-01,\n",
       "         -1.2792e-01, -2.4086e-01,  7.9902e-02, -2.5958e-01,  3.6946e-01,\n",
       "          1.8584e-02,  5.1994e-02,  2.4917e-01,  8.8848e-02,  8.3681e-02,\n",
       "          5.0996e-02, -4.9924e-02,  1.1897e-01, -4.4852e-02,  8.2452e-02,\n",
       "          1.7103e-01,  1.2376e-02,  7.7805e-02,  3.6626e-03,  5.4135e-02,\n",
       "         -1.8326e-01, -1.4845e-01, -2.8071e-02,  1.4071e-01, -4.5906e-02,\n",
       "          1.1329e-01, -5.5497e-02, -1.4703e-01,  9.5009e-02, -3.6556e-02,\n",
       "         -1.6366e-02,  1.6993e-01, -5.4957e-02,  1.7310e-01,  1.4205e-03,\n",
       "          2.4889e-01, -8.1426e-02, -1.7356e-01,  1.7809e-01,  1.1786e-02,\n",
       "          4.6322e-03, -1.1244e-01,  1.8652e-02,  4.4312e-02, -5.4190e-02,\n",
       "          1.8424e-01, -2.7483e-02,  4.8050e-02,  1.8909e-01,  9.4917e-02,\n",
       "         -2.1204e-04, -1.1003e-02, -2.5812e-02, -1.0124e-01,  1.6133e-01,\n",
       "         -8.0810e-02, -3.3017e-01, -1.1236e-01, -2.3116e-01, -6.5367e-02,\n",
       "         -3.5837e-02, -2.7885e-01, -6.9729e-02,  1.8378e-01, -1.1816e-01,\n",
       "          9.2839e-02,  8.9103e-02,  1.8515e-01, -1.8382e-01, -9.4817e-03,\n",
       "         -2.2151e-01, -1.4753e-01,  5.0777e-03, -3.0125e-01, -1.7856e-02,\n",
       "          1.5839e-01, -4.9397e-02, -2.9758e-01, -1.2887e-01, -3.3155e-01,\n",
       "         -2.0828e-03, -1.1702e-01,  2.9206e-02, -1.7655e-01, -1.3072e-01,\n",
       "         -6.5930e-03,  7.7403e-02, -4.9251e-01, -2.7962e-01, -4.5923e-02,\n",
       "          4.3709e-03, -2.2028e-01, -3.5893e-01,  8.6318e-02, -4.3247e-01,\n",
       "         -1.4406e-01, -3.2479e-01, -2.3798e-01,  1.6053e-01,  4.9873e-02,\n",
       "         -2.3230e-01, -1.4853e-01, -8.3037e-02, -3.1979e-01,  2.8131e-02],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.feed_forward.encoder_0.bias_hh_l0': tensor([ 3.8189e-02, -2.3182e-01, -8.5958e-02, -2.0333e-02, -1.3002e-01,\n",
       "         -3.4642e-01, -3.0083e-01,  1.1964e-02,  1.1380e-01, -9.4868e-02,\n",
       "          8.2010e-02,  8.0356e-02,  1.5523e-01, -1.4049e-01,  1.4817e-01,\n",
       "         -9.3127e-02, -3.3741e-01,  6.5207e-02, -2.2573e-01, -1.2411e-01,\n",
       "         -1.4468e-01, -1.4306e-01, -1.1482e-01,  1.1081e-01, -1.5327e-01,\n",
       "         -1.9268e-01, -2.9170e-02,  2.2831e-01, -7.3070e-02, -9.7368e-02,\n",
       "          2.3602e-02,  5.3651e-02, -2.9624e-01, -2.6536e-01,  7.7604e-02,\n",
       "         -2.3233e-01, -1.9399e-01, -2.4003e-01, -1.0042e-02, -4.7172e-01,\n",
       "          5.4620e-02, -1.0082e-01, -3.2068e-01, -3.6031e-03, -4.0807e-03,\n",
       "          2.0258e-03, -8.4547e-02, -1.9600e-01, -6.5479e-02,  2.3478e-01,\n",
       "          5.6113e-02, -2.4624e-02, -4.0972e-01, -3.0821e-01,  7.6033e-02,\n",
       "          1.2253e-01, -4.0955e-01, -8.1259e-02,  2.4070e-01, -5.0073e-02,\n",
       "          2.8541e-01,  1.5753e-02,  8.9092e-02, -1.9075e-01,  1.1539e-01,\n",
       "          3.5324e-02, -1.0172e-01, -3.8212e-02, -7.8008e-04, -4.6104e-01,\n",
       "          8.9241e-02, -2.4767e-01, -5.7688e-02, -4.1249e-02, -3.8474e-01,\n",
       "          6.3310e-02,  1.7065e-01, -2.4253e-01, -2.3383e-01,  9.4869e-02,\n",
       "          4.6111e-02,  5.8308e-02, -2.4760e-01, -1.9901e-01, -5.4628e-02,\n",
       "         -4.1933e-02, -2.6508e-01,  1.1588e-01, -1.0943e-03, -2.0912e-01,\n",
       "         -9.1985e-02, -1.9923e-01, -1.0905e-01,  4.1898e-02,  2.2835e-01,\n",
       "         -2.5635e-01, -4.0826e-01,  3.4230e-02, -2.1321e-01,  4.0163e-01,\n",
       "          1.3497e-01,  6.6597e-02,  8.4563e-02,  4.7115e-02,  3.8870e-02,\n",
       "         -4.5602e-02,  8.4581e-02,  4.2044e-02,  4.3855e-02, -6.4187e-02,\n",
       "          1.6173e-01,  2.4337e-02, -3.2072e-02,  1.7506e-01,  1.6967e-01,\n",
       "          6.9054e-02, -1.5384e-01,  2.9228e-02,  1.6703e-01,  4.6732e-02,\n",
       "          1.3905e-01,  5.7813e-03,  4.6876e-02,  2.3173e-01, -8.4810e-02,\n",
       "         -3.1269e-03,  2.0165e-02, -1.2671e-01,  2.4808e-01,  3.7856e-02,\n",
       "          1.2153e-01, -6.0404e-02,  1.6890e-02,  6.6162e-02, -7.4670e-02,\n",
       "          6.6949e-02, -9.1968e-02, -7.8407e-02, -1.7542e-02,  1.6146e-01,\n",
       "          1.0747e-01,  3.1609e-02,  1.4646e-02,  5.3170e-02,  1.2880e-02,\n",
       "          8.1755e-05,  1.0590e-01, -1.3800e-02,  1.0656e-01,  5.0393e-02,\n",
       "         -9.1574e-02, -2.6246e-01, -1.3774e-01, -3.0315e-01, -1.4225e-01,\n",
       "         -9.0644e-02, -1.6011e-01,  1.0762e-01,  8.1398e-02, -5.3795e-02,\n",
       "          1.8599e-01,  9.8209e-02,  2.0095e-01, -1.7661e-01,  7.4937e-02,\n",
       "         -2.4813e-01, -2.8816e-01,  8.6347e-02, -3.1401e-01, -1.7425e-01,\n",
       "         -9.0639e-03,  2.3703e-02, -1.5338e-01,  3.2444e-02, -1.5960e-01,\n",
       "          6.4921e-02, -1.2940e-01, -9.4509e-03, -1.4868e-01, -1.7212e-01,\n",
       "         -1.2905e-02,  1.1978e-01, -4.7926e-01, -1.1999e-01,  5.8766e-02,\n",
       "         -7.7741e-04, -3.5787e-01, -3.1443e-01,  2.2771e-02, -2.2383e-01,\n",
       "         -1.3748e-01, -3.4379e-01, -5.2293e-02,  5.5117e-02,  5.5275e-03,\n",
       "         -1.2192e-01, -1.5125e-01, -1.0657e-01, -2.0671e-01, -6.0111e-02],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.feed_forward.encoder_1.weight_ih_l0': tensor([[ 0.0852, -0.0150,  0.0283,  ...,  0.1645, -0.1124, -0.1458],\n",
       "         [-0.0054,  0.4465,  0.0640,  ...,  0.1553,  0.3089, -0.0720],\n",
       "         [-0.0521, -0.0499,  0.1090,  ..., -0.1310,  0.1312,  0.2069],\n",
       "         ...,\n",
       "         [ 0.3433, -0.0897,  0.1552,  ..., -0.0420, -0.1247, -0.0704],\n",
       "         [ 0.1528, -0.1328,  0.0139,  ...,  0.3178,  0.1718,  0.0965],\n",
       "         [ 0.2045, -0.0013,  0.1402,  ..., -0.0660, -0.2199, -0.0652]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.feed_forward.encoder_1.weight_hh_l0': tensor([[-2.3388e-01,  8.5565e-02,  1.4432e-01,  ..., -1.3208e-01,\n",
       "           1.8229e-01, -1.8302e-01],\n",
       "         [-1.1940e-01, -9.3734e-02, -9.4614e-02,  ..., -4.7177e-02,\n",
       "          -1.0779e-01, -1.2222e-01],\n",
       "         [ 1.3913e-01,  4.3726e-02,  1.2606e-03,  ...,  1.6613e-04,\n",
       "           2.5923e-02, -1.3182e-01],\n",
       "         ...,\n",
       "         [-2.9242e-03, -3.2914e-02,  2.3057e-01,  ..., -2.1711e-01,\n",
       "           2.2592e-01, -1.0702e-01],\n",
       "         [-4.4608e-02, -3.5150e-02,  5.9070e-02,  ..., -2.1903e-02,\n",
       "           3.9699e-01,  9.3169e-02],\n",
       "         [-3.4524e-01, -1.1855e-01,  1.9949e-01,  ..., -1.5501e-01,\n",
       "           8.8776e-02, -3.9611e-01]], dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.feed_forward.encoder_1.bias_ih_l0': tensor([ 3.4083e-02,  8.0281e-02,  9.0651e-02,  1.1365e-01, -2.2957e-01,\n",
       "         -3.6452e-02,  1.3125e-01, -9.5218e-02, -2.2122e-02, -5.3049e-02,\n",
       "         -1.7999e-02, -6.6449e-02, -6.0913e-02, -2.4533e-01,  1.0397e-01,\n",
       "         -2.2503e-01,  1.0492e-01, -5.4127e-02, -1.1279e-01,  1.5527e-02,\n",
       "         -2.7636e-02, -3.6940e-01,  2.7788e-02, -2.8120e-01,  2.0771e-01,\n",
       "          5.4086e-02, -1.3483e-01, -4.0104e-01, -2.0278e-01, -1.7167e-02,\n",
       "         -2.6537e-02, -2.2881e-01, -5.1298e-01, -5.7471e-04, -2.6753e-02,\n",
       "         -4.0739e-01, -1.7044e-01, -2.2975e-01,  1.5240e-01, -2.0083e-01,\n",
       "          2.4184e-01, -2.1737e-01, -3.5242e-01, -2.2344e-01, -1.0664e-01,\n",
       "         -1.2611e-01, -9.9786e-02, -3.7679e-01,  1.6588e-01, -3.8239e-01,\n",
       "         -4.2135e-02, -3.3603e-02, -2.9213e-01,  3.3620e-01, -9.4139e-02,\n",
       "         -3.9527e-02, -1.2728e-01, -3.0546e-01, -9.4788e-02, -1.0669e-01,\n",
       "         -1.1428e-02, -9.6167e-02, -9.2463e-02, -3.9456e-02, -1.1948e-01,\n",
       "         -2.2103e-01, -2.2903e-01, -1.3873e-02, -4.1807e-02, -1.8775e-02,\n",
       "         -7.8838e-02, -1.5470e-01,  1.4170e-01, -1.3992e-01,  2.1392e-01,\n",
       "          1.1505e-02, -2.3544e-02, -1.5954e-01, -2.3573e-01, -6.4161e-03,\n",
       "         -2.8720e-01, -8.8038e-02, -2.3149e-01, -1.0744e-01,  1.2001e-02,\n",
       "         -9.3683e-02, -1.0664e-01, -1.5636e-01,  3.1431e-02, -1.9144e-01,\n",
       "          1.5949e-01, -1.7158e-01, -1.6089e-01,  4.4476e-02,  1.5329e-01,\n",
       "         -3.0377e-01, -9.1617e-03, -2.2840e-01, -1.5045e-01, -1.7971e-01,\n",
       "         -4.8070e-02, -2.7597e-01, -2.3726e-02,  1.0407e-01, -1.5994e-01,\n",
       "          7.2668e-02,  1.6458e-01,  1.8932e-02, -3.3809e-02,  1.3697e-01,\n",
       "         -1.4545e-01, -9.9787e-02,  2.0565e-01, -4.8525e-02, -8.8185e-02,\n",
       "         -1.2672e-01, -1.6746e-01, -1.5408e-02, -1.0598e-01,  7.5427e-02,\n",
       "         -1.1739e-01,  3.5630e-04,  1.5199e-01, -1.5202e-01,  1.1734e-01,\n",
       "         -1.2979e-01,  3.7452e-02, -1.2967e-01,  1.3652e-01, -3.8741e-02,\n",
       "          5.5924e-02, -3.1471e-02, -2.2510e-01,  7.0327e-02,  3.4405e-02,\n",
       "         -1.8470e-01,  1.7163e-02, -1.5671e-01,  2.6264e-01, -7.3724e-02,\n",
       "          2.7762e-01,  3.4261e-02,  3.7321e-02, -1.2390e-01,  1.0398e-01,\n",
       "         -6.1313e-02, -9.7725e-02, -1.5507e-01, -1.5665e-01, -1.5477e-01,\n",
       "         -1.6643e-02, -1.6447e-02,  6.6738e-02, -5.3600e-02, -6.9692e-02,\n",
       "          4.8361e-03,  6.1499e-02, -8.7332e-02, -2.4469e-01, -1.1184e-03,\n",
       "         -2.2128e-01, -1.1721e-01, -3.3032e-01, -3.3067e-01, -4.2831e-03,\n",
       "         -3.5408e-01, -2.1645e-02,  1.7316e-01, -8.4356e-02, -5.9016e-02,\n",
       "         -1.6110e-01, -1.5736e-01, -9.1562e-02, -9.5907e-02, -2.1952e-01,\n",
       "         -5.5993e-03, -1.7690e-01, -2.9673e-01, -2.0664e-01,  8.4222e-02,\n",
       "          4.2766e-02, -1.9045e-01, -5.2756e-01, -2.8886e-01,  6.3104e-03,\n",
       "         -4.2815e-01, -8.0689e-02, -3.1269e-01, -3.5650e-03,  1.0632e-03,\n",
       "          1.5706e-01, -2.3391e-01, -2.3747e-01, -3.4723e-01,  3.1875e-01,\n",
       "         -2.6035e-01, -3.1198e-01, -2.8407e-01,  7.6994e-02, -7.2976e-02],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.feed_forward.encoder_1.bias_hh_l0': tensor([-2.0509e-02,  5.8566e-02,  9.3257e-02,  9.1377e-02, -3.2429e-01,\n",
       "         -7.9203e-02,  1.5949e-01, -2.0089e-01, -7.9340e-02, -1.0365e-01,\n",
       "         -3.9501e-02, -2.2591e-01, -1.3651e-01, -9.0297e-02,  8.9797e-02,\n",
       "         -4.3797e-01, -9.5854e-02, -2.2310e-01, -7.1681e-02, -1.5099e-03,\n",
       "          1.6873e-01, -2.4614e-01,  9.3059e-02, -1.7171e-01,  2.3281e-01,\n",
       "         -2.0602e-01, -6.8997e-02, -1.9489e-01, -1.2693e-01, -1.9083e-01,\n",
       "          4.3018e-02, -4.5246e-01, -2.9610e-01, -8.2900e-02, -1.7539e-01,\n",
       "         -2.3050e-01, -1.3120e-01, -2.7691e-01,  1.5971e-01, -1.5906e-01,\n",
       "          2.7502e-01, -5.7473e-02, -4.2487e-01, -2.1738e-01,  6.9267e-02,\n",
       "         -2.5337e-01, -9.0208e-03, -1.3561e-01,  1.8127e-01, -2.2392e-01,\n",
       "          1.9255e-02, -8.3779e-02, -2.3172e-01,  7.2817e-02, -8.4408e-02,\n",
       "          1.0429e-01, -1.8885e-01, -2.6678e-01, -2.3274e-01, -7.1193e-02,\n",
       "         -1.5738e-01, -2.1797e-01, -1.1306e-01, -2.2373e-01, -1.1224e-03,\n",
       "         -2.0472e-01, -8.2520e-03,  4.1909e-02, -1.4716e-01, -2.0249e-01,\n",
       "         -1.6206e-01, -2.7752e-01,  8.2497e-02, -1.3562e-03,  2.1167e-01,\n",
       "         -2.7672e-02, -2.7981e-02, -1.5141e-01, -9.1440e-02, -1.6349e-01,\n",
       "         -3.1832e-02, -9.6867e-02, -2.3485e-01, -3.5532e-01, -1.1109e-01,\n",
       "         -2.9828e-01, -6.6572e-03, -2.4669e-01, -1.3144e-01, -4.0850e-02,\n",
       "          2.0664e-01, -3.0151e-01, -1.5263e-01,  3.0779e-04, -3.1067e-02,\n",
       "         -1.2418e-01, -9.8576e-02, -2.2348e-01, -6.1587e-02, -3.0208e-02,\n",
       "         -5.6530e-02, -2.7319e-01,  3.2624e-02,  1.9994e-01, -1.5973e-02,\n",
       "          2.0688e-01,  1.6000e-01, -9.2546e-03,  4.7457e-02, -2.8547e-02,\n",
       "         -1.4776e-01,  1.6236e-01,  2.2788e-01,  4.2331e-02, -7.4177e-02,\n",
       "         -9.9983e-03,  4.3213e-02, -1.8241e-01,  3.4202e-02, -5.0329e-02,\n",
       "          4.7112e-02, -1.8244e-02,  5.6410e-02, -1.4506e-01,  1.4082e-01,\n",
       "          6.9652e-02,  1.1710e-02, -1.1480e-01,  1.5862e-01, -2.6050e-02,\n",
       "         -9.9610e-02,  1.1229e-02, -1.2523e-01,  8.5094e-02, -4.4364e-02,\n",
       "         -1.5709e-01, -7.4393e-02,  1.6919e-02,  1.5593e-01, -1.7704e-01,\n",
       "          2.5500e-01, -5.3718e-02, -9.6466e-02, -4.9889e-04,  9.1012e-02,\n",
       "          7.0393e-02, -8.2100e-02, -1.6968e-01, -2.2049e-01, -1.5600e-01,\n",
       "         -5.8086e-03,  4.8876e-02, -8.0416e-02, -7.4658e-02, -1.9053e-01,\n",
       "         -1.1964e-01,  1.0948e-01, -2.7589e-02, -1.9420e-01, -2.1442e-01,\n",
       "         -2.0139e-01, -1.2352e-01, -3.6953e-01, -1.3334e-01,  6.5767e-02,\n",
       "         -3.5034e-01,  1.3521e-01,  2.1193e-01, -1.6336e-01,  1.2577e-01,\n",
       "          5.6250e-03, -1.3655e-01, -2.3262e-02, -1.8275e-01,  1.2753e-02,\n",
       "         -1.6250e-01,  6.7645e-02, -4.1710e-01, -2.5459e-01, -1.3362e-01,\n",
       "          7.2150e-02, -2.4430e-01, -4.3336e-01, -3.8877e-01,  1.4540e-01,\n",
       "         -4.4267e-01, -1.5431e-01, -3.4465e-01, -1.2515e-01, -5.3113e-02,\n",
       "          1.9184e-02, -3.4420e-01, -3.2616e-01, -1.7793e-01,  3.1455e-01,\n",
       "         -6.7358e-02, -4.5580e-02, -2.5065e-01,  7.6422e-02, -1.4182e-01],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.feed_forward.encoder_2.weight_ih_l0': tensor([[-0.2074, -0.1843,  0.0280,  ..., -0.1520,  0.2910,  0.3025],\n",
       "         [ 0.0974, -0.0936,  0.2327,  ...,  0.2264, -0.2747, -0.1783],\n",
       "         [ 0.3272, -0.0062, -0.1259,  ...,  0.0568, -0.2162,  0.1272],\n",
       "         ...,\n",
       "         [ 0.2236, -0.1540,  0.2747,  ...,  0.0251,  0.0154, -0.2756],\n",
       "         [-0.1969,  0.0972, -0.0281,  ..., -0.1854, -0.4439, -0.1710],\n",
       "         [-0.0451, -0.0643,  0.2331,  ...,  0.1606, -0.1337,  0.0167]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.feed_forward.encoder_2.weight_hh_l0': tensor([[-0.0630, -0.0690,  0.0339,  ...,  0.0448,  0.1546,  0.1369],\n",
       "         [ 0.1550, -0.2208, -0.3335,  ...,  0.2821, -0.0388, -0.1898],\n",
       "         [-0.1088, -0.0307, -0.2083,  ..., -0.1077, -0.2529, -0.2907],\n",
       "         ...,\n",
       "         [-0.1223,  0.0451, -0.1744,  ..., -0.2246, -0.2339, -0.0860],\n",
       "         [ 0.0765,  0.1121, -0.0731,  ..., -0.2082, -0.2601,  0.0525],\n",
       "         [ 0.0590,  0.2285, -0.0090,  ...,  0.0536, -0.1733, -0.2771]],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.feed_forward.encoder_2.bias_ih_l0': tensor([ 0.2944, -0.2206, -0.2051, -0.2895, -0.0817, -0.0141, -0.0898, -0.2710,\n",
       "         -0.1038, -0.1600,  0.1213,  0.0444,  0.2875,  0.1585, -0.1844, -0.2644,\n",
       "         -0.0161, -0.1452,  0.1551, -0.1584,  0.0504, -0.0611, -0.1832, -0.3614,\n",
       "         -0.1339, -0.1956, -0.2150,  0.0581,  0.3119,  0.1386, -0.4128, -0.1026,\n",
       "         -0.2775, -0.3559, -0.0540, -0.2930,  0.0022, -0.2063, -0.4191, -0.1678,\n",
       "         -0.1456, -0.3847, -0.0625, -0.0561, -0.4334, -0.1347,  0.0146, -0.1067,\n",
       "          0.2642,  0.3311,  0.0404, -0.1207,  0.1278, -0.0991,  0.1260,  0.1488,\n",
       "         -0.0508, -0.0696, -0.0236,  0.1452, -0.0342, -0.2080,  0.2908,  0.0502,\n",
       "         -0.1228, -0.3455, -0.2277,  0.0914,  0.1538, -0.0623,  0.0026,  0.0373,\n",
       "         -0.0900, -0.1122, -0.3542, -0.1329,  0.1238, -0.0889,  0.2458, -0.0488,\n",
       "         -0.0458, -0.1145,  0.1046, -0.3303, -0.1263, -0.3138,  0.1799,  0.0609,\n",
       "         -0.2085,  0.1405, -0.0108, -0.2559, -0.2208, -0.1257, -0.0420,  0.1725,\n",
       "         -0.3183,  0.0472,  0.1098,  0.1936,  0.0516,  0.3312, -0.1575,  0.1009,\n",
       "         -0.0432, -0.0574, -0.1993, -0.1838,  0.1686,  0.2104, -0.1277,  0.0261,\n",
       "         -0.1305, -0.1122, -0.2258,  0.0442, -0.0483, -0.1364,  0.1138,  0.2194,\n",
       "          0.0899,  0.2516,  0.0297, -0.0876,  0.0912, -0.0099, -0.0172,  0.1003,\n",
       "         -0.3844,  0.0252, -0.1232, -0.0627, -0.1515,  0.2188,  0.0504,  0.0318,\n",
       "          0.0579,  0.0235, -0.0033,  0.0984,  0.0497, -0.0445,  0.1651,  0.0353,\n",
       "         -0.0121, -0.1380, -0.1680,  0.1363,  0.3469,  0.1742,  0.1219, -0.2579,\n",
       "         -0.3518, -0.0924, -0.0930, -0.0108, -0.2473, -0.1192, -0.2395, -0.0727,\n",
       "          0.0792, -0.0676, -0.0605, -0.0893, -0.3708, -0.3904,  0.0890, -0.0819,\n",
       "         -0.0235, -0.3653,  0.0042,  0.0435, -0.3258, -0.3957, -0.2674, -0.1276,\n",
       "          0.0487, -0.0208, -0.2385, -0.0890, -0.1836, -0.0786, -0.2486, -0.3460,\n",
       "         -0.0401, -0.1083, -0.0039, -0.1175,  0.0478, -0.1994, -0.1119, -0.2735,\n",
       "         -0.3013, -0.0107, -0.2421, -0.1064, -0.2753, -0.0918, -0.4601, -0.1133],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.feed_forward.encoder_2.bias_hh_l0': tensor([ 3.7110e-01, -2.1029e-01, -1.6597e-01, -1.7805e-01, -4.3674e-02,\n",
       "         -1.7547e-01, -2.2219e-01, -2.9137e-01, -1.4985e-01, -1.1454e-01,\n",
       "          4.1200e-03, -1.1114e-01,  2.8572e-01,  4.0236e-02, -3.8061e-01,\n",
       "         -2.1133e-01, -1.3255e-01, -2.0896e-01,  2.0693e-01,  6.2206e-02,\n",
       "         -1.0156e-01,  1.0311e-01, -9.0448e-02, -3.3982e-01, -4.0977e-02,\n",
       "         -1.4935e-01, -6.3822e-02, -9.3192e-02,  3.6725e-01, -3.9641e-02,\n",
       "         -1.7537e-01, -7.7893e-02, -2.2477e-01, -1.8568e-01,  8.9184e-02,\n",
       "         -6.4033e-02,  4.1715e-02, -5.2837e-02, -5.3890e-01, -2.1236e-01,\n",
       "         -2.2173e-01, -2.2015e-01, -1.5067e-02,  3.3012e-02, -3.1456e-01,\n",
       "         -2.9299e-01, -1.0656e-01,  3.4400e-02,  3.1185e-01,  2.2082e-01,\n",
       "         -7.1843e-02, -1.5486e-01, -1.1035e-01, -7.9949e-02,  1.7630e-02,\n",
       "         -7.5142e-03,  5.0640e-02, -9.9372e-02, -6.7126e-02,  2.3125e-01,\n",
       "          3.2717e-02, -1.8113e-01,  1.7893e-01, -5.0560e-02, -1.6722e-01,\n",
       "         -2.4921e-01, -2.8970e-01, -3.7872e-02,  1.9199e-01,  1.2074e-01,\n",
       "          1.8963e-03,  1.9125e-01,  6.8400e-02, -8.6672e-02, -2.9818e-01,\n",
       "         -1.3363e-01, -4.5068e-02,  1.4847e-01,  1.6600e-01, -2.4919e-02,\n",
       "         -2.2235e-01, -4.7033e-02,  1.2608e-02, -3.0800e-01, -1.0342e-02,\n",
       "         -1.7670e-01,  7.6335e-03, -5.4062e-02, -1.5099e-01, -1.0166e-02,\n",
       "         -5.3634e-02, -1.9210e-01, -1.3564e-01, -1.5211e-01, -2.4871e-01,\n",
       "          9.8572e-02, -2.9175e-01, -4.6359e-02,  2.9061e-01,  4.0468e-02,\n",
       "         -2.5204e-04,  7.8951e-02, -4.2210e-02,  8.7494e-02,  7.9754e-02,\n",
       "          5.6953e-02,  2.9444e-02, -2.5489e-01,  7.3683e-02,  2.4023e-01,\n",
       "         -2.1508e-02, -8.2298e-02, -2.7835e-02,  9.3462e-02, -8.7746e-02,\n",
       "          1.7265e-01,  3.1121e-03, -1.4797e-01,  1.6676e-01,  1.9759e-01,\n",
       "          6.1465e-02,  1.5270e-01,  3.4615e-03,  1.5662e-03,  1.6681e-01,\n",
       "         -8.7187e-02, -6.9509e-03,  8.3499e-02, -2.1899e-01,  1.4768e-01,\n",
       "         -9.8807e-02, -1.4024e-01, -1.3421e-01,  1.2155e-01, -2.9798e-02,\n",
       "         -1.1136e-01, -9.4355e-02, -1.0046e-01, -1.1101e-01, -1.4246e-01,\n",
       "         -3.1706e-02, -1.7056e-01,  4.5640e-02, -1.0719e-02, -4.6331e-02,\n",
       "         -1.2130e-02, -1.8416e-01,  1.1942e-01,  2.0248e-01,  3.2392e-02,\n",
       "          5.8638e-02, -1.8800e-01, -4.1284e-01, -6.6374e-02, -1.9141e-02,\n",
       "         -2.2894e-01, -1.4256e-01, -2.7905e-02, -3.4882e-01, -8.1092e-03,\n",
       "         -1.1106e-01, -1.0979e-01,  1.8924e-02, -1.0312e-01, -4.1255e-01,\n",
       "         -3.5907e-01, -3.7305e-02, -9.5807e-02, -2.3736e-01, -2.4250e-01,\n",
       "          9.4529e-02, -1.7039e-01, -2.6510e-01, -2.4055e-01, -1.6520e-01,\n",
       "         -2.8015e-01, -5.8736e-02,  1.1945e-01, -1.3546e-01,  2.8396e-02,\n",
       "         -2.9225e-01,  7.1509e-02, -8.0369e-02, -3.1221e-01, -9.9463e-02,\n",
       "         -1.4906e-01, -1.3502e-03, -2.4499e-01, -1.6906e-01, -2.1879e-01,\n",
       "         -1.0701e-01, -2.1669e-01, -4.0405e-01, -6.4766e-02,  7.6671e-03,\n",
       "         -1.1814e-01, -1.9802e-01, -1.5099e-01, -6.1164e-01, -5.0790e-02],\n",
       "        dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.sublayer.0.norm.a_2': tensor([0.6333, 0.3798, 0.4345, 0.2457, 0.3330, 0.2773, 0.5884, 0.5563, 0.3044,\n",
       "         0.2404, 0.4809, 0.5361, 0.6579, 0.4095, 0.4367, 0.1843, 0.3543, 0.3940,\n",
       "         0.2626, 0.5408, 0.3786, 0.4864, 0.7013, 0.2681, 0.2848, 0.4333, 0.5086,\n",
       "         0.3863, 0.4140, 0.4561, 0.2529, 0.6018, 0.2420, 0.1116, 0.4069, 0.4048,\n",
       "         0.4952, 0.7221, 0.5131, 0.4539, 0.3341, 0.2683, 0.4188, 0.5086, 0.6380,\n",
       "         0.5382, 0.4117, 0.3670, 0.2491, 0.4459], dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.sublayer.0.norm.b_2': tensor([ 0.1541,  0.0615,  0.0752, -0.0017,  0.0172,  0.0308, -0.2992,  0.0156,\n",
       "          0.0389, -0.0167,  0.1036, -0.0228,  0.1744,  0.0847, -0.0394,  0.0176,\n",
       "          0.0466, -0.0026, -0.0018, -0.0673, -0.0396,  0.1450,  0.0235,  0.0434,\n",
       "         -0.0238, -0.0288, -0.1006,  0.0846, -0.0343, -0.0308, -0.0307,  0.2185,\n",
       "          0.6166, -0.0903,  0.0228,  0.0452,  0.0081,  0.0659, -0.0466, -0.1444,\n",
       "          0.0390,  0.1824, -0.0604,  0.1595, -0.0591, -0.0510,  0.0322,  0.0479,\n",
       "         -0.5680, -0.0572], dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.sublayer.1.norm.a_2': tensor([1.0085, 1.3166, 0.9307, 1.1083, 1.0540, 0.8566, 1.1804, 1.1287, 1.2323,\n",
       "         1.1987, 0.9813, 0.6759, 1.0945, 1.1418, 1.0930, 0.9871, 1.1791, 0.9545,\n",
       "         1.0763, 1.1396, 1.2041, 1.1348, 0.8359, 1.1014, 1.3037, 1.0972, 1.1558,\n",
       "         0.8254, 1.1783, 1.0098, 1.1863, 0.9012, 0.4819, 0.8198, 1.1536, 1.1146,\n",
       "         1.4436, 1.4486, 1.0092, 1.1655, 1.0835, 0.9732, 1.3006, 1.1672, 1.0942,\n",
       "         1.0939, 1.1302, 1.2336, 0.6721, 0.8077], dtype=torch.float64),\n",
       " 'transformer_post.model.layers.0.sublayer.1.norm.b_2': tensor([ 0.1756,  0.0243,  0.1072, -0.0557,  0.1088,  0.0077, -0.1584,  0.1257,\n",
       "          0.0109,  0.0414,  0.0870, -0.0034,  0.2355,  0.0323, -0.0621,  0.0053,\n",
       "          0.0506, -0.0238,  0.0763,  0.0313, -0.0511,  0.0266,  0.0513,  0.0364,\n",
       "          0.0262, -0.0764, -0.0570,  0.1140, -0.0694, -0.0392, -0.0657,  0.2549,\n",
       "          0.3015, -0.1768,  0.0597,  0.1646,  0.0642, -0.1114, -0.0946, -0.0934,\n",
       "          0.0609,  0.2124, -0.0993,  0.1405,  0.1021, -0.1278, -0.0087,  0.0867,\n",
       "         -0.2900, -0.0451], dtype=torch.float64),\n",
       " 'transformer_post.model.norm.a_2': tensor([0.2759, 0.1403, 0.2019, 0.2071, 0.3490, 0.2623, 0.1517, 0.3572, 0.2702,\n",
       "         0.3185, 0.3710, 0.1710, 0.2483, 0.3755, 0.3139, 0.3894, 0.3420, 0.1400,\n",
       "         0.2163, 0.3324, 0.2428, 0.3920, 0.2289, 0.2690, 0.2993, 0.2479, 0.2395,\n",
       "         0.2849, 0.0594, 0.2037, 0.2444, 0.2595, 0.0634, 0.0143, 0.3621, 0.2408,\n",
       "         0.2591, 0.2303, 0.2952, 0.2460, 0.3837, 0.0294, 0.3331, 0.2686, 0.3846,\n",
       "         0.2280, 0.1083, 0.2268, 0.0718, 0.3231], dtype=torch.float64),\n",
       " 'transformer_post.model.norm.b_2': tensor([ 8.8116e-02,  2.7081e-04,  5.0955e-02,  8.6763e-03,  3.7975e-02,\n",
       "          2.4327e-02, -9.5271e-02,  5.8694e-02,  3.2517e-02,  8.9795e-03,\n",
       "          7.5094e-02,  2.5512e-03,  6.5243e-02,  6.4868e-02, -9.9371e-03,\n",
       "          9.7288e-03,  6.5648e-02,  5.6563e-03,  1.0377e-02,  8.2096e-03,\n",
       "         -9.9629e-03,  1.1772e-01,  2.3973e-02,  3.2990e-02, -1.8180e-03,\n",
       "         -8.2893e-03, -3.5093e-02,  7.9291e-02, -1.1179e-02, -6.8903e-03,\n",
       "         -1.2733e-02,  7.8232e-02,  2.1893e-01, -1.7347e-02,  1.9579e-02,\n",
       "          4.3779e-02,  1.6879e-02,  1.5397e-02, -2.1239e-02, -7.7239e-02,\n",
       "          6.5421e-02,  7.5959e-03, -1.9615e-02,  1.0410e-01, -3.9609e-03,\n",
       "         -1.8255e-02,  1.0781e-02,  4.4091e-02, -4.0004e-01, -1.7444e-02],\n",
       "        dtype=torch.float64),\n",
       " 'pos_encoding_h.embedding': tensor([[-1.3491e-01, -1.6219e-01, -7.9571e-02,  3.3553e-02, -4.3949e-01,\n",
       "          -1.6092e-01, -3.8298e-03,  3.2467e-01, -1.7095e-02,  1.2366e-01,\n",
       "          -1.9961e-01,  1.5284e-01,  2.0285e-01,  8.7552e-02, -5.6863e-01,\n",
       "           1.0799e-01,  3.4500e-01, -2.2167e-01, -1.8106e-01, -1.7468e-01,\n",
       "          -1.0910e-01, -1.0909e-01,  4.9588e-02, -2.3039e-01, -4.8572e-01,\n",
       "          -8.5587e-02,  2.2615e-01,  2.0085e-01,  4.8263e-02, -2.7526e-01,\n",
       "          -1.3097e-01,  4.1359e-02,  2.5874e-01,  2.3370e-01, -4.0156e-01,\n",
       "           1.6533e-01,  1.3246e-01,  3.6851e-01, -2.2438e-01,  2.5947e-01,\n",
       "          -1.5744e-01, -1.0300e-01,  1.2499e-01, -1.0215e-01, -3.3919e-01,\n",
       "           5.6628e-02, -1.5083e-01, -2.6339e-02,  2.2399e-01, -1.7358e-01],\n",
       "         [ 7.7217e-02,  3.2897e-02,  1.7798e-01, -6.5727e-02, -3.9229e-01,\n",
       "           2.2459e-01,  2.0977e-01, -1.9271e-01,  7.8287e-02, -4.6486e-02,\n",
       "           2.4288e-01,  2.8147e-02,  4.1011e-03,  1.6454e-01, -4.8084e-01,\n",
       "           1.8216e-01,  2.4246e-01,  1.6742e-01,  2.0035e-01, -3.0169e-03,\n",
       "           1.5232e-01,  1.1998e-02,  1.8991e-01, -3.4330e-02, -2.0911e-01,\n",
       "          -1.8684e-01, -1.6706e-01,  3.8329e-01, -1.5316e-01, -2.4600e-01,\n",
       "           1.2938e-01, -3.2200e-01,  1.8894e-01,  3.0245e-02, -2.1785e-01,\n",
       "           1.4390e-01, -4.8307e-02,  1.2537e-01, -2.0009e-01,  9.8149e-02,\n",
       "           1.7107e-01,  8.6138e-02,  2.8467e-02,  3.8208e-02,  2.3806e-01,\n",
       "           5.5270e-02,  2.3158e-01,  3.6265e-02, -2.5109e-01, -3.3838e-01],\n",
       "         [-1.2028e-01, -2.8259e-02,  2.3395e-01,  1.7609e-01, -3.0749e-01,\n",
       "          -8.9074e-02, -2.0362e-01,  1.8321e-01,  2.3838e-01, -1.8745e-01,\n",
       "           1.8019e-01,  1.9929e-01, -7.5604e-02,  1.5768e-01, -4.3445e-01,\n",
       "           4.7783e-02,  3.0206e-01,  1.3381e-01, -2.8506e-01,  2.9596e-01,\n",
       "          -3.1065e-02, -3.3208e-01,  1.7194e-02, -3.6025e-01, -4.2487e-01,\n",
       "          -3.5333e-02, -2.6428e-02,  2.9433e-01,  2.3559e-01,  1.4115e-02,\n",
       "           3.2934e-01, -1.8238e-01, -2.3299e-01,  7.7182e-02, -6.2949e-02,\n",
       "          -2.2210e-01, -2.2328e-01,  1.7337e-01, -1.1052e-01, -2.8581e-01,\n",
       "          -5.2197e-02,  1.9877e-01, -2.3972e-01, -6.3356e-02, -3.2333e-01,\n",
       "           3.5568e-02,  2.0145e-02,  1.2827e-01, -1.7636e-01, -2.1785e-01],\n",
       "         [-3.2192e-02, -3.0177e-01,  2.2906e-01, -2.3146e-01, -2.4867e-01,\n",
       "          -1.2334e-01, -9.9099e-02, -1.7587e-01,  8.3551e-02, -1.4848e-01,\n",
       "          -2.4515e-01, -2.5442e-03, -2.5152e-01, -2.2868e-01, -5.1945e-01,\n",
       "          -1.3420e-01, -3.6687e-02,  6.5146e-02,  2.5902e-01, -1.7001e-01,\n",
       "          -1.3078e-01, -3.7251e-02, -2.7841e-01, -2.4545e-01, -5.3518e-01,\n",
       "           2.0225e-01,  1.5631e-01,  3.9608e-01,  2.8180e-01,  1.4805e-01,\n",
       "           1.2780e-01, -2.3283e-01, -2.7397e-01,  2.0312e-01, -4.8217e-01,\n",
       "          -2.1584e-01,  2.2439e-01,  1.3789e-01, -4.8378e-02,  2.6707e-01,\n",
       "          -2.4612e-01,  5.3315e-02,  1.9045e-01, -1.4913e-01,  1.2612e-01,\n",
       "           3.2191e-01,  1.8337e-01,  2.9830e-01,  2.2741e-01, -3.9806e-01],\n",
       "         [ 1.3381e-01, -3.1524e-01,  9.4418e-02,  1.5759e-01, -4.5879e-01,\n",
       "          -3.9701e-02, -2.3335e-02, -6.2347e-02,  2.5591e-01, -2.4927e-01,\n",
       "          -2.6711e-01, -1.3142e-01,  1.9647e-02,  4.1157e-02, -4.1045e-02,\n",
       "          -2.0698e-01, -6.9125e-02, -3.6813e-01, -1.1572e-01, -1.6682e-01,\n",
       "          -1.4305e-01, -3.9950e-03,  1.1133e-01,  6.5083e-02, -3.0543e-01,\n",
       "           2.3472e-01,  8.4019e-02,  1.7270e-01,  1.6093e-01,  1.2441e-01,\n",
       "          -7.5667e-02,  1.5709e-01,  2.5958e-01, -1.7683e-01,  6.7149e-02,\n",
       "          -2.7296e-01,  8.7701e-02,  4.3718e-03,  1.4384e-02,  7.8575e-02,\n",
       "          -2.7783e-01, -5.6550e-02,  4.4970e-02, -1.8643e-01, -2.1338e-01,\n",
       "           1.7357e-01, -1.5186e-01, -1.8497e-02, -5.8389e-02, -1.9566e-01],\n",
       "         [ 1.3882e-02, -3.9489e-01,  9.3026e-02, -2.6923e-01, -5.3415e-01,\n",
       "          -3.3415e-03, -3.3715e-02, -2.5073e-01, -2.0361e-01,  2.2315e-01,\n",
       "           1.8513e-01, -1.5217e-01, -1.5048e-01,  1.2211e-01, -1.2840e-01,\n",
       "           1.4063e-01, -2.3966e-02, -1.6217e-01,  3.2979e-02, -4.4707e-02,\n",
       "          -2.2452e-01, -2.3277e-01, -1.0683e-01, -3.6358e-04, -4.2624e-01,\n",
       "          -1.3429e-01, -1.0165e-01,  3.3697e-01,  3.0196e-01,  4.9172e-02,\n",
       "          -9.0330e-02, -1.7256e-01,  8.6074e-02, -9.0897e-04, -3.8438e-01,\n",
       "          -1.0480e-01, -1.0964e-01,  3.8157e-01,  8.4270e-02,  1.8359e-01,\n",
       "          -2.0282e-01, -1.4784e-01,  1.4216e-01, -9.3354e-02, -2.3835e-01,\n",
       "          -7.9793e-02,  2.8057e-01,  3.0859e-01, -7.5355e-03, -1.0810e-01],\n",
       "         [-2.2226e-01, -2.4403e-01,  1.3771e-01, -2.5952e-01, -5.4601e-01,\n",
       "           9.8679e-02, -2.4127e-01,  2.3859e-01,  1.0029e-01, -1.7804e-01,\n",
       "           5.5992e-02, -2.2544e-01, -2.6497e-01, -1.3131e-01, -2.4218e-01,\n",
       "          -8.0752e-02, -7.4089e-03, -2.4752e-01, -7.8747e-02,  3.0152e-01,\n",
       "          -1.8183e-03, -4.4052e-02, -2.9832e-01, -3.0707e-01, -4.7235e-01,\n",
       "           1.0083e-01, -2.4488e-01,  6.8150e-02,  2.8532e-01, -2.5823e-01,\n",
       "           1.9381e-01, -4.8759e-02, -8.4956e-02, -4.8173e-03, -2.3664e-01,\n",
       "          -1.4220e-01, -2.0445e-02,  6.2753e-02,  4.3635e-02,  2.5976e-01,\n",
       "           2.5945e-01, -1.6324e-01, -1.3051e-01,  7.9158e-02,  1.4314e-01,\n",
       "          -1.3684e-01,  2.3818e-01,  1.8954e-01,  1.4831e-02, -9.7221e-02],\n",
       "         [ 1.2907e-01, -3.8641e-01,  2.7072e-01, -2.1348e-01, -3.8104e-01,\n",
       "          -9.8685e-02, -1.9089e-01,  1.1828e-01, -5.7315e-02, -8.6094e-02,\n",
       "          -4.9829e-02, -6.2522e-02, -2.8811e-01,  2.4537e-01, -3.0007e-01,\n",
       "          -3.1042e-02,  2.9942e-01, -3.0105e-02, -1.1637e-02,  2.2299e-03,\n",
       "          -2.5942e-01,  9.9783e-02, -2.4263e-01, -1.0759e-01, -3.3465e-01,\n",
       "           5.4870e-03,  3.9462e-02,  1.5052e-01,  1.1641e-01,  1.0213e-01,\n",
       "          -1.9832e-01,  1.7480e-01,  2.4970e-01,  9.5212e-02, -2.3151e-01,\n",
       "           1.1721e-01,  2.2484e-01, -8.5785e-02, -1.7396e-01,  2.2586e-02,\n",
       "           1.2803e-01,  2.5088e-01,  2.7865e-01,  1.1769e-01, -4.1361e-02,\n",
       "           9.9877e-02,  1.6149e-01, -7.4142e-02,  2.2431e-01,  9.5297e-02],\n",
       "         [-1.0245e-01, -4.5760e-01, -7.5990e-02, -2.2014e-01, -2.9109e-01,\n",
       "           9.8285e-03, -1.9797e-01, -7.1383e-02, -4.5000e-02, -1.8215e-01,\n",
       "          -1.7584e-01,  2.2543e-01, -1.8037e-01,  1.1232e-01, -2.3692e-01,\n",
       "           2.5271e-01,  3.9577e-01,  1.9276e-01, -7.3287e-02,  2.2889e-01,\n",
       "           6.4021e-02, -1.9066e-01, -2.4936e-01, -1.2315e-01, -5.0867e-01,\n",
       "           2.3898e-01, -5.6688e-02,  5.7081e-02,  1.4165e-01,  1.8825e-01,\n",
       "          -2.0120e-01, -2.5115e-01, -1.1104e-01, -1.9987e-01, -1.5182e-01,\n",
       "          -3.2235e-01, -1.5317e-01,  4.1275e-01, -5.0460e-02, -1.1540e-01,\n",
       "          -3.8176e-02,  1.8723e-01, -1.0201e-01,  2.5153e-01, -2.2419e-01,\n",
       "          -9.3209e-02,  1.9926e-01,  8.1972e-02, -2.0998e-03,  5.9137e-02],\n",
       "         [ 1.9105e-01, -1.6324e-01, -1.6771e-01, -2.5494e-01, -1.8482e-02,\n",
       "           1.4590e-01, -1.2945e-01,  9.6973e-02, -2.0423e-01,  6.2483e-02,\n",
       "          -1.4186e-01,  2.3980e-01,  1.8424e-01, -2.4791e-01, -2.0002e-01,\n",
       "           2.3416e-01,  6.5310e-02,  1.9614e-01,  3.1466e-01,  2.6690e-01,\n",
       "           1.0233e-01, -2.7757e-01,  1.4693e-01, -1.2351e-01, -5.1717e-01,\n",
       "          -1.1864e-01, -2.1412e-02,  2.2666e-01,  3.6686e-01,  3.0409e-01,\n",
       "           3.2304e-01, -4.5802e-02, -1.0264e-02, -1.6654e-01,  7.4647e-02,\n",
       "          -1.3016e-01, -9.9813e-02,  2.0793e-01,  2.1021e-01,  2.1248e-01,\n",
       "          -1.1045e-01, -3.0603e-03, -2.5896e-02, -1.5281e-01,  1.3609e-01,\n",
       "          -1.5257e-01,  3.2347e-01, -1.2433e-01,  1.2421e-01, -2.0483e-02],\n",
       "         [ 9.8329e-02, -3.9485e-01,  2.2809e-01, -2.3120e-01, -2.4925e-01,\n",
       "           1.6784e-01,  1.6604e-01, -1.3462e-01, -1.9071e-01,  1.6186e-01,\n",
       "          -1.0784e-01, -8.5609e-03, -2.5817e-01, -2.1607e-01, -1.7961e-01,\n",
       "           5.2447e-02,  1.4882e-01,  3.6909e-02,  3.1685e-01,  1.4188e-01,\n",
       "           1.8631e-01, -7.2622e-02,  2.7457e-01,  1.4720e-01, -3.0590e-01,\n",
       "          -1.5916e-01,  6.1357e-02,  1.5219e-01,  7.2782e-02,  3.0303e-01,\n",
       "          -1.1215e-01, -6.1433e-02,  1.1069e-01,  1.3906e-01, -2.8546e-01,\n",
       "          -2.4109e-01,  2.7543e-01, -9.0732e-02,  2.4648e-01,  1.9688e-01,\n",
       "          -7.9842e-02, -2.0417e-01, -1.0785e-01, -1.6730e-01,  2.0090e-03,\n",
       "           7.2515e-02,  7.6755e-02,  1.4713e-01,  2.5600e-01, -2.5667e-01],\n",
       "         [ 1.3526e-01, -1.9438e-01, -9.9181e-02, -2.8509e-02, -3.8252e-01,\n",
       "           8.7709e-02, -8.3121e-03,  1.2175e-01,  2.9917e-01,  1.0926e-01,\n",
       "           2.0256e-01, -3.1622e-02,  1.0901e-01,  6.1215e-02, -1.7478e-01,\n",
       "           2.2036e-01,  3.3050e-01, -2.9216e-01,  2.2916e-01,  2.7414e-01,\n",
       "          -1.4239e-02, -2.8770e-01, -4.6790e-02,  1.6440e-01, -3.8768e-01,\n",
       "          -2.2018e-01, -2.6217e-01,  1.4879e-01,  3.8091e-01, -2.2864e-01,\n",
       "           5.5376e-02, -7.5769e-02,  1.6902e-01, -2.3315e-01,  7.1454e-02,\n",
       "          -1.4711e-02,  2.2848e-01, -1.2334e-01,  1.4494e-01, -2.2099e-01,\n",
       "          -2.9347e-02,  3.9167e-02, -2.6647e-01, -1.4729e-01,  2.0004e-01,\n",
       "          -2.0218e-01, -8.3898e-02, -1.1793e-01,  2.4879e-01, -1.9587e-01],\n",
       "         [ 2.0243e-01, -5.4006e-01,  8.1690e-02, -3.1395e-01,  2.7926e-02,\n",
       "           2.1094e-02,  1.4188e-01,  2.7748e-01,  2.8134e-01,  2.2645e-01,\n",
       "          -3.9145e-02, -9.9697e-02,  1.0976e-01,  7.1388e-02, -2.6890e-01,\n",
       "           2.9197e-01,  3.2388e-02,  5.9574e-02, -1.2412e-01,  9.9392e-02,\n",
       "           3.9801e-02, -2.4314e-01, -2.2253e-01, -2.7985e-01, -5.4432e-01,\n",
       "           9.2158e-02, -3.3850e-01,  4.8962e-01,  1.3600e-02, -1.5749e-01,\n",
       "           3.2160e-01, -4.0455e-02, -9.0731e-03, -2.3271e-01, -1.1874e-01,\n",
       "          -1.7130e-02, -1.7461e-01,  3.0836e-01, -1.0396e-01, -5.9250e-02,\n",
       "           2.4139e-01, -3.1707e-01, -1.7482e-01,  2.1998e-01, -3.2642e-01,\n",
       "           2.5874e-01, -1.5495e-01, -8.3324e-02, -1.4933e-02,  3.2895e-03],\n",
       "         [ 2.5375e-02, -5.4403e-01,  2.4315e-01,  5.3040e-02, -3.3576e-01,\n",
       "          -8.0456e-02, -3.6991e-01,  9.7254e-02,  2.5704e-02,  2.3317e-01,\n",
       "          -1.4142e-01, -2.4543e-01, -1.4139e-01,  1.5625e-01, -1.4465e-01,\n",
       "           1.4958e-01,  2.6568e-02, -1.7056e-01,  1.5513e-01,  1.7859e-01,\n",
       "           1.0539e-01, -8.1980e-02,  2.0859e-01, -8.0001e-02, -2.5654e-01,\n",
       "           1.2358e-01, -3.7374e-02, -6.7321e-03,  1.0015e-02,  1.0655e-01,\n",
       "           2.1159e-01, -2.2681e-01, -6.2907e-02, -1.9897e-01,  9.1389e-02,\n",
       "          -3.4058e-01,  2.8250e-01, -2.5367e-02,  3.2020e-01, -1.9883e-01,\n",
       "           1.5526e-01,  2.3177e-01,  2.9080e-01, -2.0109e-01, -1.0724e-01,\n",
       "           3.6577e-02,  8.2105e-02, -9.9685e-02, -3.8174e-02,  6.4452e-02],\n",
       "         [ 1.3576e-01, -2.8014e-01,  3.4463e-01,  1.7347e-01, -3.7882e-01,\n",
       "          -2.4247e-01, -2.5558e-01,  1.8826e-01,  1.9296e-01, -2.0811e-01,\n",
       "          -2.6162e-01,  1.5819e-01, -2.9826e-01, -1.7428e-01, -3.5434e-01,\n",
       "          -1.1923e-01, -1.1987e-01,  7.0728e-02,  1.4070e-01,  1.4043e-01,\n",
       "           4.5254e-02,  3.9108e-02,  1.9554e-01, -1.6453e-01, -5.1780e-01,\n",
       "           1.0060e-01, -1.7207e-01,  1.9466e-02,  4.1994e-01, -1.3497e-01,\n",
       "          -1.5096e-01, -2.5599e-01, -1.0308e-01, -8.2583e-02,  1.0657e-03,\n",
       "          -2.4412e-01, -1.1416e-01,  2.7614e-01,  1.4278e-01, -2.0086e-02,\n",
       "           1.4223e-01, -2.8889e-01, -6.3739e-02, -1.6054e-01, -1.4596e-01,\n",
       "          -1.3127e-01, -4.1975e-02, -2.0349e-01, -1.8260e-01, -4.6159e-01],\n",
       "         [-1.6214e-01, -2.3365e-01,  2.9330e-01,  2.0728e-01, -2.9540e-01,\n",
       "           1.3294e-01, -2.2764e-01, -2.5544e-01,  2.1211e-01, -1.9195e-02,\n",
       "           5.0741e-02, -1.8748e-01, -2.7367e-02,  1.0967e-01, -1.0473e-01,\n",
       "           6.7006e-02,  2.1969e-01, -3.4744e-01,  2.0134e-03,  3.7916e-01,\n",
       "           2.1798e-01, -2.8638e-01,  1.1499e-01, -2.8745e-01, -2.8805e-01,\n",
       "           2.9323e-01, -2.7742e-01,  8.7894e-02, -9.6766e-02,  3.7882e-02,\n",
       "           1.1513e-03, -2.8419e-01,  8.4976e-02, -8.6278e-02, -2.3753e-02,\n",
       "          -7.8732e-02,  1.0228e-02,  3.5891e-01,  3.3242e-01,  2.2035e-01,\n",
       "          -9.6506e-02, -5.8981e-02, -4.1128e-02,  1.5116e-01, -2.4269e-01,\n",
       "           1.0477e-01,  1.1111e-01, -2.0970e-01,  2.3595e-01, -1.5303e-01],\n",
       "         [ 4.2884e-02, -2.3573e-01,  3.6214e-01,  1.3629e-02, -3.5454e-01,\n",
       "           2.0946e-01,  6.9490e-02,  1.7709e-01, -1.4181e-02,  6.7264e-02,\n",
       "          -1.0246e-01, -1.7047e-01,  1.7162e-01,  1.3803e-01, -3.9895e-01,\n",
       "          -4.8998e-02,  1.0873e-01, -1.3252e-01,  5.4489e-03,  3.6259e-01,\n",
       "          -1.0028e-01, -2.4258e-01, -2.3661e-01,  2.3228e-01, -3.0758e-01,\n",
       "          -3.3931e-02, -2.3229e-01,  5.1340e-01,  2.8650e-01,  8.9177e-02,\n",
       "          -1.0177e-01,  2.7442e-02,  5.1924e-02, -1.9425e-01, -2.5291e-01,\n",
       "           4.6309e-02, -1.7950e-01,  2.4690e-01,  5.9915e-02,  1.0691e-01,\n",
       "           1.0548e-01, -1.0133e-01, -8.5496e-02, -9.9613e-02, -2.3524e-02,\n",
       "           1.4427e-01, -1.7953e-01, -1.2068e-01, -8.3609e-02, -3.8724e-01],\n",
       "         [ 5.5609e-02, -2.9415e-02,  3.1579e-01, -5.4209e-02,  2.4742e-02,\n",
       "           7.5592e-02, -1.2854e-01,  4.6541e-02,  1.4090e-01, -3.0625e-02,\n",
       "          -1.9894e-01, -2.1541e-01, -1.5581e-01,  8.6798e-02, -1.1464e-01,\n",
       "          -2.3813e-01,  3.8791e-02, -1.2759e-01,  2.2741e-01,  2.4705e-01,\n",
       "          -2.4141e-01, -2.9417e-01,  2.3546e-01, -2.0046e-01, -5.0566e-01,\n",
       "           2.7358e-01,  1.8250e-02,  1.2461e-01,  4.7371e-01,  5.1100e-03,\n",
       "          -1.8148e-01, -2.7433e-01, -1.4427e-01, -2.3904e-01, -1.9107e-01,\n",
       "          -2.0390e-01,  6.3785e-02,  2.8309e-01, -4.7703e-02,  2.4840e-01,\n",
       "          -1.1226e-02,  7.5062e-02, -2.2223e-01, -1.3184e-01, -1.6342e-01,\n",
       "           8.6357e-02,  1.1970e-01, -1.4520e-01,  4.0770e-02, -4.3167e-01],\n",
       "         [ 1.1392e-01, -3.2811e-01,  3.1462e-01,  1.8450e-01,  4.4200e-02,\n",
       "           1.9073e-01, -3.6740e-01, -2.0395e-01,  3.1003e-01,  1.3527e-01,\n",
       "           3.9888e-02, -2.2681e-01, -7.5546e-02,  1.7342e-01, -3.3271e-01,\n",
       "           2.2267e-01,  3.4803e-01, -1.2832e-01, -1.7683e-01,  3.0906e-02,\n",
       "          -3.1687e-01, -1.3778e-01,  1.3697e-01,  3.6062e-02, -4.2118e-01,\n",
       "           8.2472e-02,  4.8343e-02,  1.9235e-01,  2.2160e-01, -1.7911e-01,\n",
       "           2.6934e-01,  1.5762e-01,  2.7800e-01, -1.8039e-01,  1.5928e-01,\n",
       "          -2.1172e-01, -2.1262e-01,  2.4625e-01,  1.6024e-01, -3.0531e-01,\n",
       "          -3.7997e-02,  7.5601e-02, -2.4597e-01, -6.4342e-02, -3.5693e-02,\n",
       "           1.6430e-01,  8.1228e-02, -1.2850e-01,  2.6371e-01, -3.4114e-01],\n",
       "         [ 1.8379e-01, -4.7698e-01,  1.8521e-01, -6.3544e-02, -9.9024e-02,\n",
       "          -6.7137e-02,  1.4495e-01,  2.2328e-02, -9.6754e-02,  8.5006e-02,\n",
       "          -7.2244e-02, -2.2436e-01, -1.6953e-01,  2.4956e-01, -1.5823e-01,\n",
       "           1.9617e-01, -3.6257e-02,  9.1774e-02,  3.2952e-01,  3.2566e-01,\n",
       "           2.0360e-01, -6.9524e-02,  2.6537e-01,  3.3157e-02, -3.5515e-01,\n",
       "          -1.7567e-01, -2.0362e-02,  4.4885e-01,  4.5602e-01,  3.3181e-01,\n",
       "          -9.1682e-02, -1.3928e-01, -1.4676e-01,  2.7602e-01, -1.4129e-01,\n",
       "          -4.0722e-01, -1.5179e-01,  3.9898e-02,  2.1743e-01,  3.0415e-02,\n",
       "           1.1476e-02,  2.1035e-01,  2.0935e-02,  2.1683e-01, -2.0758e-01,\n",
       "           2.0129e-01, -1.3374e-01,  2.8983e-01,  3.7901e-02, -4.5193e-01]],\n",
       "        dtype=torch.float64),\n",
       " 'pos_encoding_h.mu': tensor([[-0.1526,  0.1080,  0.8583,  0.9376,  1.0746,  1.4060,  1.4354,  1.7240,\n",
       "           2.1845,  1.8806,  2.7055,  2.6925,  2.9234,  3.1889,  3.5168,  3.6268,\n",
       "           3.9821,  4.4399,  4.3673,  5.1107]], dtype=torch.float64),\n",
       " 'pos_encoding_h.sigma': tensor([[50.1765, 49.8358, 49.8770, 50.1453, 50.2778, 50.1671, 49.7882, 50.2446,\n",
       "          49.9990, 49.8701, 50.2477, 50.2880, 49.8038, 49.7671, 50.1883, 49.8410,\n",
       "          49.7972, 50.0971, 49.7716, 49.8978]], dtype=torch.float64),\n",
       " 'pos_encoding_v.embedding': tensor([[ 0.5327, -0.1264,  0.2521, -0.1179, -0.0154],\n",
       "         [-0.0643,  0.1180, -0.0731, -0.0720,  0.1577],\n",
       "         [-0.4147,  0.3104, -0.2441, -0.0071,  0.4518],\n",
       "         [ 0.2447, -0.5136,  0.1635,  0.4781, -0.1212],\n",
       "         [ 0.0044, -0.1077, -0.4024,  0.8099,  0.4815],\n",
       "         [ 0.0815, -0.1145, -0.5608, -0.1233,  0.3327],\n",
       "         [ 0.1239, -0.2456,  0.0095,  0.0105, -0.1555],\n",
       "         [-0.4914, -0.3202,  0.0977,  0.3607,  0.1018],\n",
       "         [ 0.0107, -0.2551, -0.2820,  0.6339,  0.2788],\n",
       "         [ 0.2208, -0.1039, -0.0236,  0.1982, -0.2909],\n",
       "         [-0.2445,  0.3669, -0.0382,  0.4826, -0.2511],\n",
       "         [ 0.3013, -0.4723, -0.5165, -0.0598,  0.7333],\n",
       "         [-0.0487,  0.1069, -0.2449,  0.3766,  0.4098],\n",
       "         [-0.2030, -0.3615,  0.2578,  0.2654,  0.0256],\n",
       "         [-0.0607, -0.3729, -0.0369,  0.0728,  0.2560],\n",
       "         [-0.0281,  0.2274, -0.1905,  0.3557,  0.0028],\n",
       "         [ 0.2033, -0.5889, -0.2621,  0.4506, -0.2165],\n",
       "         [-0.0269,  0.1044, -0.4240,  0.1340, -0.0040],\n",
       "         [ 0.0211, -0.3402, -0.4845,  0.6078,  0.4351],\n",
       "         [-0.1824,  0.0761,  0.2828, -0.1588,  0.4435]], dtype=torch.float64),\n",
       " 'pos_encoding_v.mu': tensor([[-0.2589,  2.7759,  5.3338,  7.2650,  9.9738, 12.6493, 15.0096, 17.3109,\n",
       "          20.0400, 22.3177, 25.0111, 27.4420, 30.2244, 32.6991, 35.3245, 37.4113,\n",
       "          40.6421, 42.1848, 44.8767, 46.8556]], dtype=torch.float64),\n",
       " 'pos_encoding_v.sigma': tensor([[49.8329, 50.3470, 50.0658, 50.0566, 50.0204, 50.4824, 50.1597, 50.3050,\n",
       "          50.1374, 50.1607, 50.5467, 49.8467, 50.0769, 50.3739, 50.5153, 50.1054,\n",
       "          50.6204, 50.2807, 49.7973, 50.6623]], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.self_attn.linears.0.weight': tensor([[ 0.4160, -0.0469, -0.4019,  0.2277, -0.0243],\n",
       "         [ 0.3415,  0.2949,  0.3902, -0.2110, -0.2388],\n",
       "         [-0.1448,  0.0976, -0.1009, -0.0445,  0.0232],\n",
       "         [ 1.0999,  0.0335,  0.1375,  0.1498, -0.4431],\n",
       "         [ 0.1919, -0.4719,  0.1229, -0.3156,  0.2551]], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.self_attn.linears.0.bias': tensor([ 0.1842, -0.6354,  0.4970,  0.2169, -0.0045], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.self_attn.linears.1.weight': tensor([[ 0.5258,  0.1239, -0.2054, -0.2020, -0.0086],\n",
       "         [ 0.0982,  0.6290,  0.7971, -0.6703, -0.0306],\n",
       "         [-0.4375,  0.1640,  0.1311, -0.1592,  0.1673],\n",
       "         [ 0.6859,  0.0649, -0.3855, -0.1650,  0.7458],\n",
       "         [-0.1071, -0.0177,  0.7951, -0.2719, -0.0554]], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.self_attn.linears.1.bias': tensor([ 0.2656, -0.2895,  0.1534,  0.1680,  0.1456], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.self_attn.linears.2.weight': tensor([[-0.0451, -0.1692, -0.0352, -0.0318,  0.1283],\n",
       "         [ 0.3739,  0.2462,  0.3101,  0.0209, -0.3587],\n",
       "         [ 0.2160, -0.0728, -0.0816, -0.1630,  0.0123],\n",
       "         [ 0.2723,  0.0211, -0.0201, -0.0106,  0.5489],\n",
       "         [ 0.0856, -0.0498, -0.1208, -0.3371,  0.2661]], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.self_attn.linears.2.bias': tensor([ 0.1546, -0.0401,  0.2630,  0.1532, -0.0024], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.self_attn.linears.3.weight': tensor([[ 0.1070,  0.1176, -0.3086, -0.0642,  0.1035],\n",
       "         [ 0.2894,  0.0300,  0.2929,  0.0154, -0.1991],\n",
       "         [-0.1579, -0.1216,  0.0784, -0.1781,  0.2999],\n",
       "         [ 0.2463,  0.4568, -0.0785, -0.1394,  0.4057],\n",
       "         [ 0.1418, -0.1221, -0.1072, -0.2812,  0.0501]], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.self_attn.linears.3.bias': tensor([ 0.0911, -0.1023,  0.0396,  0.2096,  0.0463], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.feed_forward.bn.weight': tensor([0.5352, 0.7740, 0.8644, 0.7946, 1.0678], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.feed_forward.bn.bias': tensor([-0.6129, -0.3500, -0.3679, -0.4640, -0.0491], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.feed_forward.bn.running_mean': tensor([-0.0281,  0.0648, -0.0246, -0.1083, -0.0227], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.feed_forward.bn.running_var': tensor([0.0126, 0.0405, 0.0058, 0.0445, 0.0305], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.feed_forward.bn.num_batches_tracked': tensor(213030),\n",
       " 'v_transformer.model.layers.0.feed_forward.encoder_0.weight_ih_l0': tensor([[ 0.0497,  0.4852, -0.0853,  0.2333,  0.0349],\n",
       "         [ 0.0636,  0.2932,  0.0061,  0.3992, -0.3003],\n",
       "         [-0.4061,  0.6303,  0.3690,  0.1643,  0.1428],\n",
       "         [-0.5606,  0.1860,  0.3091,  0.4689,  0.0906],\n",
       "         [ 0.4798,  0.5643,  0.5701, -0.3601, -0.1485],\n",
       "         [-0.0114,  0.6809,  0.0037, -0.0271, -0.1961],\n",
       "         [-0.3228,  0.2052, -0.3829,  0.2897,  0.2112],\n",
       "         [ 0.3216,  0.2646,  0.7202, -0.4501, -0.2485],\n",
       "         [-0.0301, -0.0509,  0.5469, -0.1630,  0.2271],\n",
       "         [-0.8981,  0.3959,  0.4238, -0.4565, -0.3523],\n",
       "         [-0.1227,  0.6942,  0.0215, -0.0585, -0.0788],\n",
       "         [ 0.2209,  0.1291, -0.3113,  0.2994, -0.5783],\n",
       "         [ 0.0413,  0.1052,  0.1202, -0.1330, -0.3325],\n",
       "         [ 0.7455,  0.2388,  0.2730,  0.2615, -0.1982],\n",
       "         [-0.2949,  0.2926, -0.5405, -0.1458, -0.0882],\n",
       "         [-0.4495, -0.5329, -0.4872, -0.1271,  0.5739],\n",
       "         [-0.3005,  0.0897,  0.2025, -0.2563, -0.6276],\n",
       "         [-0.2387, -0.0471,  0.1721, -0.4224,  0.2103],\n",
       "         [-0.0790,  0.4242,  0.0775,  0.5329, -0.2604],\n",
       "         [ 0.0477, -0.4637, -0.0290, -0.3110,  0.0546]], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.feed_forward.encoder_0.weight_hh_l0': tensor([[ 0.5056,  0.9158,  0.3683,  0.3324,  0.4752],\n",
       "         [ 0.0103,  0.2272,  0.2960,  0.3499,  0.3268],\n",
       "         [ 0.2812,  0.0306, -0.3692,  0.6021, -0.3734],\n",
       "         [ 0.1141, -0.6146, -0.0032,  0.1490,  0.0755],\n",
       "         [ 0.4485, -0.3579, -0.0679, -0.3174,  0.2049],\n",
       "         [ 0.4216,  0.0892, -0.4985,  0.1654, -0.8197],\n",
       "         [-0.1302,  0.3547,  0.4885,  0.1495,  0.1976],\n",
       "         [ 0.1066,  0.6309, -0.0513,  0.0976, -0.4921],\n",
       "         [ 0.3673, -0.3027,  0.4135, -0.1243, -0.4076],\n",
       "         [ 0.1649, -0.2865,  0.0755, -0.4324,  0.7348],\n",
       "         [ 0.0115, -0.0213, -0.2771, -0.3121,  0.3161],\n",
       "         [-0.5540, -0.2017,  0.1632, -0.1873,  0.4646],\n",
       "         [-0.2951,  0.0790, -0.1825,  0.0324, -0.4529],\n",
       "         [ 0.3302, -0.2289,  0.0418,  0.2976, -0.2130],\n",
       "         [-0.1368, -0.4830,  0.3443, -0.3060,  0.7116],\n",
       "         [ 0.2098, -0.0862,  0.0606,  0.0197,  0.3320],\n",
       "         [-0.0560, -0.3073,  0.2116,  0.0750,  0.5881],\n",
       "         [ 0.5471, -0.0701, -0.3874,  0.2565,  0.3563],\n",
       "         [ 0.1097, -0.8945,  0.5443, -0.5050,  0.5019],\n",
       "         [ 0.2222, -0.6958,  0.7898, -0.2721,  0.0841]], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.feed_forward.encoder_0.bias_ih_l0': tensor([ 0.2789, -0.4896, -0.0280,  0.2953,  0.1164, -0.5670,  0.1357,  0.2362,\n",
       "         -0.3528,  0.3651, -0.0578, -0.0366,  0.3998,  0.0489, -0.4153,  0.3659,\n",
       "          0.0261, -0.1576,  0.2785,  0.7470], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.feed_forward.encoder_0.bias_hh_l0': tensor([-0.0530, -0.5447, -0.2998, -0.1180,  0.2802, -0.4862,  0.4705,  0.4994,\n",
       "         -0.2977,  0.2908,  0.2080, -0.3834,  0.3302,  0.2585, -0.4328,  0.1438,\n",
       "         -0.5025, -0.3531,  0.3688,  0.7382], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.feed_forward.encoder_1.weight_ih_l0': tensor([[-3.4766e-01, -4.0840e-01, -3.5177e-01,  1.4552e-01,  3.4426e-01],\n",
       "         [-3.9740e-01,  7.5505e-01, -1.6084e-01,  3.0193e-02, -3.2789e-01],\n",
       "         [-4.7916e-01,  5.1382e-01, -2.9577e-01,  6.4840e-02, -2.2479e-01],\n",
       "         [-3.8030e-01,  2.7974e-01, -6.1479e-01,  6.7485e-01,  3.1751e-01],\n",
       "         [-3.3090e-01,  5.7824e-01, -5.8123e-02,  2.8250e-01, -2.1866e-02],\n",
       "         [-1.1726e-01,  2.0817e-01,  8.4377e-01, -2.8748e-01, -5.3211e-01],\n",
       "         [-2.0544e-01,  1.6126e-01,  2.7772e-02, -1.7726e-01, -2.9759e-01],\n",
       "         [ 2.9079e-01,  5.5681e-01,  3.8664e-01, -3.6286e-01, -2.9949e-01],\n",
       "         [-6.5044e-02,  7.6237e-01,  8.5372e-02, -9.3033e-01, -5.6436e-02],\n",
       "         [-9.6456e-02,  7.1810e-02,  3.3465e-01,  2.0247e-01, -2.8732e-01],\n",
       "         [-3.0442e-01, -1.5453e-01,  5.5046e-01, -4.0765e-01, -2.7899e-01],\n",
       "         [ 3.0244e-01, -4.9078e-01, -1.9659e-01, -1.2511e-01, -2.5796e-01],\n",
       "         [-3.7190e-02, -4.5033e-02,  2.1582e-01, -1.9267e-01, -9.2704e-02],\n",
       "         [ 6.2767e-01, -4.9401e-02,  4.3735e-03, -1.6160e-01, -3.8557e-01],\n",
       "         [ 3.9195e-01, -8.2082e-01,  2.4370e-01,  2.5675e-01,  4.3636e-01],\n",
       "         [-2.7522e-01, -2.5020e-01,  2.7331e-01, -6.3822e-01,  2.6773e-01],\n",
       "         [-3.9718e-01,  6.0298e-02, -2.4018e-01, -2.0755e-01, -3.1433e-01],\n",
       "         [ 6.1398e-04,  4.2434e-01, -8.2924e-02, -5.0091e-01,  2.4196e-02],\n",
       "         [-6.3860e-01, -3.4562e-01, -3.9401e-01,  1.0065e+00,  5.7744e-01],\n",
       "         [ 2.7095e-01, -2.5206e-01, -5.5990e-02, -1.8576e-01,  1.6136e-01]],\n",
       "        dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.feed_forward.encoder_1.weight_hh_l0': tensor([[ 4.9223e-01, -3.2888e-01, -2.6375e-02, -6.7718e-01,  3.2217e-01],\n",
       "         [ 2.3922e-01, -2.2843e-01, -2.0864e-01,  3.6760e-01,  2.8143e-01],\n",
       "         [ 3.4362e-01,  5.4663e-01, -1.1782e-01,  5.2714e-01,  4.8882e-01],\n",
       "         [ 1.5733e-01, -5.5104e-01, -6.5637e-01, -7.8710e-01,  3.5868e-01],\n",
       "         [ 3.8312e-01,  9.2714e-01,  6.9054e-01, -2.6397e-02, -3.3940e-01],\n",
       "         [ 4.6443e-01, -3.5034e-02, -2.7410e-01, -4.7964e-01,  1.9601e-01],\n",
       "         [ 2.2379e-01,  1.9388e-02, -5.1912e-02,  1.0948e+00, -2.3007e-01],\n",
       "         [ 2.3192e-01,  9.6794e-02, -1.8357e-01, -2.4955e-02,  6.9342e-01],\n",
       "         [ 4.1164e-01, -4.3581e-01, -1.6862e-01,  9.0032e-01, -3.4524e-01],\n",
       "         [-1.9429e-01,  3.3344e-01,  2.8146e-01, -1.8675e-01, -1.1118e-01],\n",
       "         [-1.1662e-03,  6.6036e-01, -2.0191e-01, -7.3215e-02, -9.0625e-02],\n",
       "         [ 2.9706e-01, -2.7695e-05,  3.2438e-01,  2.3863e-01,  8.6241e-02],\n",
       "         [ 5.6718e-01,  5.3239e-01,  2.7347e-01,  7.3556e-02,  8.3508e-01],\n",
       "         [-3.6471e-01, -1.0629e-02,  1.2009e-01, -4.3566e-01, -2.1257e-01],\n",
       "         [ 2.7654e-01,  5.7026e-02, -1.7458e-02,  7.7070e-02, -1.4012e-01],\n",
       "         [ 3.3644e-01, -1.0814e-01, -4.0082e-01, -5.4936e-01, -5.4917e-02],\n",
       "         [ 3.3598e-05,  3.5005e-01,  7.0924e-01, -1.2162e-01,  4.9191e-02],\n",
       "         [ 4.1922e-01, -2.0841e-01,  2.3982e-01, -1.0784e-01,  1.7018e-01],\n",
       "         [ 1.5746e-01,  1.5156e-01,  1.4752e-01, -1.6643e-01,  4.4866e-01],\n",
       "         [-3.5706e-02,  8.0602e-01,  2.1571e-01, -6.3769e-01,  4.4113e-01]],\n",
       "        dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.feed_forward.encoder_1.bias_ih_l0': tensor([ 0.1339, -0.0900, -0.4756,  0.1713, -0.1283, -0.4396,  0.1912,  0.0817,\n",
       "         -0.3797,  0.5611,  0.1770,  0.4023,  0.4854,  0.2294,  0.2189,  0.3171,\n",
       "          0.4786,  0.1410, -0.2852,  0.6180], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.feed_forward.encoder_1.bias_hh_l0': tensor([ 0.1640, -0.0167, -0.1501, -0.2133,  0.1969, -0.1435,  0.3276,  0.1873,\n",
       "         -0.3340, -0.0990, -0.3796, -0.1422,  0.3346,  0.0502, -0.3853,  0.3003,\n",
       "          0.5422,  0.2423,  0.1541,  0.9282], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.feed_forward.encoder_2.weight_ih_l0': tensor([[ 7.2383e-03,  7.0492e-03,  1.2908e-01,  8.4636e-02,  5.6220e-04],\n",
       "         [ 1.0992e+00,  2.1678e-02, -8.9137e-01, -3.8447e-01,  4.2949e-01],\n",
       "         [-6.1229e-01, -1.4030e-01,  3.7656e-01,  8.2961e-02,  1.9739e-01],\n",
       "         [-1.3219e-01, -3.2308e-02, -2.4468e-01, -5.4926e-02, -9.6013e-02],\n",
       "         [ 1.6592e-02, -1.1579e-01,  5.2784e-01, -4.1808e-01,  1.6315e-01],\n",
       "         [-6.5215e-01,  2.7679e-02,  2.9069e-01, -1.9859e-01, -1.0137e-01],\n",
       "         [-9.4447e-02, -7.9465e-02, -3.0710e-01, -8.2169e-02,  1.2501e-01],\n",
       "         [ 1.6688e-01, -1.5576e-01, -9.5687e-02, -3.7669e-01, -1.9794e-01],\n",
       "         [ 5.6004e-01, -3.7421e-01,  5.7368e-01, -8.7289e-02,  4.1971e-02],\n",
       "         [ 4.6998e-01,  4.0852e-01, -2.7404e-01,  1.5239e-02, -4.2551e-01],\n",
       "         [-1.3522e-01,  2.1227e-01, -1.6453e-01,  2.2152e-01,  4.9033e-02],\n",
       "         [-5.6060e-01, -2.0536e-01,  1.7991e-01,  2.5234e-01,  5.4618e-01],\n",
       "         [-2.3953e-02,  1.3649e-01, -2.4118e-01, -4.2697e-01, -2.2731e-01],\n",
       "         [-7.3137e-01,  4.9634e-01,  6.1792e-02,  1.7305e-01,  1.7260e-01],\n",
       "         [-3.5370e-03,  4.1391e-01, -2.5152e-01,  1.6751e-01,  1.7031e-01],\n",
       "         [ 1.7039e-01,  1.8703e-01,  2.7807e-01,  3.5318e-01,  3.1261e-01],\n",
       "         [ 7.2862e-01, -3.7166e-01, -3.3871e-01, -7.9425e-03,  3.8358e-01],\n",
       "         [ 4.7288e-01, -3.4422e-01, -2.4034e-01,  1.0755e-01, -1.0752e-04],\n",
       "         [-1.6106e-01, -3.1043e-01,  3.4660e-01,  9.3837e-02, -3.6829e-01],\n",
       "         [ 3.4278e-02,  3.6318e-01,  1.0413e-01, -3.8034e-01, -4.1979e-01]],\n",
       "        dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.feed_forward.encoder_2.weight_hh_l0': tensor([[ 1.6746e-01,  1.4654e-01,  2.2947e-01,  2.7667e-01,  2.2099e-01],\n",
       "         [-6.4881e-01,  1.8272e-01,  1.4698e-01, -1.8421e-01,  1.9506e-01],\n",
       "         [-1.4727e-01, -2.7449e-01,  8.0296e-01,  6.1304e-01,  4.5634e-01],\n",
       "         [ 1.6157e-01, -9.0902e-01, -7.8162e-01, -2.5639e-01, -2.0680e-02],\n",
       "         [-2.8320e-01, -1.8962e-01,  7.3431e-02,  1.6096e-01,  6.9354e-01],\n",
       "         [ 6.4639e-02, -5.1736e-01, -2.0524e-02,  8.4268e-02, -9.6702e-02],\n",
       "         [-1.6164e-01, -2.6996e-01, -3.1849e-03,  9.6369e-02, -4.9483e-01],\n",
       "         [ 1.4373e-01,  4.3056e-01,  6.6087e-01,  7.4129e-01, -9.4223e-03],\n",
       "         [-3.2197e-01, -3.9887e-01, -2.2306e-01,  4.4039e-01,  3.5285e-01],\n",
       "         [-5.0455e-01,  2.6885e-01, -8.2819e-02, -2.6758e-01,  3.7394e-01],\n",
       "         [ 1.6398e-01, -5.4962e-01, -5.0953e-01,  7.2181e-02, -5.2250e-01],\n",
       "         [-5.6734e-01, -4.9096e-01,  4.0154e-01, -3.0346e-01,  1.3244e-01],\n",
       "         [ 2.8409e-01,  5.6699e-02, -3.4257e-01, -2.7135e-01,  8.1530e-02],\n",
       "         [ 1.9064e-01, -6.4132e-01, -3.5935e-01, -7.4579e-01,  3.5756e-02],\n",
       "         [-1.4873e-01,  2.8164e-01,  1.3516e-01,  1.6900e-02,  1.0893e-01],\n",
       "         [-2.8754e-01, -1.6345e-01,  3.6638e-01,  8.9209e-01, -1.5673e-02],\n",
       "         [-5.0197e-01,  4.1457e-04, -2.5126e-01, -4.8718e-02,  2.1998e-01],\n",
       "         [-4.0307e-01, -1.0333e-01,  1.1792e-01,  3.2104e-01,  3.8996e-01],\n",
       "         [ 3.0169e-01,  3.1981e-01, -8.1613e-01, -7.6207e-02, -1.7131e-02],\n",
       "         [-3.0227e-01,  7.9813e-02,  4.6396e-01,  1.0234e+00, -1.8319e-01]],\n",
       "        dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.feed_forward.encoder_2.bias_ih_l0': tensor([-0.0247,  0.0824,  0.1896,  0.2827,  0.1327,  0.4328, -0.0987, -0.0118,\n",
       "         -0.0947, -0.5482,  0.2566, -0.1262, -0.7821, -0.2108, -0.0546, -0.0920,\n",
       "         -0.3538, -0.0827, -0.0742,  0.4846], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.feed_forward.encoder_2.bias_hh_l0': tensor([-0.1178, -0.2231, -0.4629,  0.7336,  0.0293,  0.1214,  0.5625,  0.1022,\n",
       "          0.0603, -0.4154,  0.4220,  0.1690,  0.0756, -0.3244, -0.5432,  0.2807,\n",
       "          0.4118,  0.4857,  0.4678,  0.3633], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.sublayer.0.norm.a_2': tensor([1.0851, 0.7780, 0.8035, 0.9197, 0.8766], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.sublayer.0.norm.b_2': tensor([-0.0444,  0.3176,  0.2741, -0.1560, -0.4548], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.sublayer.1.norm.a_2': tensor([1.5740, 1.2107, 0.9029, 1.0288, 1.0955], dtype=torch.float64),\n",
       " 'v_transformer.model.layers.0.sublayer.1.norm.b_2': tensor([ 0.1343, -0.1701,  0.2455, -0.1556, -0.2369], dtype=torch.float64),\n",
       " 'v_transformer.model.norm.a_2': tensor([0.2785, 0.1277, 0.1617, 0.1217, 0.1066], dtype=torch.float64),\n",
       " 'v_transformer.model.norm.b_2': tensor([ 0.0947,  0.0426,  0.1009, -0.0631, -0.0882], dtype=torch.float64),\n",
       " 'dense.weight': tensor([[ 1.4672e-02,  5.4860e-02, -5.9038e-02,  ..., -3.8029e-02,\n",
       "          -8.8763e-03, -3.3491e-02],\n",
       "         [ 1.8799e-02, -1.2290e-02, -1.7109e-02,  ...,  2.2533e-02,\n",
       "          -3.6962e-02,  1.3243e-02],\n",
       "         [-1.3545e-01,  4.2388e-02, -4.2102e-02,  ...,  4.7879e-02,\n",
       "           8.1648e-02,  5.2845e-02],\n",
       "         ...,\n",
       "         [ 1.2175e-02,  4.8735e-02,  1.7367e-01,  ..., -1.2406e-01,\n",
       "          -2.5100e-02,  5.1039e-02],\n",
       "         [-4.5217e-02, -9.8635e-02, -8.7917e-02,  ..., -8.1278e-05,\n",
       "          -8.2650e-02, -5.0422e-02],\n",
       "         [ 5.3077e-02,  8.2950e-02, -9.1362e-02,  ..., -1.6484e-01,\n",
       "           2.7652e-02, -2.6862e-02]], dtype=torch.float64),\n",
       " 'dense.bias': tensor([ 0.1816, -0.0344, -1.9362,  1.8189,  2.1331, -0.5055, -1.5841,  0.0397,\n",
       "         -0.3893, -1.3777, -1.9553,  0.0321,  1.9128, -2.1266, -2.2472, -0.1288,\n",
       "         -0.1205, -1.8331,  0.0206, -1.5689, -0.2963, -2.0312, -2.0721, -0.2369,\n",
       "          0.4190,  1.6509, -0.8878,  1.7671, -2.4316, -1.7528,  2.0561,  1.8316,\n",
       "          1.7018,  0.1782,  0.0963, -2.0919, -1.0636, -0.0446,  1.4743, -0.3045,\n",
       "         -2.1653, -0.1928, -1.2114, -1.8019,  1.6841, -0.1190, -2.0957, -0.4468,\n",
       "         -2.1214, -0.2969,  2.2387,  2.2768,  2.1852, -1.2352,  0.0523, -2.1240,\n",
       "          0.2587, -0.1882, -0.2045, -0.1123, -0.1900, -0.0090, -2.2737, -1.9489],\n",
       "        dtype=torch.float64),\n",
       " 'dense2.weight': tensor([[-3.1648e-02, -1.8020e-02,  5.3295e-02,  ...,  1.3123e-02,\n",
       "           2.3831e-02,  6.2966e-03],\n",
       "         [ 3.3862e-03,  1.9228e-02, -3.2504e-02,  ..., -5.0932e-05,\n",
       "          -2.7851e-02,  2.8147e-02],\n",
       "         [ 5.2850e-02,  4.0458e-02,  5.3849e-02,  ..., -2.1649e-02,\n",
       "          -3.1495e-02,  4.5647e-02],\n",
       "         ...,\n",
       "         [-5.0932e-02,  2.9208e-02, -1.6926e-02,  ...,  5.6461e-02,\n",
       "          -2.9843e-02, -3.1265e-02],\n",
       "         [-2.9312e-02, -8.9972e-04, -3.7099e-02,  ..., -3.5076e-02,\n",
       "           4.9820e-02, -2.8863e-02],\n",
       "         [ 3.5667e-02, -6.2166e-02, -3.1877e-02,  ..., -4.7372e-02,\n",
       "           4.8205e-02,  1.5751e-04]], dtype=torch.float64),\n",
       " 'dense2.bias': tensor([ 0.0540,  0.0019, -0.0009, -0.0441,  0.0204,  0.0452, -0.0450, -0.0287,\n",
       "         -0.0602, -0.0457, -0.0207,  0.0362, -0.0196, -0.0519,  0.0563, -0.0291,\n",
       "          0.0127,  0.0319, -0.0015,  0.0599, -0.0071,  0.0406, -0.0132,  0.0577,\n",
       "          0.0567, -0.0033, -0.0358, -0.0384, -0.0236, -0.0417, -0.0153,  0.0353,\n",
       "         -0.0160,  0.0141,  0.0231,  0.0597, -0.0147,  0.0153,  0.0443, -0.0143,\n",
       "          0.0574,  0.0130, -0.0458, -0.0440,  0.0008, -0.0147, -0.0311,  0.0547,\n",
       "         -0.0585, -0.0499,  0.0239,  0.0595, -0.0148,  0.0378, -0.0082,  0.0093,\n",
       "         -0.0426,  0.0299, -0.0412,  0.0318, -0.0068,  0.0491, -0.0435,  0.0535],\n",
       "        dtype=torch.float64),\n",
       " 'encoder_0.weight': tensor([[[-9.5413e-02, -1.3166e-02, -4.3705e-02, -4.2668e-03,  1.1002e-01],\n",
       "          [-2.9353e-02, -1.1523e-01,  8.4708e-02,  9.4840e-02,  1.6972e-01],\n",
       "          [ 4.6642e-02, -2.5695e-02,  3.7384e-02,  8.4199e-03, -6.9887e-03],\n",
       "          ...,\n",
       "          [-9.1586e-02, -1.0236e-01,  2.2430e-02, -9.8186e-02,  3.3728e-02],\n",
       "          [-1.3793e-01, -3.1270e-04, -4.4063e-03,  4.6821e-02, -1.9094e-02],\n",
       "          [ 1.1639e-01,  1.1387e-01,  1.3516e-01,  9.2429e-02, -7.1910e-03]],\n",
       " \n",
       "         [[ 1.3685e-01,  3.7892e-02,  1.1686e-01,  9.3431e-02,  2.2275e-02],\n",
       "          [ 2.3293e-02,  2.0218e-01,  1.4148e-01,  2.9175e-01,  1.9604e-01],\n",
       "          [ 2.9752e-01,  2.5367e-01,  1.8548e-01,  3.3441e-01,  2.8122e-01],\n",
       "          ...,\n",
       "          [ 1.9123e-03,  1.0949e-02,  6.1430e-02,  1.3492e-02,  4.8858e-03],\n",
       "          [-9.0322e-03,  4.8243e-02, -4.4536e-02, -1.7331e-02, -6.9043e-02],\n",
       "          [ 1.2116e-01,  7.0602e-02, -7.8271e-02,  3.8177e-02,  1.2070e-01]],\n",
       " \n",
       "         [[-1.4160e-01, -8.1099e-02, -2.1054e-02, -7.1226e-02, -5.1383e-02],\n",
       "          [ 1.3498e-01,  5.8587e-02,  1.3585e-01,  1.0582e-01,  1.7368e-01],\n",
       "          [-4.0100e-02, -1.0722e-01, -7.6982e-02, -9.3889e-02, -8.1928e-03],\n",
       "          ...,\n",
       "          [-3.1451e-03, -3.1639e-02, -5.2635e-02,  9.3929e-02,  1.3238e-02],\n",
       "          [ 1.5205e-01,  3.7109e-02,  6.0527e-02, -1.5139e-01, -3.0879e-02],\n",
       "          [ 1.5506e-01,  2.6252e-01,  2.5994e-01,  1.8022e-01,  1.4379e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-4.7126e-02, -3.5798e-02, -5.0355e-02, -5.1639e-02, -7.3878e-02],\n",
       "          [-1.1304e-01,  1.8385e-02, -8.1108e-02, -5.3020e-02, -1.7415e-01],\n",
       "          [-5.0202e-02, -2.5692e-03, -2.1494e-02, -6.0571e-02,  3.1270e-02],\n",
       "          ...,\n",
       "          [ 8.8849e-02, -2.0954e-02, -8.1400e-02, -4.7779e-02, -7.5792e-02],\n",
       "          [-1.3292e-02, -8.1000e-02,  2.0896e-02, -5.4329e-02, -1.0915e-02],\n",
       "          [-4.5837e-02, -2.7169e-02,  1.6521e-02, -3.8892e-02, -1.0878e-01]],\n",
       " \n",
       "         [[ 6.0007e-02, -7.4588e-02,  3.4268e-02,  7.0443e-02,  4.1821e-02],\n",
       "          [-1.4861e-01, -1.4766e-01, -1.8506e-01, -1.1429e-01, -5.4756e-02],\n",
       "          [-2.0931e-01, -4.0395e-02, -1.4277e-01, -5.4221e-02, -1.3137e-01],\n",
       "          ...,\n",
       "          [ 1.2335e-01, -2.0630e-02,  7.2714e-02, -2.3187e-02,  9.7551e-02],\n",
       "          [ 2.8697e-02,  5.1900e-02,  6.3863e-02,  3.1008e-02, -9.0896e-03],\n",
       "          [-1.0818e-01, -1.5587e-01, -1.0552e-01,  7.1223e-03, -1.5066e-02]],\n",
       " \n",
       "         [[ 1.2765e-01,  5.3751e-02, -1.8600e-02,  6.1883e-02, -4.6060e-02],\n",
       "          [-9.5964e-02, -1.1531e-02,  1.0650e-01, -4.2731e-03,  6.2519e-02],\n",
       "          [-5.4449e-02, -1.4708e-02,  1.1914e-01,  7.8922e-02,  3.7143e-02],\n",
       "          ...,\n",
       "          [ 1.0301e-02, -2.4331e-02, -3.6545e-02, -1.5169e-01, -1.3828e-01],\n",
       "          [-2.7203e-02,  1.9923e-02,  9.9224e-02,  5.1065e-02,  5.3463e-02],\n",
       "          [ 4.9155e-02,  6.1019e-02,  5.9603e-02, -2.9812e-02,  3.3081e-02]]],\n",
       "        dtype=torch.float64),\n",
       " 'encoder_0.bias': tensor([-0.0017, -0.0416, -0.0009, -0.0791, -0.0570, -0.1231, -0.0261, -0.1341,\n",
       "          0.0074, -0.0564, -0.0582, -0.0381, -0.1802, -0.0602, -0.0911, -0.1489,\n",
       "         -0.0295, -0.0446, -0.1046, -0.0511, -0.0668,  0.0294, -0.0762, -0.0963,\n",
       "          0.0063, -0.0128, -0.1263, -0.0730, -0.1410, -0.0836, -0.0462, -0.0034,\n",
       "         -0.0362, -0.1121,  0.0162,  0.0089,  0.0212, -0.0664, -0.0650, -0.0646,\n",
       "         -0.1010,  0.0129, -0.0110, -0.0544, -0.0876, -0.0799, -0.1450, -0.0680,\n",
       "         -0.1014, -0.0687, -0.0359, -0.1044, -0.0984, -0.0505, -0.0720,  0.0045,\n",
       "          0.0100, -0.1452, -0.1288,  0.0136, -0.1456, -0.0633, -0.0221, -0.0305,\n",
       "         -0.0605, -0.0343, -0.1367, -0.0271,  0.0108, -0.1222, -0.0277, -0.0922,\n",
       "         -0.0125, -0.1323, -0.1131, -0.0855, -0.0786, -0.0011, -0.0356, -0.0707,\n",
       "         -0.0552, -0.0799, -0.0232, -0.0699, -0.1220, -0.0382, -0.0618, -0.0548,\n",
       "         -0.1084, -0.1385, -0.0119, -0.0070, -0.0629, -0.0062, -0.0344, -0.0761,\n",
       "         -0.0645,  0.0124, -0.0961, -0.0465, -0.0853, -0.0638, -0.0499, -0.0716,\n",
       "         -0.0475, -0.0303, -0.0883, -0.0502, -0.0419, -0.0570, -0.0822,  0.0099,\n",
       "          0.0342,  0.0034, -0.0300,  0.0516, -0.0732, -0.0759, -0.0269, -0.0141,\n",
       "         -0.0528, -0.0740, -0.0168, -0.0500, -0.0163, -0.0393, -0.1674,  0.0072],\n",
       "        dtype=torch.float64),\n",
       " 'encoder_1.weight': tensor([[[-0.1376, -0.0228, -0.0414, -0.0604, -0.0658],\n",
       "          [-0.0640,  0.0562,  0.1812,  0.0548,  0.1553],\n",
       "          [-0.0047, -0.0467,  0.0653, -0.0334,  0.0316],\n",
       "          ...,\n",
       "          [-0.0864,  0.0750,  0.0046, -0.0939,  0.0111],\n",
       "          [ 0.0378,  0.0780,  0.0408,  0.0054, -0.0884],\n",
       "          [ 0.1061,  0.2003,  0.2368,  0.1243,  0.2220]],\n",
       " \n",
       "         [[-0.0198,  0.0780,  0.0937, -0.1095,  0.0290],\n",
       "          [-0.1070, -0.0582, -0.0411,  0.0337, -0.0220],\n",
       "          [ 0.0298,  0.0635,  0.0544,  0.0903, -0.0472],\n",
       "          ...,\n",
       "          [-0.1647, -0.0209, -0.0042, -0.0396, -0.1500],\n",
       "          [ 0.0147, -0.0748,  0.0160, -0.0857,  0.0863],\n",
       "          [ 0.0298, -0.0120, -0.0031,  0.0045,  0.1320]],\n",
       " \n",
       "         [[ 0.1263,  0.1946,  0.2069,  0.0740,  0.1766],\n",
       "          [ 0.0559, -0.0924, -0.0165,  0.0785, -0.1014],\n",
       "          [ 0.2202,  0.1054,  0.2263,  0.2263,  0.2448],\n",
       "          ...,\n",
       "          [-0.0459, -0.0495, -0.1316, -0.0359, -0.0347],\n",
       "          [ 0.0394,  0.0873, -0.0265, -0.0208,  0.0236],\n",
       "          [ 0.0165,  0.0663, -0.0865,  0.0099,  0.0791]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.1817,  0.1794,  0.0991,  0.1551,  0.0301],\n",
       "          [-0.0081, -0.0583, -0.0084,  0.0860, -0.0028],\n",
       "          [ 0.2707,  0.1538,  0.2236,  0.2551,  0.2364],\n",
       "          ...,\n",
       "          [-0.0595,  0.0731,  0.0371,  0.0772, -0.0422],\n",
       "          [ 0.1401,  0.1652,  0.0812,  0.0887,  0.0778],\n",
       "          [ 0.0575, -0.0679, -0.1387, -0.1332, -0.1012]],\n",
       " \n",
       "         [[ 0.1174,  0.0143, -0.0517, -0.0180,  0.0950],\n",
       "          [ 0.0242,  0.0930, -0.0233,  0.0643,  0.2390],\n",
       "          [ 0.0206, -0.0420, -0.0699, -0.0061,  0.0140],\n",
       "          ...,\n",
       "          [ 0.1159,  0.0089,  0.0412,  0.0754, -0.0847],\n",
       "          [ 0.0573, -0.0178,  0.0448,  0.0104, -0.0011],\n",
       "          [-0.0965,  0.0023, -0.1020, -0.0485,  0.0782]],\n",
       " \n",
       "         [[-0.0071,  0.0089,  0.0179, -0.0973, -0.1734],\n",
       "          [ 0.0499,  0.0704,  0.1114,  0.0728, -0.0056],\n",
       "          [-0.0427, -0.0015, -0.0308,  0.0646,  0.0537],\n",
       "          ...,\n",
       "          [-0.0818,  0.0683, -0.0220,  0.0903,  0.0195],\n",
       "          [-0.0428, -0.0586, -0.0182, -0.0493, -0.0578],\n",
       "          [ 0.1121,  0.0945,  0.1116,  0.1601,  0.0712]]], dtype=torch.float64),\n",
       " 'encoder_1.bias': tensor([-0.0515, -0.0393, -0.0161, -0.1413, -0.0542,  0.0048, -0.0193, -0.0662,\n",
       "         -0.0737, -0.1022, -0.0172, -0.0507,  0.0005, -0.0324, -0.0300, -0.0542,\n",
       "         -0.0434, -0.0988, -0.0682, -0.0898, -0.0829, -0.0495, -0.1074, -0.0177,\n",
       "         -0.0085, -0.1274, -0.0933, -0.0736, -0.1140, -0.0157, -0.0595, -0.1532,\n",
       "         -0.0556, -0.0547, -0.1021,  0.0152, -0.0909, -0.1656, -0.1135, -0.0399,\n",
       "         -0.0219, -0.0877, -0.0110, -0.0048, -0.1110, -0.0036, -0.0624, -0.0243,\n",
       "         -0.1182, -0.0381, -0.1251, -0.0396, -0.1119,  0.0200,  0.0105, -0.1439,\n",
       "         -0.0502, -0.0837, -0.0249, -0.1342, -0.0796, -0.0446, -0.0415, -0.0366,\n",
       "         -0.0180, -0.0217, -0.0855, -0.0358, -0.0677, -0.1198, -0.0663, -0.1021,\n",
       "          0.0365, -0.0281, -0.1141,  0.0044, -0.0562, -0.0343, -0.0141, -0.0403,\n",
       "         -0.0054, -0.1006, -0.0035,  0.0023, -0.0543, -0.0617, -0.0623, -0.0878,\n",
       "         -0.0168, -0.0741, -0.0701, -0.0598, -0.0312, -0.1116, -0.0561, -0.1106,\n",
       "         -0.1381, -0.0304, -0.0468, -0.0435, -0.0992, -0.0209, -0.1052,  0.0104,\n",
       "         -0.1007, -0.0772, -0.0687, -0.1568, -0.0958, -0.1033, -0.0116, -0.0143,\n",
       "         -0.1074, -0.0511, -0.0139,  0.0740, -0.0734,  0.0931, -0.0519,  0.0462,\n",
       "         -0.0848, -0.1012,  0.0040,  0.0118, -0.0257, -0.0470, -0.0491, -0.0328],\n",
       "        dtype=torch.float64),\n",
       " 'encoder_v_0.weight': tensor([[[-2.3753e-01, -1.8286e-01,  3.3682e-02,  ..., -5.3712e-02,\n",
       "           -1.8302e-01, -4.3794e-02],\n",
       "          [ 1.5751e-02, -6.2348e-02, -2.9251e-01,  ...,  7.1005e-02,\n",
       "           -1.2922e-01, -2.1625e-01],\n",
       "          [-1.0790e-01, -7.6204e-02,  9.6644e-02,  ...,  7.7654e-02,\n",
       "           -2.6757e-01,  1.9015e-01],\n",
       "          [ 1.4113e-01,  1.6881e-01,  1.6612e-01,  ...,  1.0265e-01,\n",
       "            2.0557e-01,  6.6384e-02],\n",
       "          [ 1.0177e-01,  1.3185e-01, -9.3693e-02,  ..., -7.7798e-02,\n",
       "            2.9127e-01, -7.1109e-02]],\n",
       " \n",
       "         [[ 4.7429e-01,  9.9933e-02,  8.0267e-02,  ...,  9.3934e-03,\n",
       "           -1.7015e-02,  1.1114e-01],\n",
       "          [-2.9715e-01, -3.2002e-02, -2.8443e-02,  ...,  7.3463e-02,\n",
       "           -5.9392e-02, -1.1512e-01],\n",
       "          [ 4.4890e-01, -7.0457e-02, -1.4614e-01,  ...,  3.1910e-02,\n",
       "           -2.2055e-01,  3.6510e-02],\n",
       "          [ 6.3124e-02, -4.2053e-02, -1.0237e-01,  ..., -1.0471e-01,\n",
       "            4.6020e-03, -1.2001e-01],\n",
       "          [-5.2633e-01,  1.1470e-01,  1.9359e-01,  ...,  3.6977e-03,\n",
       "            1.7810e-01,  1.4275e-01]],\n",
       " \n",
       "         [[-9.7082e-02,  1.7781e-01,  1.4872e-03,  ..., -1.0335e-01,\n",
       "           -1.1468e-02,  1.3819e-01],\n",
       "          [ 1.4007e-01,  1.5411e-01,  2.8351e-01,  ...,  1.1545e-01,\n",
       "           -3.9534e-02, -2.5373e-02],\n",
       "          [-2.2931e-01,  1.0673e-02, -1.3796e-02,  ...,  6.2054e-02,\n",
       "            8.4590e-02, -7.5846e-02],\n",
       "          [-1.8039e-01, -2.7901e-01, -2.9111e-01,  ..., -1.2896e-01,\n",
       "           -6.4630e-02,  9.0550e-02],\n",
       "          [ 2.2574e-01, -2.0521e-02,  1.5407e-02,  ...,  4.9118e-02,\n",
       "           -6.7806e-02, -6.9058e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-2.9961e-03,  1.0422e-02, -2.4148e-02,  ..., -4.7235e-02,\n",
       "           -1.8775e-01,  7.6711e-02],\n",
       "          [ 2.1865e-01, -1.0744e-01, -4.9416e-02,  ...,  7.5881e-02,\n",
       "           -3.3481e-02,  3.6997e-02],\n",
       "          [-1.0708e-01, -1.5569e-02, -4.0330e-02,  ..., -6.3714e-02,\n",
       "           -3.4306e-01,  1.3426e-01],\n",
       "          [-2.0905e-01,  5.9900e-02,  6.2073e-02,  ...,  2.9302e-02,\n",
       "            2.0562e-01,  8.3573e-02],\n",
       "          [ 7.2801e-02,  5.8046e-02,  9.3344e-02,  ...,  1.5986e-02,\n",
       "            1.9877e-01, -1.7035e-01]],\n",
       " \n",
       "         [[ 3.9513e-01, -4.2796e-02, -6.8264e-02,  ..., -1.6797e-01,\n",
       "            1.8012e-02, -1.5873e-03],\n",
       "          [-2.5737e-01, -6.4862e-02,  8.5367e-02,  ...,  2.0172e-03,\n",
       "            7.4835e-02, -2.0384e-02],\n",
       "          [ 4.3467e-01, -2.8983e-02, -3.9022e-02,  ...,  8.2164e-02,\n",
       "           -3.6022e-02,  1.3566e-01],\n",
       "          [ 9.3057e-02,  5.8452e-02,  1.1336e-01,  ..., -6.5336e-02,\n",
       "           -8.7155e-02,  1.2599e-01],\n",
       "          [-4.5173e-01,  5.8233e-02,  1.7933e-02,  ...,  2.5135e-02,\n",
       "            4.4754e-04, -1.0363e-01]],\n",
       " \n",
       "         [[ 2.1156e-01, -7.0115e-02, -9.8462e-02,  ..., -9.3159e-02,\n",
       "           -3.1807e-02, -2.0477e-01],\n",
       "          [-2.5513e-01,  4.3150e-02, -7.9658e-03,  ...,  1.8020e-02,\n",
       "            3.0660e-01, -3.3993e-02],\n",
       "          [ 2.1643e-01,  3.2604e-03, -2.6585e-02,  ...,  5.5710e-02,\n",
       "            6.6253e-02, -8.6931e-02],\n",
       "          [ 6.1631e-02,  1.2905e-01,  1.5452e-01,  ..., -9.2045e-02,\n",
       "            2.0960e-02,  1.7858e-01],\n",
       "          [-1.8495e-01, -1.3755e-02, -1.0312e-01,  ...,  3.1489e-02,\n",
       "           -3.2168e-01,  1.9217e-02]]], dtype=torch.float64),\n",
       " 'encoder_v_0.bias': tensor([-0.1075,  0.0367, -0.1551, -0.0541,  0.0705, -0.1580, -0.2080, -0.1165,\n",
       "         -0.0315, -0.0665,  0.0490,  0.0674, -0.1722, -0.0445, -0.0871, -0.0276,\n",
       "         -0.1343, -0.0554,  0.0116,  0.0559,  0.0370, -0.2068, -0.0532, -0.1565,\n",
       "         -0.0413, -0.0323, -0.0499,  0.0512, -0.0784, -0.0951,  0.0382, -0.1333],\n",
       "        dtype=torch.float64),\n",
       " 'encoder_v_1.weight': tensor([[[-1.9718e-01, -5.7559e-02,  1.3269e-01,  ..., -2.3149e-02,\n",
       "           -2.6816e-02, -1.3636e-02],\n",
       "          [-7.3947e-02,  2.4098e-02,  1.6139e-02,  ...,  9.7988e-02,\n",
       "            3.3259e-03,  1.1011e-01],\n",
       "          [-1.6061e-01,  8.1665e-02,  3.8229e-02,  ..., -5.2165e-02,\n",
       "            1.5772e-01, -2.7117e-01],\n",
       "          [ 1.9094e-01,  2.5552e-02, -1.7124e-01,  ...,  9.0846e-02,\n",
       "            3.3185e-02,  1.1299e-02],\n",
       "          [ 1.1984e-01, -7.3019e-02, -4.4106e-02,  ..., -1.0007e-01,\n",
       "           -1.2644e-01,  8.8722e-02]],\n",
       " \n",
       "         [[-9.0078e-02,  1.0441e-01,  9.4941e-02,  ..., -2.3401e-02,\n",
       "            1.4010e-01,  1.2485e-02],\n",
       "          [ 3.4962e-01, -1.2108e-01, -6.3834e-02,  ..., -5.5805e-02,\n",
       "            4.4314e-02,  3.7900e-01],\n",
       "          [-1.0409e-01,  1.9426e-02, -7.3416e-02,  ...,  1.0013e-02,\n",
       "            6.6456e-02,  4.4060e-02],\n",
       "          [-2.6310e-01, -4.9693e-02,  1.5056e-02,  ..., -3.0660e-02,\n",
       "           -8.4417e-02, -1.5398e-01],\n",
       "          [ 1.0195e-01,  3.4049e-02, -4.3947e-02,  ..., -8.1333e-02,\n",
       "           -1.7899e-01, -1.7822e-01]],\n",
       " \n",
       "         [[ 6.3866e-01,  8.1413e-02, -2.7411e-02,  ..., -9.2952e-02,\n",
       "            1.2605e-01, -1.4128e-02],\n",
       "          [-1.1526e-01, -9.7272e-02,  1.2611e-01,  ..., -1.0826e-02,\n",
       "           -6.9975e-02, -4.1815e-02],\n",
       "          [ 4.1050e-01,  4.3710e-04, -9.4774e-03,  ...,  6.2717e-02,\n",
       "            5.7764e-02,  3.9624e-02],\n",
       "          [ 9.3841e-03, -3.7071e-03, -7.1881e-02,  ..., -1.3723e-01,\n",
       "           -5.4950e-02, -2.9220e-02],\n",
       "          [-5.4158e-01,  1.2271e-01,  7.5502e-02,  ...,  6.9062e-02,\n",
       "           -7.9932e-02, -1.1830e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 3.5888e-01, -1.3982e-01,  6.9612e-02,  ..., -5.1587e-02,\n",
       "            1.1291e-01, -1.7229e-01],\n",
       "          [-2.1731e-01,  6.9106e-02, -7.8142e-02,  ...,  1.3654e-01,\n",
       "           -6.8513e-02,  1.5582e-01],\n",
       "          [ 1.7069e-01,  1.2277e-01,  3.2232e-02,  ...,  1.3930e-01,\n",
       "            1.9086e-02, -2.3963e-02],\n",
       "          [-1.2923e-02,  1.3595e-01,  1.1895e-01,  ...,  9.1329e-02,\n",
       "            1.8710e-01, -5.4910e-02],\n",
       "          [-2.2206e-01, -2.2699e-01, -1.5027e-01,  ..., -2.9044e-01,\n",
       "           -1.5162e-01,  1.6127e-02]],\n",
       " \n",
       "         [[ 5.8052e-01,  1.6430e-01, -8.7073e-02,  ...,  5.9112e-02,\n",
       "           -7.0644e-02,  2.7420e-02],\n",
       "          [-3.4627e-01, -1.8678e-01, -1.1974e-01,  ..., -1.5345e-01,\n",
       "            1.1930e-02, -2.6403e-02],\n",
       "          [ 4.5616e-01, -9.9228e-02,  6.2145e-03,  ...,  5.1150e-02,\n",
       "           -1.1452e-01, -6.9391e-02],\n",
       "          [ 1.7478e-01,  2.0608e-02, -1.8372e-02,  ..., -3.3972e-02,\n",
       "            2.2845e-01, -3.7995e-03],\n",
       "          [-5.2001e-01,  9.1012e-02,  1.7316e-01,  ...,  9.4724e-02,\n",
       "           -7.1822e-02, -2.4993e-02]],\n",
       " \n",
       "         [[-1.7040e-01,  3.6564e-02, -9.1396e-02,  ..., -3.8703e-02,\n",
       "           -1.8767e-01, -5.3681e-02],\n",
       "          [ 4.1567e-01, -2.1041e-02, -1.7165e-02,  ...,  5.9879e-02,\n",
       "           -7.4655e-02,  7.0256e-02],\n",
       "          [-1.9058e-02, -7.6407e-02, -1.5376e-01,  ..., -2.4759e-01,\n",
       "           -6.6216e-02,  8.6827e-02],\n",
       "          [-2.1183e-01,  2.7852e-02, -2.0068e-03,  ...,  1.3103e-02,\n",
       "            8.2833e-02, -2.4365e-02],\n",
       "          [ 1.7941e-02,  5.5830e-02,  2.2371e-01,  ...,  1.3727e-01,\n",
       "            1.0177e-01, -8.0836e-03]]], dtype=torch.float64),\n",
       " 'encoder_v_1.bias': tensor([-0.2234, -0.3535,  0.0336, -0.1371, -0.1569, -0.0442, -0.0462, -0.0911,\n",
       "          0.0123, -0.0065, -0.2003, -0.0546, -0.1913,  0.1434, -0.0673, -0.0558,\n",
       "         -0.1288, -0.1747, -0.0132, -0.0409, -0.0359, -0.0658, -0.0139, -0.0092,\n",
       "          0.0434, -0.1221,  0.0411,  0.0337,  0.0427, -0.1695,  0.1406, -0.0342],\n",
       "        dtype=torch.float64)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "typeformer_state = torch.load('TypeFormer_pretrained.pt', map_location='cpu', weights_only=True)\n",
    "altered_state = { key.replace('.net.3', '.net.2').replace('net','ff'): value for key, value in typeformer_state.items()}\n",
    "altered_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12.0000,  4.0000, 55.0000, 11.0000,  0.2000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[12., 4., 55., 11., 0.2]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformer_rec.model.layers.0.self_attn.rotary_pos_emb.inv_freq',\n",
       " 'transformer_rec.model.layers.0.self_attn.input_self_attn.norm.g',\n",
       " 'transformer_rec.model.layers.0.self_attn.input_self_attn.to_q.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.input_self_attn.to_kv.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.input_self_attn.to_out.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.input_self_attn.to_out.bias',\n",
       " 'transformer_rec.model.layers.0.self_attn.state_self_attn.norm.g',\n",
       " 'transformer_rec.model.layers.0.self_attn.state_self_attn.to_q.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.state_self_attn.to_kv.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.state_self_attn.to_out.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.state_self_attn.to_out.bias',\n",
       " 'transformer_rec.model.layers.0.self_attn.input_state_cross_attn.norm.g',\n",
       " 'transformer_rec.model.layers.0.self_attn.input_state_cross_attn.to_q.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.input_state_cross_attn.to_kv.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.input_state_cross_attn.to_out.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.input_state_cross_attn.to_out.bias',\n",
       " 'transformer_rec.model.layers.0.self_attn.state_input_cross_attn.norm.g',\n",
       " 'transformer_rec.model.layers.0.self_attn.state_input_cross_attn.to_q.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.state_input_cross_attn.to_kv.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.state_input_cross_attn.to_out.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.state_input_cross_attn.to_out.bias',\n",
       " 'transformer_rec.model.layers.0.self_attn.proj_gate.main_proj.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.proj_gate.main_proj.bias',\n",
       " 'transformer_rec.model.layers.0.self_attn.proj_gate.input_proj.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.proj_gate.input_proj.bias',\n",
       " 'transformer_rec.model.layers.0.self_attn.proj_gate.forget_proj.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.proj_gate.forget_proj.bias',\n",
       " 'transformer_rec.model.layers.0.self_attn.ff_gate.main_proj.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.ff_gate.main_proj.bias',\n",
       " 'transformer_rec.model.layers.0.self_attn.ff_gate.input_proj.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.ff_gate.input_proj.bias',\n",
       " 'transformer_rec.model.layers.0.self_attn.ff_gate.forget_proj.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.ff_gate.forget_proj.bias',\n",
       " 'transformer_rec.model.layers.0.self_attn.input_proj.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.state_proj.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.input_ff.ff.0.0.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.input_ff.ff.0.0.bias',\n",
       " 'transformer_rec.model.layers.0.self_attn.input_ff.ff.2.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.input_ff.ff.2.bias',\n",
       " 'transformer_rec.model.layers.0.self_attn.state_ff.ff.0.0.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.state_ff.ff.0.0.bias',\n",
       " 'transformer_rec.model.layers.0.self_attn.state_ff.ff.2.weight',\n",
       " 'transformer_rec.model.layers.0.self_attn.state_ff.ff.2.bias',\n",
       " 'transformer_rec.model.layers.0.feed_forward.bn.weight',\n",
       " 'transformer_rec.model.layers.0.feed_forward.bn.bias',\n",
       " 'transformer_rec.model.layers.0.feed_forward.bn.running_mean',\n",
       " 'transformer_rec.model.layers.0.feed_forward.bn.running_var',\n",
       " 'transformer_rec.model.layers.0.feed_forward.bn.num_batches_tracked',\n",
       " 'transformer_rec.model.layers.0.feed_forward.encoder_0.weight',\n",
       " 'transformer_rec.model.layers.0.feed_forward.encoder_0.bias',\n",
       " 'transformer_rec.model.layers.0.feed_forward.encoder_1.weight',\n",
       " 'transformer_rec.model.layers.0.feed_forward.encoder_1.bias',\n",
       " 'transformer_rec.model.layers.0.feed_forward.encoder_2.weight',\n",
       " 'transformer_rec.model.layers.0.feed_forward.encoder_2.bias',\n",
       " 'transformer_rec.model.layers.0.sublayer.0.norm.a_2',\n",
       " 'transformer_rec.model.layers.0.sublayer.0.norm.b_2',\n",
       " 'transformer_rec.model.layers.0.sublayer.1.norm.a_2',\n",
       " 'transformer_rec.model.layers.0.sublayer.1.norm.b_2',\n",
       " 'transformer_rec.model.layers.1.self_attn.rotary_pos_emb.inv_freq',\n",
       " 'transformer_rec.model.layers.1.self_attn.input_self_attn.norm.g',\n",
       " 'transformer_rec.model.layers.1.self_attn.input_self_attn.to_q.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.input_self_attn.to_kv.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.input_self_attn.to_out.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.input_self_attn.to_out.bias',\n",
       " 'transformer_rec.model.layers.1.self_attn.state_self_attn.norm.g',\n",
       " 'transformer_rec.model.layers.1.self_attn.state_self_attn.to_q.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.state_self_attn.to_kv.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.state_self_attn.to_out.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.state_self_attn.to_out.bias',\n",
       " 'transformer_rec.model.layers.1.self_attn.input_state_cross_attn.norm.g',\n",
       " 'transformer_rec.model.layers.1.self_attn.input_state_cross_attn.to_q.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.input_state_cross_attn.to_kv.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.input_state_cross_attn.to_out.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.input_state_cross_attn.to_out.bias',\n",
       " 'transformer_rec.model.layers.1.self_attn.state_input_cross_attn.norm.g',\n",
       " 'transformer_rec.model.layers.1.self_attn.state_input_cross_attn.to_q.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.state_input_cross_attn.to_kv.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.state_input_cross_attn.to_out.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.state_input_cross_attn.to_out.bias',\n",
       " 'transformer_rec.model.layers.1.self_attn.proj_gate.main_proj.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.proj_gate.main_proj.bias',\n",
       " 'transformer_rec.model.layers.1.self_attn.proj_gate.input_proj.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.proj_gate.input_proj.bias',\n",
       " 'transformer_rec.model.layers.1.self_attn.proj_gate.forget_proj.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.proj_gate.forget_proj.bias',\n",
       " 'transformer_rec.model.layers.1.self_attn.ff_gate.main_proj.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.ff_gate.main_proj.bias',\n",
       " 'transformer_rec.model.layers.1.self_attn.ff_gate.input_proj.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.ff_gate.input_proj.bias',\n",
       " 'transformer_rec.model.layers.1.self_attn.ff_gate.forget_proj.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.ff_gate.forget_proj.bias',\n",
       " 'transformer_rec.model.layers.1.self_attn.input_proj.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.state_proj.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.input_ff.ff.0.0.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.input_ff.ff.0.0.bias',\n",
       " 'transformer_rec.model.layers.1.self_attn.input_ff.ff.2.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.input_ff.ff.2.bias',\n",
       " 'transformer_rec.model.layers.1.self_attn.state_ff.ff.0.0.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.state_ff.ff.0.0.bias',\n",
       " 'transformer_rec.model.layers.1.self_attn.state_ff.ff.2.weight',\n",
       " 'transformer_rec.model.layers.1.self_attn.state_ff.ff.2.bias',\n",
       " 'transformer_rec.model.layers.1.feed_forward.bn.weight',\n",
       " 'transformer_rec.model.layers.1.feed_forward.bn.bias',\n",
       " 'transformer_rec.model.layers.1.feed_forward.bn.running_mean',\n",
       " 'transformer_rec.model.layers.1.feed_forward.bn.running_var',\n",
       " 'transformer_rec.model.layers.1.feed_forward.bn.num_batches_tracked',\n",
       " 'transformer_rec.model.layers.1.feed_forward.encoder_0.weight',\n",
       " 'transformer_rec.model.layers.1.feed_forward.encoder_0.bias',\n",
       " 'transformer_rec.model.layers.1.feed_forward.encoder_1.weight',\n",
       " 'transformer_rec.model.layers.1.feed_forward.encoder_1.bias',\n",
       " 'transformer_rec.model.layers.1.feed_forward.encoder_2.weight',\n",
       " 'transformer_rec.model.layers.1.feed_forward.encoder_2.bias',\n",
       " 'transformer_rec.model.layers.1.sublayer.0.norm.a_2',\n",
       " 'transformer_rec.model.layers.1.sublayer.0.norm.b_2',\n",
       " 'transformer_rec.model.layers.1.sublayer.1.norm.a_2',\n",
       " 'transformer_rec.model.layers.1.sublayer.1.norm.b_2',\n",
       " 'transformer_rec.model.norm.a_2',\n",
       " 'transformer_rec.model.norm.b_2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.Model import HARTrans\n",
    "from config.train_config import configs\n",
    "transformer = HARTrans(configs).double()\n",
    "[ item for item in transformer.state_dict().keys() if '_rec' in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.load_state_dict(altered_state, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9513, 0.0138, 0.0148, 0.8359, 0.7919, 0.8066, 0.0957, 0.0011, 0.8679,\n",
       "         0.4171, 0.0675, 0.3885, 0.8291, 0.1909, 0.1047, 0.3542, 0.3868, 0.2232,\n",
       "         0.4034, 0.1064, 0.7260, 0.1088, 0.0586, 0.3152, 0.2504, 0.8480, 0.2091,\n",
       "         0.9862, 0.0525, 0.1353, 0.8392, 0.8372, 0.9021, 0.2002, 0.8880, 0.0745,\n",
       "         0.7025, 0.2850, 0.8415, 0.8161, 0.1038, 0.0674, 0.1868, 0.1631, 0.7519,\n",
       "         0.8224, 0.1597, 0.6773, 0.1259, 0.3615, 0.9181, 0.8282, 0.8740, 0.3951,\n",
       "         0.0941, 0.0879, 0.8221, 0.1499, 0.7228, 0.7236, 0.7637, 0.7540, 0.0949,\n",
       "         0.1022]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create input from time-series event of keystrokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../keystrokes_4.csv')\n",
    "df['timestamp'] = df['timestamp'].map(lambda x: x/1000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_type</th>\n",
       "      <th>key</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D</td>\n",
       "      <td>16</td>\n",
       "      <td>1.726412e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>73</td>\n",
       "      <td>1.726412e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U</td>\n",
       "      <td>16</td>\n",
       "      <td>1.726412e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U</td>\n",
       "      <td>73</td>\n",
       "      <td>1.726412e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>32</td>\n",
       "      <td>1.726412e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  event_type  key     timestamp\n",
       "0          D   16  1.726412e+12\n",
       "1          D   73  1.726412e+12\n",
       "2          U   16  1.726412e+12\n",
       "3          U   73  1.726412e+12\n",
       "4          D   32  1.726412e+12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywise_feature_generator():\n",
    "    features = []\n",
    "    last_down_idx = {}\n",
    "    def next_feature(event_type: str, key: int, timestamp: float):\n",
    "        nonlocal features\n",
    "        if event_type == 'D':\n",
    "            last_down_idx[key] = len(features)\n",
    "            features.append(\n",
    "                {\n",
    "                    'key': key,\n",
    "                    'down': timestamp,\n",
    "                    'up': 0.0,\n",
    "                }\n",
    "            )\n",
    "            yield {}\n",
    "        else:\n",
    "            features[last_down_idx[key]]['up'] = timestamp\n",
    "            yield features[last_down_idx[key]]\n",
    "    return next_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "{'key': 1, 'down': 0.1, 'up': 0.25}\n",
      "{'key': 2, 'down': 0.2, 'up': 0.3}\n"
     ]
    }
   ],
   "source": [
    "next_feature = keywise_feature_generator()\n",
    "events = [\n",
    "    ('D', 1, 0.1),\n",
    "    ('D', 2, 0.2),\n",
    "    ('U', 1, 0.25),\n",
    "    ('U', 2, 0.3),\n",
    "]\n",
    "\n",
    "for event in events:\n",
    "    print(next(next_feature(*event)))\n",
    "# print(next(next_feature('D', 1, 0.1)))\n",
    "# print(next(next_feature('D', 2, 0.2)))\n",
    "# print(next(next_feature('U', 1, 0.25)))\n",
    "# print(next(next_feature('U', 2, 0.3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'key': 16, 'down': 1726412251692.3606, 'up': 1726412251892.5317},\n",
       " {'key': 73, 'down': 1726412251810.3462, 'up': 1726412251892.5317},\n",
       " {'key': 32, 'down': 1726412252002.7615, 'up': 1726412252082.5757},\n",
       " {'key': 84, 'down': 1726412252144.7578, 'up': 1726412252216.1365},\n",
       " {'key': 82, 'down': 1726412252342.3472, 'up': 1726412252429.166},\n",
       " {'key': 73, 'down': 1726412252444.793, 'up': 1726412252533.5994},\n",
       " {'key': 69, 'down': 1726412252534.6526, 'up': 1726412252628.639},\n",
       " {'key': 68, 'down': 1726412252722.8936, 'up': 1726412252811.5208},\n",
       " {'key': 32, 'down': 1726412252779.7593, 'up': 1726412252865.494},\n",
       " {'key': 83, 'down': 1726412252973.0483, 'up': 1726412253061.2117},\n",
       " {'key': 79, 'down': 1726412253052.8442, 'up': 1726412253136.183},\n",
       " {'key': 32, 'down': 1726412253248.437, 'up': 1726412253345.579},\n",
       " {'key': 72, 'down': 1726412253458.7986, 'up': 1726412253532.637},\n",
       " {'key': 65, 'down': 1726412253532.637, 'up': 1726412253602.8596},\n",
       " {'key': 82, 'down': 1726412253682.9722, 'up': 1726412253765.6658},\n",
       " {'key': 68, 'down': 1726412253892.858, 'up': 1726412253989.7737},\n",
       " {'key': 32, 'down': 1726412253989.7737, 'up': 1726412254110.2722},\n",
       " {'key': 65, 'down': 1726412254110.2722, 'up': 1726412254197.362},\n",
       " {'key': 78, 'down': 1726412254197.362, 'up': 1726412254277.7217},\n",
       " {'key': 68, 'down': 1726412254368.6863, 'up': 1726412254542.8066},\n",
       " {'key': 32, 'down': 1726412254646.2515, 'up': 1726412254735.0085},\n",
       " {'key': 71, 'down': 1726412254797.9358, 'up': 1726412254884.8208},\n",
       " {'key': 79, 'down': 1726412254903.0364, 'up': 1726412254982.7998},\n",
       " {'key': 84, 'down': 1726412255032.9275, 'up': 1726412255114.734},\n",
       " {'key': 32, 'down': 1726412255114.734, 'up': 1726412255182.8818},\n",
       " {'key': 83, 'down': 1726412255276.8696, 'up': 1726412255381.9077},\n",
       " {'key': 79, 'down': 1726412255331.2544, 'up': 1726412255408.6438},\n",
       " {'key': 32, 'down': 1726412255512.6228, 'up': 1726412255602.9702},\n",
       " {'key': 70, 'down': 1726412255642.7664, 'up': 1726412255723.3445},\n",
       " {'key': 65, 'down': 1726412255812.9727, 'up': 1726412255922.8943},\n",
       " {'key': 82, 'down': 1726412255994.1382, 'up': 1726412256072.836},\n",
       " {'key': 32, 'down': 1726412256097.203, 'up': 1726412256194.2397},\n",
       " {'key': 66, 'down': 1726412256282.964, 'up': 1726412256358.0427},\n",
       " {'key': 85, 'down': 1726412256377.722, 'up': 1726412256482.7803},\n",
       " {'key': 84, 'down': 1726412256515.3574, 'up': 1726412256592.776},\n",
       " {'key': 32, 'down': 1726412256592.776, 'up': 1726412256675.1438},\n",
       " {'key': 73, 'down': 1726412256848.2683, 'up': 1726412256923.3315},\n",
       " {'key': 78, 'down': 1726412256988.0195, 'up': 1726412257046.1704},\n",
       " {'key': 32, 'down': 1726412257133.1785, 'up': 1726412257213.229},\n",
       " {'key': 84, 'down': 1726412257213.229, 'up': 1726412257288.7212},\n",
       " {'key': 72, 'down': 1726412257320.462, 'up': 1726412257412.9697},\n",
       " {'key': 69, 'down': 1726412257412.9697, 'up': 1726412257510.3425},\n",
       " {'key': 32, 'down': 1726412257510.3425, 'up': 1726412257592.7146},\n",
       " {'key': 69, 'down': 1726412257620.506, 'up': 1726412257699.316},\n",
       " {'key': 78, 'down': 1726412257747.0723, 'up': 1726412257853.1616},\n",
       " {'key': 68, 'down': 1726412257853.1616, 'up': 1726412257929.098},\n",
       " {'key': 32, 'down': 1726412257952.9287, 'up': 1726412258027.8748},\n",
       " {'key': 73, 'down': 1726412258138.0188, 'up': 1726412258242.9214},\n",
       " {'key': 84, 'down': 1726412258246.6248, 'up': 1726412258297.6082},\n",
       " {'key': 32, 'down': 1726412258353.0781, 'up': 1726412258433.2297},\n",
       " {'key': 68, 'down': 1726412258486.7368, 'up': 1726412258563.2002},\n",
       " {'key': 79, 'down': 1726412258563.2002, 'up': 1726412258646.3645},\n",
       " {'key': 69, 'down': 1726412258673.2341, 'up': 1726412258748.1536},\n",
       " {'key': 83, 'down': 1726412258842.9678, 'up': 1726412258934.3206},\n",
       " {'key': 78, 'down': 1726412259202.973, 'up': 1726412259283.0352},\n",
       " {'key': 39, 'down': 1726412259465.2783, 'up': 1726412259573.5679},\n",
       " {'key': 84, 'down': 1726412259614.8293, 'up': 1726412259683.1194},\n",
       " {'key': 32, 'down': 1726412259777.2, 'up': 1726412259852.9958},\n",
       " {'key': 69, 'down': 1726412259955.127, 'up': 1726412260043.2427},\n",
       " {'key': 86, 'down': 1726412260160.9558, 'up': 1726412260300.0723},\n",
       " {'key': 69, 'down': 1726412260231.59, 'up': 1726412260348.2947},\n",
       " {'key': 78, 'down': 1726412260348.2947, 'up': 1726412260403.1797},\n",
       " {'key': 32, 'down': 1726412260483.7305, 'up': 1726412260568.275},\n",
       " {'key': 77, 'down': 1726412260633.2346, 'up': 1726412260733.365},\n",
       " {'key': 65, 'down': 1726412260733.365, 'up': 1726412260803.0854},\n",
       " {'key': 84, 'down': 1726412260883.4502, 'up': 1726412260969.3572},\n",
       " {'key': 84, 'down': 1726412261045.405, 'up': 1726412261119.7788},\n",
       " {'key': 69, 'down': 1726412261123.2883, 'up': 1726412261213.1658},\n",
       " {'key': 82, 'down': 1726412261193.0823, 'up': 1726412261303.2258},\n",
       " {'key': 32, 'down': 1726412261364.2378, 'up': 1726412261453.513},\n",
       " {'key': 8, 'down': 1726412261873.2659, 'up': 1726412261969.5444},\n",
       " {'key': 46, 'down': 1726412262088.2056, 'up': 1726412262203.382},\n",
       " {'key': 32, 'down': 1726412262201.8562, 'up': 1726412262299.2043},\n",
       " {'key': 16, 'down': 1726412264503.6016, 'up': 1726412264644.6382},\n",
       " {'key': 79, 'down': 1726412264530.3342, 'up': 1726412264644.6382},\n",
       " {'key': 78, 'down': 1726412264738.766, 'up': 1726412264800.5513},\n",
       " {'key': 32, 'down': 1726412264915.1848, 'up': 1726412264983.2478},\n",
       " {'key': 69, 'down': 1726412265106.0076, 'up': 1726412265214.4775},\n",
       " {'key': 8, 'down': 1726412265853.6045, 'up': 1726412265905.1228},\n",
       " {'key': 8, 'down': 1726412265979.5652, 'up': 1726412266063.5464},\n",
       " {'key': 69, 'down': 1726412266063.5464, 'up': 1726412266170.3696},\n",
       " {'key': 32, 'down': 1726412266226.8186, 'up': 1726412266324.4058},\n",
       " {'key': 84, 'down': 1726412266442.3801, 'up': 1726412266512.4148},\n",
       " {'key': 72, 'down': 1726412266525.098, 'up': 1726412266588.7134},\n",
       " {'key': 73, 'down': 1726412266703.9463, 'up': 1726412266783.4314},\n",
       " {'key': 78, 'down': 1726412266845.5288, 'up': 1726412266924.195},\n",
       " {'key': 71, 'down': 1726412266949.982, 'up': 1726412267016.7988},\n",
       " {'key': 32, 'down': 1726412267016.7988, 'up': 1726412267098.0388},\n",
       " {'key': 16, 'down': 1726412267342.251, 'up': 1726412267529.0864},\n",
       " {'key': 73, 'down': 1726412267462.1172, 'up': 1726412267529.0864},\n",
       " {'key': 32, 'down': 1726412267643.901, 'up': 1726412267723.9246},\n",
       " {'key': 68, 'down': 1726412267743.465, 'up': 1726412267803.8418},\n",
       " {'key': 79, 'down': 1726412267867.5574, 'up': 1726412267954.2415},\n",
       " {'key': 78, 'down': 1726412268033.6335, 'up': 1726412268095.408},\n",
       " {'key': 39, 'down': 1726412268233.927, 'up': 1726412268346.1072},\n",
       " {'key': 84, 'down': 1726412268347.8765, 'up': 1726412268414.7915},\n",
       " {'key': 32, 'down': 1726412268482.5164, 'up': 1726412268552.94},\n",
       " {'key': 75, 'down': 1726412268609.932, 'up': 1726412268706.8186},\n",
       " {'key': 78, 'down': 1726412268764.705, 'up': 1726412268823.868},\n",
       " {'key': 79, 'down': 1726412268883.9104, 'up': 1726412268964.6455},\n",
       " {'key': 87, 'down': 1726412269004.4153, 'up': 1726412269123.8447},\n",
       " {'key': 32, 'down': 1726412269123.8447, 'up': 1726412269197.5796},\n",
       " {'key': 87, 'down': 1726412269232.107, 'up': 1726412269303.637},\n",
       " {'key': 72, 'down': 1726412269303.637, 'up': 1726412269365.5945},\n",
       " {'key': 89, 'down': 1726412269484.022, 'up': 1726412269595.9126},\n",
       " {'key': 32, 'down': 1726412269670.2954, 'up': 1726412269763.5864},\n",
       " {'key': 16, 'down': 1726412270904.093, 'up': 1726412271056.312},\n",
       " {'key': 73, 'down': 1726412271014.036, 'up': 1726412271096.384},\n",
       " {'key': 84, 'down': 1726412271183.7449, 'up': 1726412271226.9275},\n",
       " {'key': 32, 'down': 1726412271274.5854, 'up': 1726412271362.5283},\n",
       " {'key': 70, 'down': 1726412271546.2942, 'up': 1726412271643.8884},\n",
       " {'key': 79, 'down': 1726412271666.272, 'up': 1726412271763.3193},\n",
       " {'key': 69, 'down': 1726412271815.9438, 'up': 1726412271914.901},\n",
       " {'key': 8, 'down': 1726412272268.373, 'up': 1726412272336.475},\n",
       " {'key': 8, 'down': 1726412272404.1235, 'up': 1726412272479.98},\n",
       " {'key': 68, 'down': 1726412272604.3435, 'up': 1726412272688.6104},\n",
       " {'key': 73, 'down': 1726412272754.0051, 'up': 1726412272796.3074},\n",
       " {'key': 69, 'down': 1726412272839.0017, 'up': 1726412272895.4922},\n",
       " {'key': 8, 'down': 1726412273194.3372, 'up': 1726412273245.655},\n",
       " {'key': 8, 'down': 1726412273324.1614, 'up': 1726412273396.1118},\n",
       " {'key': 8, 'down': 1726412273463.9783, 'up': 1726412273546.95},\n",
       " {'key': 68, 'down': 1726412273848.3696, 'up': 1726412273940.2817},\n",
       " {'key': 79, 'down': 1726412273968.1006, 'up': 1726412274079.119},\n",
       " {'key': 69, 'down': 1726412274080.2573, 'up': 1726412274128.9597},\n",
       " {'key': 83, 'down': 1726412274254.6687, 'up': 1726412274359.3772},\n",
       " {'key': 32, 'down': 1726412274385.0503, 'up': 1726412274474.4512},\n",
       " {'key': 78, 'down': 1726412274584.077, 'up': 1726412274648.531},\n",
       " {'key': 79, 'down': 1726412274704.1533, 'up': 1726412274807.7373},\n",
       " {'key': 84, 'down': 1726412274807.7373, 'up': 1726412274882.3772},\n",
       " {'key': 32, 'down': 1726412274900.433, 'up': 1726412275029.1797},\n",
       " {'key': 69, 'down': 1726412275030.2942, 'up': 1726412275162.3164},\n",
       " {'key': 86, 'down': 1726412275234.9575, 'up': 1726412275383.9294},\n",
       " {'key': 69, 'down': 1726412275308.243, 'up': 1726412275447.7935},\n",
       " {'key': 78, 'down': 1726412275383.9294, 'up': 1726412275465.392},\n",
       " {'key': 32, 'down': 1726412275548.5486, 'up': 1726412275614.0115},\n",
       " {'key': 77, 'down': 1726412275683.8733, 'up': 1726412275764.6853},\n",
       " {'key': 65, 'down': 1726412275794.5144, 'up': 1726412275898.6628},\n",
       " {'key': 84, 'down': 1726412275935.9688, 'up': 1726412275995.4602},\n",
       " {'key': 84, 'down': 1726412276074.1135, 'up': 1726412276147.182},\n",
       " {'key': 69, 'down': 1726412276147.182, 'up': 1726412276265.083},\n",
       " {'key': 82, 'down': 1726412276230.718, 'up': 1726412276346.4622},\n",
       " {'key': 32, 'down': 1726412276346.4622, 'up': 1726412276434.7827},\n",
       " {'key': 72, 'down': 1726412276536.2554, 'up': 1726412276604.3977},\n",
       " {'key': 79, 'down': 1726412276734.3335, 'up': 1726412276824.5027},\n",
       " {'key': 87, 'down': 1726412276867.3633, 'up': 1726412276948.08},\n",
       " {'key': 32, 'down': 1726412276976.6382, 'up': 1726412277081.483},\n",
       " {'key': 72, 'down': 1726412277164.0886, 'up': 1726412277248.0552},\n",
       " {'key': 65, 'down': 1726412277227.035, 'up': 1726412277304.6333},\n",
       " {'key': 82, 'down': 1726412277389.9958, 'up': 1726412277464.3374},\n",
       " {'key': 68, 'down': 1726412277581.3882, 'up': 1726412277664.2012},\n",
       " {'key': 32, 'down': 1726412277664.2012, 'up': 1726412277734.1328},\n",
       " {'key': 89, 'down': 1726412277853.2068, 'up': 1726412277941.5046},\n",
       " {'key': 79, 'down': 1726412277957.7346, 'up': 1726412278027.736},\n",
       " {'key': 85, 'down': 1726412278144.2068, 'up': 1726412278224.3726},\n",
       " {'key': 32, 'down': 1726412278320.246, 'up': 1726412278425.6729},\n",
       " {'key': 84, 'down': 1726412278427.365, 'up': 1726412278474.3},\n",
       " {'key': 82, 'down': 1726412278604.9321, 'up': 1726412278685.987},\n",
       " {'key': 89, 'down': 1726412278685.987, 'up': 1726412278764.645}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature_generator = keywise_feature_generator()\n",
    "features = []\n",
    "for event in df.itertuples():\n",
    "    f = next(df_feature_generator(event.event_type, event.key, event.timestamp))\n",
    "    if len(f) == 0:\n",
    "        continue\n",
    "    features.append(f)\n",
    "    \n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(features)):\n",
    "    if features[i]['down'] < features[i-1]['down']:\n",
    "        print('Not sorted at index', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold latency, inter-key latency, press latency, release latency, ascii\n",
    "def create_feator_vector(feature, previous_feature=None):\n",
    "    if previous_feature is None:\n",
    "        return torch.tensor(\n",
    "            [feature['up'] - feature['down'],\n",
    "             0.0,\n",
    "             0.0,\n",
    "             0.0,\n",
    "             feature['key'] / 128] \n",
    "        )\n",
    "    \n",
    "    return torch.tensor(\n",
    "        [feature['up'] - feature['down'],\n",
    "         feature['down'] - previous_feature['up'],\n",
    "         feature['down'] - previous_feature['down'],\n",
    "         feature['up'] - previous_feature['up'],\n",
    "         feature['key'] / 128]\n",
    "    )\n",
    "\n",
    "def model_input_generator():\n",
    "    previous_feature = None\n",
    "    def next_input(feature):\n",
    "        nonlocal previous_feature\n",
    "        vec = create_feator_vector(feature, previous_feature)\n",
    "        previous_feature = feature\n",
    "        yield vec\n",
    "    \n",
    "    return next_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0017e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2500e-01])\n",
      "tensor([ 82.1855, -82.1855, 117.9856,   0.0000,   0.5703])\n",
      "tensor([ 79.8142, 110.2297, 192.4153, 190.0439,   0.2500])\n",
      "tensor([ 71.3787,  62.1821, 141.9963, 133.5608,   0.6562])\n",
      "tensor([ 86.8188, 126.2107, 197.5894, 213.0295,   0.6406])\n",
      "tensor([ 88.8064,  15.6270, 102.4458, 104.4333,   0.5703])\n",
      "tensor([93.9863,  1.0532, 89.8596, 95.0396,  0.5391])\n",
      "tensor([ 88.6272,  94.2546, 188.2410, 182.8818,   0.5312])\n",
      "tensor([ 85.7346, -31.7615,  56.8657,  53.9731,   0.2500])\n",
      "tensor([ 88.1633, 107.5544, 193.2891, 195.7178,   0.6484])\n",
      "tensor([83.3389, -8.3674, 79.7959, 74.9714,  0.6172])\n",
      "tensor([ 97.1421, 112.2539, 195.5928, 209.3960,   0.2500])\n",
      "tensor([ 73.8384, 113.2195, 210.3616, 187.0579,   0.5625])\n",
      "tensor([70.2227,  0.0000, 73.8384, 70.2227,  0.5078])\n",
      "tensor([ 82.6936,  80.1125, 150.3352, 162.8062,   0.6406])\n",
      "tensor([ 96.9158, 127.1921, 209.8857, 224.1079,   0.5312])\n",
      "tensor([120.4985,   0.0000,  96.9158, 120.4985,   0.2500])\n",
      "tensor([ 87.0898,   0.0000, 120.4985,  87.0898,   0.5078])\n",
      "tensor([80.3596,  0.0000, 87.0898, 80.3596,  0.6094])\n",
      "tensor([174.1204,  90.9646, 171.3242, 265.0850,   0.5312])\n",
      "tensor([8.8757e+01, 1.0344e+02, 2.7757e+02, 1.9220e+02, 2.5000e-01])\n",
      "tensor([ 86.8850,  62.9272, 151.6843, 149.8123,   0.5547])\n",
      "tensor([ 79.7634,  18.2156, 105.1006,  97.9790,   0.6172])\n",
      "tensor([ 81.8064,  50.1277, 129.8911, 131.9341,   0.6562])\n",
      "tensor([68.1479,  0.0000, 81.8064, 68.1479,  0.2500])\n",
      "tensor([105.0381,  93.9878, 162.1357, 199.0259,   0.6484])\n",
      "tensor([ 77.3894, -50.6533,  54.3848,  26.7361,   0.6172])\n",
      "tensor([ 90.3474, 103.9790, 181.3684, 194.3264,   0.2500])\n",
      "tensor([ 80.5781,  39.7961, 130.1436, 120.3743,   0.5469])\n",
      "tensor([109.9216,  89.6282, 170.2063, 199.5498,   0.5078])\n",
      "tensor([ 78.6978,  71.2439, 181.1655, 149.9417,   0.6406])\n",
      "tensor([ 97.0369,  24.3669, 103.0647, 121.4038,   0.2500])\n",
      "tensor([ 75.0786,  88.7244, 185.7612, 163.8030,   0.5156])\n",
      "tensor([105.0583,  19.6792,  94.7578, 124.7375,   0.6641])\n",
      "tensor([ 77.4185,  32.5771, 137.6355, 109.9956,   0.6562])\n",
      "tensor([82.3679,  0.0000, 77.4185, 82.3679,  0.2500])\n",
      "tensor([ 75.0632, 173.1245, 255.4924, 248.1877,   0.5703])\n",
      "tensor([ 58.1509,  64.6880, 139.7512, 122.8389,   0.6094])\n",
      "tensor([ 80.0505,  87.0081, 145.1589, 167.0586,   0.2500])\n",
      "tensor([75.4922,  0.0000, 80.0505, 75.4922,  0.6562])\n",
      "tensor([ 92.5078,  31.7407, 107.2329, 124.2485,   0.5625])\n",
      "tensor([97.3728,  0.0000, 92.5078, 97.3728,  0.5391])\n",
      "tensor([82.3721,  0.0000, 97.3728, 82.3721,  0.2500])\n",
      "tensor([ 78.8098,  27.7915, 110.1636, 106.6013,   0.5391])\n",
      "tensor([106.0894,  47.7563, 126.5662, 153.8457,   0.6094])\n",
      "tensor([ 75.9363,   0.0000, 106.0894,  75.9363,   0.5312])\n",
      "tensor([74.9460, 23.8308, 99.7671, 98.7769,  0.2500])\n",
      "tensor([104.9026, 110.1440, 185.0901, 215.0466,   0.5703])\n",
      "tensor([ 50.9834,   3.7034, 108.6060,  54.6868,   0.6562])\n",
      "tensor([ 80.1516,  55.4700, 106.4534, 135.6216,   0.2500])\n",
      "tensor([ 76.4634,  53.5071, 133.6587, 129.9705,   0.5312])\n",
      "tensor([83.1643,  0.0000, 76.4634, 83.1643,  0.6172])\n",
      "tensor([ 74.9194,  26.8696, 110.0339, 101.7891,   0.5391])\n",
      "tensor([ 91.3528,  94.8142, 169.7336, 186.1670,   0.6484])\n",
      "tensor([ 80.0623, 268.6523, 360.0051, 348.7146,   0.6094])\n",
      "tensor([108.2896, 182.2432, 262.3054, 290.5327,   0.3047])\n",
      "tensor([ 68.2900,  41.2615, 149.5510, 109.5515,   0.6562])\n",
      "tensor([ 75.7959,  94.0806, 162.3706, 169.8765,   0.2500])\n",
      "tensor([ 88.1157, 102.1311, 177.9270, 190.2468,   0.5391])\n",
      "tensor([139.1165, 117.7131, 205.8289, 256.8296,   0.6719])\n",
      "tensor([116.7046, -68.4822,  70.6343,  48.2224,   0.5391])\n",
      "tensor([ 54.8850,   0.0000, 116.7046,  54.8850,   0.6094])\n",
      "tensor([ 84.5444,  80.5508, 135.4358, 165.0952,   0.2500])\n",
      "tensor([100.1304,  64.9597, 149.5042, 165.0901,   0.6016])\n",
      "tensor([ 69.7205,   0.0000, 100.1304,  69.7205,   0.5078])\n",
      "tensor([ 85.9070,  80.3647, 150.0852, 166.2717,   0.6562])\n",
      "tensor([ 74.3738,  76.0479, 161.9548, 150.4216,   0.6562])\n",
      "tensor([89.8774,  3.5095, 77.8833, 93.3870,  0.5391])\n",
      "tensor([110.1436, -20.0835,  69.7939,  90.0601,   0.6406])\n",
      "tensor([ 89.2751,  61.0120, 171.1555, 150.2871,   0.2500])\n",
      "tensor([9.6279e+01, 4.1975e+02, 5.0903e+02, 5.1603e+02, 6.2500e-02])\n",
      "tensor([115.1765, 118.6611, 214.9397, 233.8376,   0.3594])\n",
      "tensor([ 97.3481,  -1.5259, 113.6506,  95.8223,   0.2500])\n",
      "tensor([1.4104e+02, 2.2044e+03, 2.3017e+03, 2.3454e+03, 1.2500e-01])\n",
      "tensor([ 114.3040, -114.3040,   26.7327,    0.0000,    0.6172])\n",
      "tensor([ 61.7852,  94.1279, 208.4319, 155.9131,   0.6094])\n",
      "tensor([ 68.0630, 114.6335, 176.4187, 182.6965,   0.2500])\n",
      "tensor([108.4700, 122.7598, 190.8228, 231.2297,   0.5391])\n",
      "tensor([5.1518e+01, 6.3913e+02, 7.4760e+02, 6.9065e+02, 6.2500e-02])\n",
      "tensor([8.3981e+01, 7.4442e+01, 1.2596e+02, 1.5842e+02, 6.2500e-02])\n",
      "tensor([106.8232,   0.0000,  83.9812, 106.8232,   0.5391])\n",
      "tensor([ 97.5872,  56.4490, 163.2722, 154.0361,   0.2500])\n",
      "tensor([ 70.0347, 117.9744, 215.5615, 188.0090,   0.6562])\n",
      "tensor([63.6155, 12.6831, 82.7178, 76.2986,  0.5625])\n",
      "tensor([ 79.4851, 115.2329, 178.8484, 194.7180,   0.5703])\n",
      "tensor([ 78.6663,  62.0974, 141.5825, 140.7637,   0.6094])\n",
      "tensor([ 66.8169,  25.7869, 104.4531,  92.6038,   0.5547])\n",
      "tensor([81.2400,  0.0000, 66.8169, 81.2400,  0.2500])\n",
      "tensor([1.8684e+02, 2.4421e+02, 3.2545e+02, 4.3105e+02, 1.2500e-01])\n",
      "tensor([ 66.9692, -66.9692, 119.8662,   0.0000,   0.5703])\n",
      "tensor([ 80.0237, 114.8145, 181.7837, 194.8381,   0.2500])\n",
      "tensor([60.3767, 19.5405, 99.5642, 79.9172,  0.5312])\n",
      "tensor([ 86.6841,  63.7156, 124.0923, 150.3997,   0.6172])\n",
      "tensor([ 61.7744,  79.3921, 166.0762, 141.1665,   0.6094])\n",
      "tensor([112.1802, 138.5190, 200.2935, 250.6992,   0.3047])\n",
      "tensor([ 66.9150,   1.7693, 113.9495,  68.6843,   0.6562])\n",
      "tensor([ 70.4236,  67.7249, 134.6399, 138.1484,   0.2500])\n",
      "tensor([ 96.8867,  56.9919, 127.4155, 153.8787,   0.5859])\n",
      "tensor([ 59.1628,  57.8865, 154.7732, 117.0493,   0.6094])\n",
      "tensor([ 80.7351,  60.0425, 119.2053, 140.7776,   0.6172])\n",
      "tensor([119.4294,  39.7698, 120.5049, 159.1992,   0.6797])\n",
      "tensor([ 73.7349,   0.0000, 119.4294,  73.7349,   0.2500])\n",
      "tensor([ 71.5300,  34.5273, 108.2622, 106.0574,   0.6797])\n",
      "tensor([61.9575,  0.0000, 71.5300, 61.9575,  0.5625])\n",
      "tensor([111.8906, 118.4275, 180.3850, 230.3181,   0.6953])\n",
      "tensor([ 93.2910,  74.3828, 186.2734, 167.6738,   0.2500])\n",
      "tensor([1.5222e+02, 1.1405e+03, 1.2338e+03, 1.2927e+03, 1.2500e-01])\n",
      "tensor([ 82.3481, -42.2761, 109.9429,  40.0720,   0.5703])\n",
      "tensor([ 43.1826,  87.3608, 169.7090, 130.5435,   0.6562])\n",
      "tensor([ 87.9429,  47.6580,  90.8406, 135.6008,   0.2500])\n",
      "tensor([ 97.5942, 183.7659, 271.7087, 281.3601,   0.5469])\n",
      "tensor([ 97.0474,  22.3835, 119.9778, 119.4309,   0.6172])\n",
      "tensor([ 98.9570,  52.6245, 149.6719, 151.5815,   0.5391])\n",
      "tensor([6.8102e+01, 3.5347e+02, 4.5243e+02, 4.2157e+02, 6.2500e-02])\n",
      "tensor([7.5856e+01, 6.7648e+01, 1.3575e+02, 1.4350e+02, 6.2500e-02])\n",
      "tensor([ 84.2668, 124.3635, 200.2200, 208.6304,   0.5312])\n",
      "tensor([ 42.3022,  65.3948, 149.6616, 107.6970,   0.5703])\n",
      "tensor([56.4905, 42.6943, 84.9966, 99.1848,  0.5391])\n",
      "tensor([5.1318e+01, 2.9884e+02, 3.5534e+02, 3.5016e+02, 6.2500e-02])\n",
      "tensor([7.1950e+01, 7.8506e+01, 1.2982e+02, 1.5046e+02, 6.2500e-02])\n",
      "tensor([8.2972e+01, 6.7866e+01, 1.3982e+02, 1.5084e+02, 6.2500e-02])\n",
      "tensor([ 91.9121, 301.4197, 384.3914, 393.3318,   0.5312])\n",
      "tensor([111.0183,  27.8188, 119.7310, 138.8372,   0.6172])\n",
      "tensor([ 48.7024,   1.1384, 112.1567,  49.8408,   0.5391])\n",
      "tensor([104.7085, 125.7090, 174.4114, 230.4175,   0.6484])\n",
      "tensor([ 89.4009,  25.6731, 130.3816, 115.0740,   0.2500])\n",
      "tensor([ 64.4541, 109.6257, 199.0266, 174.0798,   0.6094])\n",
      "tensor([103.5840,  55.6223, 120.0764, 159.2063,   0.6172])\n",
      "tensor([ 74.6399,   0.0000, 103.5840,  74.6399,   0.6562])\n",
      "tensor([128.7466,  18.0559,  92.6958, 146.8025,   0.2500])\n",
      "tensor([132.0222,   1.1145, 129.8611, 133.1367,   0.5391])\n",
      "tensor([148.9719,  72.6411, 204.6633, 221.6130,   0.6719])\n",
      "tensor([139.5505, -75.6865,  73.2854,  63.8640,   0.5391])\n",
      "tensor([ 81.4626, -63.8640,  75.6865,  17.5986,   0.6094])\n",
      "tensor([ 65.4629,  83.1565, 164.6191, 148.6194,   0.2500])\n",
      "tensor([ 80.8120,  69.8618, 135.3247, 150.6738,   0.6016])\n",
      "tensor([104.1484,  29.8291, 110.6411, 133.9775,   0.5078])\n",
      "tensor([ 59.4915,  37.3059, 141.4543,  96.7974,   0.6562])\n",
      "tensor([ 73.0684,  78.6533, 138.1448, 151.7217,   0.6562])\n",
      "tensor([117.9011,   0.0000,  73.0684, 117.9011,   0.5391])\n",
      "tensor([115.7441, -34.3650,  83.5361,  81.3792,   0.6406])\n",
      "tensor([ 88.3206,   0.0000, 115.7441,  88.3206,   0.2500])\n",
      "tensor([ 68.1423, 101.4727, 189.7932, 169.6150,   0.5625])\n",
      "tensor([ 90.1692, 129.9358, 198.0781, 220.1050,   0.6172])\n",
      "tensor([ 80.7168,  42.8606, 133.0298, 123.5774,   0.6797])\n",
      "tensor([104.8447,  28.5581, 109.2749, 133.4028,   0.2500])\n",
      "tensor([ 83.9666,  82.6057, 187.4504, 166.5723,   0.5625])\n",
      "tensor([ 77.5984, -21.0203,  62.9463,  56.5781,   0.5078])\n",
      "tensor([ 74.3416,  85.3625, 162.9609, 159.7041,   0.6406])\n",
      "tensor([ 82.8130, 117.0508, 191.3923, 199.8638,   0.5312])\n",
      "tensor([69.9316,  0.0000, 82.8130, 69.9316,  0.2500])\n",
      "tensor([ 88.2979, 119.0740, 189.0056, 207.3718,   0.6953])\n",
      "tensor([ 70.0015,  16.2300, 104.5278,  86.2314,   0.6172])\n",
      "tensor([ 80.1658, 116.4707, 186.4722, 196.6365,   0.6641])\n",
      "tensor([105.4268,  95.8735, 176.0393, 201.3003,   0.2500])\n",
      "tensor([ 46.9351,   1.6921, 107.1189,  48.6272,   0.6562])\n",
      "tensor([ 81.0549, 130.6321, 177.5671, 211.6870,   0.6406])\n",
      "tensor([78.6580,  0.0000, 81.0549, 78.6580,  0.6953])\n"
     ]
    }
   ],
   "source": [
    "model_input_gen = model_input_generator()\n",
    "inputs = []\n",
    "for feature in features:\n",
    "    inputs.append(next(model_input_gen(feature)))\n",
    "    print(inputs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8976, 0.1840, 0.2840,  ..., 0.7051, 0.0928, 0.0428],\n",
       "        [0.4014, 0.1517, 0.1177,  ..., 0.3880, 0.1678, 0.0370],\n",
       "        [0.9846, 0.1572, 0.0314,  ..., 0.3968, 0.1249, 0.0415],\n",
       "        ...,\n",
       "        [0.9311, 0.0307, 0.1120,  ..., 0.6309, 0.0721, 0.0897],\n",
       "        [0.9532, 0.1425, 0.0157,  ..., 0.5976, 0.0958, 0.0508],\n",
       "        [0.8715, 0.0818, 0.0376,  ..., 0.6656, 0.0625, 0.0405]],\n",
       "       dtype=torch.float64, grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer(torch.stack(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing similarity of embedding by splitting features into 5 sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features 158\n",
      "Number of sessions 5\n",
      "Session lengths [31, 32, 31, 32, 32]\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of features {len(features)}')\n",
    "size = len(features)\n",
    "num_of_sessions = 5\n",
    "sessions = []\n",
    "for i in range(num_of_sessions-1):\n",
    "    sessions.append(\n",
    "        torch.stack(inputs[i*size//num_of_sessions:(i+1)*size//num_of_sessions])\n",
    "    )\n",
    "sessions.append(\n",
    "    torch.stack(inputs[(num_of_sessions-1)*size//num_of_sessions:])\n",
    ")\n",
    "print(f'Number of sessions {len(sessions)}')\n",
    "print(f'Session lengths {[len(session) for session in sessions]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.8856, 0.1088, 0.0719, 0.8187, 0.8513, 0.8022, 0.1066, 0.0540, 0.8278,\n",
       "         0.2389, 0.0863, 0.3549, 0.8734, 0.0908, 0.0935, 0.2500, 0.2885, 0.1399,\n",
       "         0.5329, 0.0522, 0.6949, 0.0784, 0.0711, 0.5644, 0.2466, 0.8569, 0.0201,\n",
       "         0.9906, 0.0324, 0.1078, 0.8818, 0.8508, 0.9450, 0.1885, 0.6847, 0.0632,\n",
       "         0.5387, 0.3846, 0.8774, 0.6200, 0.0884, 0.2582, 0.2077, 0.1699, 0.8287,\n",
       "         0.7358, 0.0848, 0.7760, 0.1141, 0.4266, 0.9005, 0.8832, 0.8684, 0.2185,\n",
       "         0.1548, 0.1112, 0.8779, 0.4991, 0.7867, 0.5737, 0.8630, 0.4846, 0.0771,\n",
       "         0.0614], dtype=torch.float64, grad_fn=<MeanBackward1>),\n",
       " tensor([0.8741, 0.1073, 0.0689, 0.8233, 0.8611, 0.8079, 0.0945, 0.0475, 0.8218,\n",
       "         0.2402, 0.0814, 0.3235, 0.8747, 0.0917, 0.1017, 0.2817, 0.3276, 0.1501,\n",
       "         0.4816, 0.0754, 0.6855, 0.0771, 0.0767, 0.5152, 0.2321, 0.8605, 0.0401,\n",
       "         0.9867, 0.0352, 0.1075, 0.8893, 0.8622, 0.9379, 0.1804, 0.7189, 0.0604,\n",
       "         0.5227, 0.3307, 0.8798, 0.6140, 0.0850, 0.2306, 0.2123, 0.1603, 0.8209,\n",
       "         0.7860, 0.0888, 0.7535, 0.1250, 0.4566, 0.9073, 0.8902, 0.8718, 0.2114,\n",
       "         0.1439, 0.1102, 0.8768, 0.4527, 0.7298, 0.6269, 0.8827, 0.4848, 0.0803,\n",
       "         0.0629], dtype=torch.float64, grad_fn=<MeanBackward1>),\n",
       " tensor([0.8808, 0.1160, 0.0630, 0.8292, 0.8648, 0.7801, 0.0983, 0.0493, 0.8253,\n",
       "         0.2253, 0.0853, 0.3037, 0.8669, 0.0917, 0.1051, 0.3005, 0.3194, 0.1500,\n",
       "         0.5011, 0.0699, 0.7131, 0.0791, 0.0785, 0.5800, 0.2042, 0.8506, 0.0388,\n",
       "         0.9854, 0.0304, 0.1105, 0.8864, 0.8758, 0.9420, 0.2079, 0.6379, 0.0628,\n",
       "         0.5456, 0.3281, 0.8720, 0.5949, 0.0917, 0.2400, 0.1729, 0.1592, 0.8375,\n",
       "         0.7859, 0.0944, 0.7488, 0.1227, 0.5174, 0.8946, 0.8885, 0.8703, 0.2211,\n",
       "         0.1584, 0.1082, 0.8504, 0.5060, 0.7896, 0.5734, 0.8701, 0.4515, 0.0846,\n",
       "         0.0664], dtype=torch.float64, grad_fn=<MeanBackward1>),\n",
       " tensor([0.9126, 0.1086, 0.0573, 0.8424, 0.8596, 0.7516, 0.1060, 0.0565, 0.8295,\n",
       "         0.2183, 0.0844, 0.3127, 0.8578, 0.0933, 0.0986, 0.3149, 0.3400, 0.1516,\n",
       "         0.5002, 0.0771, 0.7337, 0.0881, 0.0753, 0.5725, 0.2386, 0.8454, 0.0640,\n",
       "         0.9830, 0.0324, 0.1169, 0.8824, 0.8750, 0.9418, 0.2042, 0.7085, 0.0756,\n",
       "         0.5611, 0.3563, 0.8670, 0.6276, 0.0889, 0.2659, 0.1682, 0.1612, 0.8326,\n",
       "         0.8155, 0.1014, 0.7219, 0.1041, 0.5488, 0.9017, 0.8945, 0.8608, 0.2340,\n",
       "         0.1767, 0.1054, 0.8513, 0.5192, 0.8145, 0.6170, 0.8390, 0.4499, 0.0781,\n",
       "         0.0768], dtype=torch.float64, grad_fn=<MeanBackward1>),\n",
       " tensor([0.8860, 0.0872, 0.0559, 0.8280, 0.8674, 0.8182, 0.0938, 0.0431, 0.8180,\n",
       "         0.2381, 0.0815, 0.3309, 0.8669, 0.0941, 0.1021, 0.2779, 0.3200, 0.1347,\n",
       "         0.5239, 0.0535, 0.7016, 0.0723, 0.0714, 0.5253, 0.2690, 0.8574, 0.0180,\n",
       "         0.9897, 0.0289, 0.1055, 0.8811, 0.8680, 0.9448, 0.1804, 0.7394, 0.0573,\n",
       "         0.5347, 0.3440, 0.8800, 0.6256, 0.0885, 0.2336, 0.2120, 0.1590, 0.8311,\n",
       "         0.7839, 0.0891, 0.7452, 0.1025, 0.4651, 0.9096, 0.8877, 0.8563, 0.2283,\n",
       "         0.1285, 0.1017, 0.8839, 0.4643, 0.7742, 0.5906, 0.8805, 0.4880, 0.0716,\n",
       "         0.0644], dtype=torch.float64, grad_fn=<MeanBackward1>)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_of_vectors(t: torch.Tensor) -> torch.Tensor:\n",
    "    return t.mean(dim=0)\n",
    "    \n",
    "\n",
    "embeddings = [mean_of_vectors(transformer(session)) for session in sessions]\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session 0 tensor(0.9993, dtype=torch.float64, grad_fn=<SumBackward1>) tensor(0.9991, dtype=torch.float64, grad_fn=<SumBackward1>) tensor(0.9986, dtype=torch.float64, grad_fn=<SumBackward1>) tensor(0.9995, dtype=torch.float64, grad_fn=<SumBackward1>) \n",
      "session 1 tensor(0.9991, dtype=torch.float64, grad_fn=<SumBackward1>) tensor(0.9988, dtype=torch.float64, grad_fn=<SumBackward1>) tensor(0.9997, dtype=torch.float64, grad_fn=<SumBackward1>) \n",
      "session 2 tensor(0.9995, dtype=torch.float64, grad_fn=<SumBackward1>) tensor(0.9991, dtype=torch.float64, grad_fn=<SumBackward1>) \n",
      "session 3 tensor(0.9989, dtype=torch.float64, grad_fn=<SumBackward1>) \n",
      "session 4 \n"
     ]
    }
   ],
   "source": [
    "# cosine similarity for pairwise embeddings\n",
    "def cosine_similarity(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.nn.functional.cosine_similarity(a, b, 0)\n",
    "\n",
    "for i in range(num_of_sessions):\n",
    "    print('session', i, end=' ')\n",
    "    for j in range(i+1, num_of_sessions):\n",
    "        print(cosine_similarity(embeddings[i], embeddings[j]), end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8878, 0.1056, 0.0634, 0.8283, 0.8608, 0.7920, 0.0998, 0.0500, 0.8245,\n",
       "        0.2321, 0.0838, 0.3251, 0.8679, 0.0923, 0.1002, 0.2850, 0.3191, 0.1453,\n",
       "        0.5079, 0.0656, 0.7058, 0.0790, 0.0746, 0.5515, 0.2381, 0.8542, 0.0362,\n",
       "        0.9871, 0.0318, 0.1096, 0.8842, 0.8664, 0.9423, 0.1923, 0.6979, 0.0639,\n",
       "        0.5406, 0.3488, 0.8752, 0.6164, 0.0885, 0.2457, 0.1946, 0.1619, 0.8302,\n",
       "        0.7814, 0.0917, 0.7491, 0.1137, 0.4829, 0.9027, 0.8888, 0.8655, 0.2227,\n",
       "        0.1525, 0.1074, 0.8680, 0.4883, 0.7790, 0.5963, 0.8671, 0.4718, 0.0783,\n",
       "        0.0664], dtype=torch.float64, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embeddings = mean_of_vectors(torch.stack(embeddings))\n",
    "user_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User embedding creation fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features 158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.8843, 0.0933, 0.0624, 0.8321, 0.8642, 0.7888, 0.1030, 0.0469, 0.8288,\n",
       "        0.2399, 0.0806, 0.3230, 0.8656, 0.0951, 0.1032, 0.2979, 0.3261, 0.1437,\n",
       "        0.5142, 0.0627, 0.7115, 0.0769, 0.0758, 0.5417, 0.2477, 0.8492, 0.0382,\n",
       "        0.9864, 0.0325, 0.1059, 0.8838, 0.8683, 0.9420, 0.1832, 0.6840, 0.0664,\n",
       "        0.5531, 0.3484, 0.8793, 0.6279, 0.0855, 0.2414, 0.1890, 0.1616, 0.8373,\n",
       "        0.7719, 0.0896, 0.7725, 0.1092, 0.4770, 0.9051, 0.8872, 0.8698, 0.2199,\n",
       "        0.1641, 0.1068, 0.8623, 0.4761, 0.7752, 0.6001, 0.8630, 0.4777, 0.0828,\n",
       "        0.0660], dtype=torch.float64, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../keystrokes_4.csv')\n",
    "df['timestamp'] = df['timestamp'].map(lambda x: x/1000_000)\n",
    "\n",
    "keywise_feat_gen = keywise_feature_generator()\n",
    "keywise_feat = []\n",
    "for event in df.itertuples():\n",
    "    f = next(keywise_feat_gen(event.event_type, event.key, event.timestamp))\n",
    "    if len(f) == 0:\n",
    "        continue\n",
    "    keywise_feat.append(f)\n",
    "    \n",
    "model_input_gen = model_input_generator()\n",
    "inputs = []\n",
    "for feature in keywise_feat:\n",
    "    inputs.append(next(model_input_gen(feature)))\n",
    "\n",
    "print(f'Number of features {len(keywise_feat)}')\n",
    "embeddings = mean_of_vectors(transformer(torch.stack(inputs)))\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9089, 0.1018, 0.0394, 0.8267, 0.8333, 0.7174, 0.1051, 0.0483, 0.8351,\n",
       "        0.2359, 0.0839, 0.2503, 0.8154, 0.1243, 0.1360, 0.3906, 0.3920, 0.1700,\n",
       "        0.4031, 0.0911, 0.7515, 0.0854, 0.0820, 0.6605, 0.2118, 0.8584, 0.1520,\n",
       "        0.9677, 0.0357, 0.1297, 0.8890, 0.9060, 0.9287, 0.2646, 0.6207, 0.0864,\n",
       "        0.5803, 0.3206, 0.8624, 0.6029, 0.0999, 0.2435, 0.1119, 0.1628, 0.8341,\n",
       "        0.8420, 0.1007, 0.6486, 0.0968, 0.7165, 0.8851, 0.8877, 0.8443, 0.2534,\n",
       "        0.1593, 0.1254, 0.8213, 0.5856, 0.8256, 0.5604, 0.8731, 0.4660, 0.0915,\n",
       "        0.0740], dtype=torch.float64, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv('../keystrokes_5.csv')\n",
    "df_1['timestamp'] = df_1['timestamp'].map(lambda x: x/1000_000)\n",
    "\n",
    "keywise_feat_gen = keywise_feature_generator()\n",
    "model_input_gen = model_input_generator()\n",
    "inputs = []\n",
    "for event in df_1.itertuples():\n",
    "    f = next(keywise_feat_gen(event.event_type, event.key, event.timestamp))\n",
    "    if len(f) == 0:\n",
    "        continue\n",
    "    inputs.append(next(model_input_gen(f)))\n",
    "        \n",
    "embeddings1 = mean_of_vectors(transformer(torch.stack(inputs)))\n",
    "embeddings1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4413, dtype=torch.float64, grad_fn=<NormBackward1>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# euclidean distance\n",
    "def euclidean_distance(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.nn.functional.pairwise_distance(a, b, p=2)\n",
    "euclidean_distance(embeddings, embeddings1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8900, 0.0978, 0.0516, 0.8293, 0.8549, 0.7664, 0.1017, 0.0466, 0.8241,\n",
       "        0.2315, 0.0854, 0.3035, 0.8493, 0.1099, 0.1136, 0.3267, 0.3359, 0.1525,\n",
       "        0.4710, 0.0772, 0.7308, 0.0826, 0.0803, 0.5861, 0.2196, 0.8551, 0.0650,\n",
       "        0.9820, 0.0324, 0.1170, 0.8897, 0.8792, 0.9377, 0.2181, 0.6740, 0.0729,\n",
       "        0.5589, 0.3328, 0.8731, 0.6100, 0.0923, 0.2305, 0.1646, 0.1652, 0.8371,\n",
       "        0.7932, 0.0944, 0.7352, 0.1058, 0.5479, 0.9041, 0.8862, 0.8649, 0.2340,\n",
       "        0.1637, 0.1075, 0.8549, 0.5177, 0.7926, 0.5898, 0.8761, 0.4756, 0.0853,\n",
       "        0.0697], dtype=torch.float64, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = pd.read_csv('../keystrokes_6.csv')\n",
    "df_2['timestamp'] = df_2['timestamp'].map(lambda x: x/1000_000)\n",
    "\n",
    "keywise_feat_gen = keywise_feature_generator()\n",
    "model_input_gen = model_input_generator()\n",
    "inputs = []\n",
    "for event in df_2.itertuples():\n",
    "    f = next(keywise_feat_gen(event.event_type, event.key, event.timestamp))\n",
    "    if len(f) == 0:\n",
    "        continue\n",
    "    inputs.append(next(model_input_gen(f)))\n",
    "        \n",
    "embeddings2 = mean_of_vectors(transformer(torch.stack(inputs)))\n",
    "embeddings2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1465, dtype=torch.float64, grad_fn=<NormBackward1>)\n",
      "tensor(0.3035, dtype=torch.float64, grad_fn=<NormBackward1>)\n",
      "tensor(0.4413, dtype=torch.float64, grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9995, dtype=torch.float64, grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(euclidean_distance(embeddings, embeddings2))\n",
    "print(euclidean_distance(embeddings1, embeddings2))\n",
    "print(euclidean_distance(embeddings, embeddings1))\n",
    "torch.nn.functional.cosine_similarity(embeddings, embeddings2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.read_csv('../keystrokes_7.csv')\n",
    "df_3['timestamp'] = df_3['timestamp'].map(lambda x: x/1000_000)\n",
    "\n",
    "keywise_feat_gen = keywise_feature_generator()\n",
    "model_input_gen = model_input_generator()\n",
    "inputs = []\n",
    "for event in df_3.itertuples():\n",
    "    f = next(keywise_feat_gen(event.event_type, event.key, event.timestamp))\n",
    "    if len(f) == 0:\n",
    "        continue\n",
    "    inputs.append(next(model_input_gen(f)))\n",
    "    \n",
    "embeddings3 = mean_of_vectors(transformer(torch.stack(inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0803, dtype=torch.float64, grad_fn=<NormBackward1>)\n",
      "tensor(0.1465, dtype=torch.float64, grad_fn=<NormBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(euclidean_distance(embeddings, embeddings3))\n",
    "print(euclidean_distance(embeddings, embeddings2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10 = pd.read_csv('../keystrokes_10.csv')\n",
    "df_10['timestamp'] = df_10['timestamp'].map(lambda x: x/1000_000)\n",
    "\n",
    "keywise_feat_gen = keywise_feature_generator()\n",
    "model_input_gen = model_input_generator()\n",
    "inputs = []\n",
    "for event in df_10.itertuples():\n",
    "    f = next(keywise_feat_gen(event.event_type, event.key, event.timestamp))\n",
    "    if len(f) == 0:\n",
    "        continue\n",
    "    inputs.append(next(model_input_gen(f)))\n",
    "    \n",
    "embeddings10 = mean_of_vectors(transformer(torch.stack(inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11 = pd.read_csv('../keystrokes_11.csv')\n",
    "df_11['timestamp'] = df_11['timestamp'].map(lambda x: x/1000_000)\n",
    "\n",
    "keywise_feat_gen = keywise_feature_generator()\n",
    "model_input_gen = model_input_generator()\n",
    "inputs = []\n",
    "for event in df_11.itertuples():\n",
    "    f = next(keywise_feat_gen(event.event_type, event.key, event.timestamp))\n",
    "    if len(f) == 0:\n",
    "        continue\n",
    "    inputs.append(next(model_input_gen(f)))\n",
    "    \n",
    "embeddings11 = mean_of_vectors(transformer(torch.stack(inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1398, dtype=torch.float64, grad_fn=<NormBackward1>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance(embeddings, embeddings10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0756, dtype=torch.float64, grad_fn=<NormBackward1>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance(embeddings, embeddings11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
